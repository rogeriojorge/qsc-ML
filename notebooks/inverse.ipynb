{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a006d30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3feecd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'epochs': 200,\n",
    "    'test_size': 0.2,\n",
    "    'random_state': 1337,\n",
    "    'validation_split': 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "626db50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/qsc_out.random_scan_nfp2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "266e3f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.115912</td>\n",
       "      <td>-0.207162</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.012060</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>-0.736734</td>\n",
       "      <td>0.012462</td>\n",
       "      <td>0.783335</td>\n",
       "      <td>0.278748</td>\n",
       "      <td>0.497138</td>\n",
       "      <td>0.645087</td>\n",
       "      <td>0.926717</td>\n",
       "      <td>1.717088</td>\n",
       "      <td>0.338459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.081966</td>\n",
       "      <td>-0.182033</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.010903</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.755056</td>\n",
       "      <td>0.031954</td>\n",
       "      <td>1.379462</td>\n",
       "      <td>0.284927</td>\n",
       "      <td>0.386816</td>\n",
       "      <td>0.493242</td>\n",
       "      <td>0.881144</td>\n",
       "      <td>1.562226</td>\n",
       "      <td>0.326036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.098121</td>\n",
       "      <td>0.188199</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>-0.010709</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>-0.641071</td>\n",
       "      <td>0.060675</td>\n",
       "      <td>1.124535</td>\n",
       "      <td>0.342645</td>\n",
       "      <td>0.523383</td>\n",
       "      <td>0.639508</td>\n",
       "      <td>0.869696</td>\n",
       "      <td>1.574066</td>\n",
       "      <td>0.331869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.077109</td>\n",
       "      <td>-0.206706</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.006428</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>-0.000304</td>\n",
       "      <td>-0.868233</td>\n",
       "      <td>-0.092663</td>\n",
       "      <td>1.205836</td>\n",
       "      <td>0.265378</td>\n",
       "      <td>0.541464</td>\n",
       "      <td>0.512058</td>\n",
       "      <td>0.907885</td>\n",
       "      <td>1.711111</td>\n",
       "      <td>0.324205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.082828</td>\n",
       "      <td>0.221897</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>-0.008468</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>-0.758676</td>\n",
       "      <td>-0.317667</td>\n",
       "      <td>1.026909</td>\n",
       "      <td>0.273752</td>\n",
       "      <td>0.751935</td>\n",
       "      <td>0.643160</td>\n",
       "      <td>0.944501</td>\n",
       "      <td>1.518423</td>\n",
       "      <td>0.326940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6        x7   \n",
       "0 -0.115912 -0.207162  0.001411  0.012060  0.000871 -0.000108 -0.736734  \\\n",
       "1 -0.081966 -0.182033  0.001298  0.010903  0.000813 -0.000155 -0.755056   \n",
       "2 -0.098121  0.188199  0.001285 -0.010709  0.000807  0.000152 -0.641071   \n",
       "3 -0.077109 -0.206706  0.001522  0.006428  0.000926 -0.000304 -0.868233   \n",
       "4 -0.082828  0.221897  0.000230 -0.008468  0.000198  0.000174 -0.758676   \n",
       "\n",
       "         x8        y0        y1        y2        y3        y4        y5   \n",
       "0  0.012462  0.783335  0.278748  0.497138  0.645087  0.926717  1.717088  \\\n",
       "1  0.031954  1.379462  0.284927  0.386816  0.493242  0.881144  1.562226   \n",
       "2  0.060675  1.124535  0.342645  0.523383  0.639508  0.869696  1.574066   \n",
       "3 -0.092663  1.205836  0.265378  0.541464  0.512058  0.907885  1.711111   \n",
       "4 -0.317667  1.026909  0.273752  0.751935  0.643160  0.944501  1.518423   \n",
       "\n",
       "         y6  \n",
       "0  0.338459  \n",
       "1  0.326036  \n",
       "2  0.331869  \n",
       "3  0.324205  \n",
       "4  0.326940  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe81e8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4796, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc22d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = [col for col in df.columns if col.startswith('x')]\n",
    "y_columns = [col for col in df.columns if col.startswith('y')]\n",
    "\n",
    "## ACTUALLY SOLVING THE INVERSE PROBLEM\n",
    "Y = df[x_columns].values\n",
    "X = df[y_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "368937c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_train, X_test, Y_train, Y_test, params):\n",
    "    scaler_x = StandardScaler().fit(X_train)\n",
    "    scaler_y = StandardScaler().fit(Y_train)\n",
    "    X_train = scaler_x.transform(X_train)\n",
    "    X_test = scaler_x.transform(X_test)\n",
    "    Y_train = scaler_y.transform(Y_train)\n",
    "    Y_test = scaler_y.transform(Y_test)\n",
    "\n",
    "    input_shape = X_train.shape[1]\n",
    "    \n",
    "    output_shape = Y_train.shape[1]\n",
    "    return X_train, X_test, Y_train, Y_test, input_shape, output_shape, scaler_x, scaler_y\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=params['test_size'], \n",
    "                                                    random_state=params['random_state'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test, input_shape, output_shape, scaler_x, scaler_y = preprocess_data(X_train, X_test, Y_train, Y_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d8e5d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-4.01657042e-15,  4.72944589e-15,  2.50063555e-15, -3.41465936e-15,\n",
       "        -5.97028509e-15, -9.70058815e-15, -3.51141604e-14]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.mean(axis=0), X_train.std(axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9395cc23",
   "metadata": {},
   "source": [
    "## Appears to be drift, perhaps the sample is not big enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea6231fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.03647091, 0.05036899, 0.0240539 , 0.01615513, 0.02262298,\n",
       "        0.069791  , 0.00742891]),\n",
       " array([1.04363768, 1.03365372, 1.03354061, 1.01573765, 1.04018519,\n",
       "        0.98510014, 1.0395029 ]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.mean(axis=0), X_test.std(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec739c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.83484230e-17, -2.05489663e-17,  1.57677139e-16,  1.15291278e-16,\n",
       "        -6.44832351e-17, -3.98823600e-17,  2.63764795e-16,  9.18495381e-16]),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.mean(axis=0), Y_train.std(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "031dc5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.02525043,  0.00971201,  0.01397497,  0.04719729,  0.01297527,\n",
       "        -0.02875165, -0.00224075,  0.00415783]),\n",
       " array([1.00535971, 1.00234493, 1.04188367, 1.01245292, 1.03768115,\n",
       "        0.98217117, 1.014723  , 1.01594242]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.mean(axis=0), Y_test.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570f8bae",
   "metadata": {},
   "source": [
    "## Dummy regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a3f6c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98a743cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16],\n",
       "       [ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16],\n",
       "       [ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16],\n",
       "       ...,\n",
       "       [ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16],\n",
       "       [ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16],\n",
       "       [ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = MultiOutputRegressor(DummyRegressor(strategy=\"mean\")).fit(X_train, Y_train)\n",
    "regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f63f156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.784444521947988"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_train, regr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f93f49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7960079177938875"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_test, regr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04a0b59",
   "metadata": {},
   "source": [
    "## Train a linear regression for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d16830e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15676934,  0.04012469, -0.12659159, ...,  0.06290221,\n",
       "        -0.40890284,  0.03899315],\n",
       "       [ 0.098538  ,  0.02856683, -0.02685268, ..., -0.01454209,\n",
       "        -0.16032767,  0.49703159],\n",
       "       [-0.17443072,  0.00250346,  0.13851425, ..., -0.0678374 ,\n",
       "        -0.04978863,  0.27261235],\n",
       "       ...,\n",
       "       [ 0.02097198,  0.03903598,  0.03713012, ..., -0.02695103,\n",
       "        -0.3743756 ,  0.34646245],\n",
       "       [-0.26866067,  0.03050944,  0.16463002, ..., -0.05755192,\n",
       "        -0.21087286,  0.37635694],\n",
       "       [ 0.33351338,  0.08189727, -0.20413084, ...,  0.07795407,\n",
       "        -0.54412842,  0.25056948]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = MultiOutputRegressor(Ridge(random_state=123)).fit(X_train, Y_train)\n",
    "regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ace27dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7415822877132044"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_train, regr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6c2c051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7557919677337949"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_test, regr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc845dde",
   "metadata": {},
   "source": [
    "## Simplest neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2090cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5c2fcbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 8), dtype=float32, numpy=\n",
       "array([[-0.07937413,  0.2776039 ,  0.06575887, -0.01724354,  0.05366279,\n",
       "         0.06912079, -0.08714859, -0.07554742]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Sequential model with 3 layers\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(input_shape, activation=\"relu\", name=\"layer_in\"),\n",
    "        layers.Dense(128, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(64, activation=\"relu\", name=\"layer3\"),\n",
    "        layers.Dense(output_shape, name=\"layer_out\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model(X_train[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd7e9881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer_in (Dense)            (1, 7)                    56        \n",
      "                                                                 \n",
      " layer2 (Dense)              (1, 128)                  1024      \n",
      "                                                                 \n",
      " layer3 (Dense)              (1, 64)                   8256      \n",
      "                                                                 \n",
      " layer_out (Dense)           (1, 8)                    520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9856 (38.50 KB)\n",
      "Trainable params: 9856 (38.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db203b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.MeanAbsoluteError(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.MeanAbsoluteError()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a4fbb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/80\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.7574 - mean_absolute_error: 0.7574 - val_loss: 0.7539 - val_mean_absolute_error: 0.7539\n",
      "Epoch 2/80\n",
      "60/60 [==============================] - 0s 874us/step - loss: 0.7353 - mean_absolute_error: 0.7353 - val_loss: 0.7450 - val_mean_absolute_error: 0.7450\n",
      "Epoch 3/80\n",
      "60/60 [==============================] - 0s 834us/step - loss: 0.7285 - mean_absolute_error: 0.7285 - val_loss: 0.7410 - val_mean_absolute_error: 0.7410\n",
      "Epoch 4/80\n",
      "60/60 [==============================] - 0s 840us/step - loss: 0.7236 - mean_absolute_error: 0.7236 - val_loss: 0.7384 - val_mean_absolute_error: 0.7384\n",
      "Epoch 5/80\n",
      "60/60 [==============================] - 0s 774us/step - loss: 0.7199 - mean_absolute_error: 0.7199 - val_loss: 0.7344 - val_mean_absolute_error: 0.7344\n",
      "Epoch 6/80\n",
      "60/60 [==============================] - 0s 757us/step - loss: 0.7170 - mean_absolute_error: 0.7170 - val_loss: 0.7330 - val_mean_absolute_error: 0.7330\n",
      "Epoch 7/80\n",
      "60/60 [==============================] - 0s 742us/step - loss: 0.7137 - mean_absolute_error: 0.7137 - val_loss: 0.7288 - val_mean_absolute_error: 0.7288\n",
      "Epoch 8/80\n",
      "60/60 [==============================] - 0s 726us/step - loss: 0.7116 - mean_absolute_error: 0.7116 - val_loss: 0.7285 - val_mean_absolute_error: 0.7285\n",
      "Epoch 9/80\n",
      "60/60 [==============================] - 0s 731us/step - loss: 0.7090 - mean_absolute_error: 0.7090 - val_loss: 0.7269 - val_mean_absolute_error: 0.7269\n",
      "Epoch 10/80\n",
      "60/60 [==============================] - 0s 708us/step - loss: 0.7072 - mean_absolute_error: 0.7072 - val_loss: 0.7251 - val_mean_absolute_error: 0.7251\n",
      "Epoch 11/80\n",
      "60/60 [==============================] - 0s 657us/step - loss: 0.7053 - mean_absolute_error: 0.7053 - val_loss: 0.7245 - val_mean_absolute_error: 0.7245\n",
      "Epoch 12/80\n",
      "60/60 [==============================] - 0s 630us/step - loss: 0.7033 - mean_absolute_error: 0.7033 - val_loss: 0.7232 - val_mean_absolute_error: 0.7232\n",
      "Epoch 13/80\n",
      "60/60 [==============================] - 0s 635us/step - loss: 0.7024 - mean_absolute_error: 0.7024 - val_loss: 0.7236 - val_mean_absolute_error: 0.7236\n",
      "Epoch 14/80\n",
      "60/60 [==============================] - 0s 778us/step - loss: 0.7011 - mean_absolute_error: 0.7011 - val_loss: 0.7227 - val_mean_absolute_error: 0.7227\n",
      "Epoch 15/80\n",
      "60/60 [==============================] - 0s 633us/step - loss: 0.6998 - mean_absolute_error: 0.6998 - val_loss: 0.7219 - val_mean_absolute_error: 0.7219\n",
      "Epoch 16/80\n",
      "60/60 [==============================] - 0s 629us/step - loss: 0.6986 - mean_absolute_error: 0.6986 - val_loss: 0.7204 - val_mean_absolute_error: 0.7204\n",
      "Epoch 17/80\n",
      "60/60 [==============================] - 0s 615us/step - loss: 0.6974 - mean_absolute_error: 0.6974 - val_loss: 0.7216 - val_mean_absolute_error: 0.7216\n",
      "Epoch 18/80\n",
      "60/60 [==============================] - 0s 625us/step - loss: 0.6963 - mean_absolute_error: 0.6963 - val_loss: 0.7190 - val_mean_absolute_error: 0.7190\n",
      "Epoch 19/80\n",
      "60/60 [==============================] - 0s 625us/step - loss: 0.6952 - mean_absolute_error: 0.6952 - val_loss: 0.7215 - val_mean_absolute_error: 0.7215\n",
      "Epoch 20/80\n",
      "60/60 [==============================] - 0s 621us/step - loss: 0.6941 - mean_absolute_error: 0.6941 - val_loss: 0.7184 - val_mean_absolute_error: 0.7184\n",
      "Epoch 21/80\n",
      "60/60 [==============================] - 0s 638us/step - loss: 0.6930 - mean_absolute_error: 0.6930 - val_loss: 0.7178 - val_mean_absolute_error: 0.7178\n",
      "Epoch 22/80\n",
      "60/60 [==============================] - 0s 664us/step - loss: 0.6922 - mean_absolute_error: 0.6922 - val_loss: 0.7178 - val_mean_absolute_error: 0.7178\n",
      "Epoch 23/80\n",
      "60/60 [==============================] - 0s 661us/step - loss: 0.6913 - mean_absolute_error: 0.6913 - val_loss: 0.7171 - val_mean_absolute_error: 0.7171\n",
      "Epoch 24/80\n",
      "60/60 [==============================] - 0s 682us/step - loss: 0.6901 - mean_absolute_error: 0.6901 - val_loss: 0.7169 - val_mean_absolute_error: 0.7169\n",
      "Epoch 25/80\n",
      "60/60 [==============================] - 0s 634us/step - loss: 0.6895 - mean_absolute_error: 0.6895 - val_loss: 0.7172 - val_mean_absolute_error: 0.7172\n",
      "Epoch 26/80\n",
      "60/60 [==============================] - 0s 704us/step - loss: 0.6886 - mean_absolute_error: 0.6886 - val_loss: 0.7161 - val_mean_absolute_error: 0.7161\n",
      "Epoch 27/80\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.6875 - mean_absolute_error: 0.6875 - val_loss: 0.7148 - val_mean_absolute_error: 0.7148\n",
      "Epoch 28/80\n",
      "60/60 [==============================] - 0s 675us/step - loss: 0.6867 - mean_absolute_error: 0.6867 - val_loss: 0.7141 - val_mean_absolute_error: 0.7141\n",
      "Epoch 29/80\n",
      "60/60 [==============================] - 0s 691us/step - loss: 0.6859 - mean_absolute_error: 0.6859 - val_loss: 0.7141 - val_mean_absolute_error: 0.7141\n",
      "Epoch 30/80\n",
      "60/60 [==============================] - 0s 665us/step - loss: 0.6851 - mean_absolute_error: 0.6851 - val_loss: 0.7119 - val_mean_absolute_error: 0.7119\n",
      "Epoch 31/80\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.6840 - mean_absolute_error: 0.6840 - val_loss: 0.7145 - val_mean_absolute_error: 0.7145\n",
      "Epoch 32/80\n",
      "60/60 [==============================] - 0s 748us/step - loss: 0.6829 - mean_absolute_error: 0.6829 - val_loss: 0.7111 - val_mean_absolute_error: 0.7111\n",
      "Epoch 33/80\n",
      "60/60 [==============================] - 0s 803us/step - loss: 0.6820 - mean_absolute_error: 0.6820 - val_loss: 0.7108 - val_mean_absolute_error: 0.7108\n",
      "Epoch 34/80\n",
      "60/60 [==============================] - 0s 833us/step - loss: 0.6811 - mean_absolute_error: 0.6811 - val_loss: 0.7099 - val_mean_absolute_error: 0.7099\n",
      "Epoch 35/80\n",
      "60/60 [==============================] - 0s 837us/step - loss: 0.6801 - mean_absolute_error: 0.6801 - val_loss: 0.7106 - val_mean_absolute_error: 0.7106\n",
      "Epoch 36/80\n",
      "60/60 [==============================] - 0s 836us/step - loss: 0.6796 - mean_absolute_error: 0.6796 - val_loss: 0.7096 - val_mean_absolute_error: 0.7096\n",
      "Epoch 37/80\n",
      "60/60 [==============================] - 0s 749us/step - loss: 0.6785 - mean_absolute_error: 0.6785 - val_loss: 0.7073 - val_mean_absolute_error: 0.7073\n",
      "Epoch 38/80\n",
      "60/60 [==============================] - 0s 703us/step - loss: 0.6776 - mean_absolute_error: 0.6776 - val_loss: 0.7072 - val_mean_absolute_error: 0.7072\n",
      "Epoch 39/80\n",
      "60/60 [==============================] - 0s 666us/step - loss: 0.6765 - mean_absolute_error: 0.6765 - val_loss: 0.7080 - val_mean_absolute_error: 0.7080\n",
      "Epoch 40/80\n",
      "60/60 [==============================] - 0s 716us/step - loss: 0.6759 - mean_absolute_error: 0.6759 - val_loss: 0.7069 - val_mean_absolute_error: 0.7069\n",
      "Epoch 41/80\n",
      "60/60 [==============================] - 0s 703us/step - loss: 0.6746 - mean_absolute_error: 0.6746 - val_loss: 0.7069 - val_mean_absolute_error: 0.7069\n",
      "Epoch 42/80\n",
      "60/60 [==============================] - 0s 653us/step - loss: 0.6736 - mean_absolute_error: 0.6736 - val_loss: 0.7049 - val_mean_absolute_error: 0.7049\n",
      "Epoch 43/80\n",
      "60/60 [==============================] - 0s 657us/step - loss: 0.6726 - mean_absolute_error: 0.6726 - val_loss: 0.7063 - val_mean_absolute_error: 0.7063\n",
      "Epoch 44/80\n",
      "60/60 [==============================] - 0s 665us/step - loss: 0.6721 - mean_absolute_error: 0.6721 - val_loss: 0.7043 - val_mean_absolute_error: 0.7043\n",
      "Epoch 45/80\n",
      "60/60 [==============================] - 0s 681us/step - loss: 0.6711 - mean_absolute_error: 0.6711 - val_loss: 0.7066 - val_mean_absolute_error: 0.7066\n",
      "Epoch 46/80\n",
      "60/60 [==============================] - 0s 803us/step - loss: 0.6703 - mean_absolute_error: 0.6703 - val_loss: 0.7015 - val_mean_absolute_error: 0.7015\n",
      "Epoch 47/80\n",
      "60/60 [==============================] - 0s 640us/step - loss: 0.6691 - mean_absolute_error: 0.6691 - val_loss: 0.7018 - val_mean_absolute_error: 0.7018\n",
      "Epoch 48/80\n",
      "60/60 [==============================] - 0s 648us/step - loss: 0.6675 - mean_absolute_error: 0.6675 - val_loss: 0.7000 - val_mean_absolute_error: 0.7000\n",
      "Epoch 49/80\n",
      "60/60 [==============================] - 0s 740us/step - loss: 0.6667 - mean_absolute_error: 0.6667 - val_loss: 0.7009 - val_mean_absolute_error: 0.7009\n",
      "Epoch 50/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 800us/step - loss: 0.6661 - mean_absolute_error: 0.6661 - val_loss: 0.7002 - val_mean_absolute_error: 0.7002\n",
      "Epoch 51/80\n",
      "60/60 [==============================] - 0s 788us/step - loss: 0.6650 - mean_absolute_error: 0.6650 - val_loss: 0.7018 - val_mean_absolute_error: 0.7018\n",
      "Epoch 52/80\n",
      "60/60 [==============================] - 0s 787us/step - loss: 0.6641 - mean_absolute_error: 0.6641 - val_loss: 0.7033 - val_mean_absolute_error: 0.7033\n",
      "Epoch 53/80\n",
      "60/60 [==============================] - 0s 759us/step - loss: 0.6638 - mean_absolute_error: 0.6638 - val_loss: 0.6994 - val_mean_absolute_error: 0.6994\n",
      "Epoch 54/80\n",
      "60/60 [==============================] - 0s 644us/step - loss: 0.6621 - mean_absolute_error: 0.6621 - val_loss: 0.6972 - val_mean_absolute_error: 0.6972\n",
      "Epoch 55/80\n",
      "60/60 [==============================] - 0s 648us/step - loss: 0.6618 - mean_absolute_error: 0.6618 - val_loss: 0.6980 - val_mean_absolute_error: 0.6980\n",
      "Epoch 56/80\n",
      "60/60 [==============================] - 0s 648us/step - loss: 0.6607 - mean_absolute_error: 0.6607 - val_loss: 0.6961 - val_mean_absolute_error: 0.6961\n",
      "Epoch 57/80\n",
      "60/60 [==============================] - 0s 637us/step - loss: 0.6599 - mean_absolute_error: 0.6599 - val_loss: 0.6969 - val_mean_absolute_error: 0.6969\n",
      "Epoch 58/80\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.6589 - mean_absolute_error: 0.6589 - val_loss: 0.6971 - val_mean_absolute_error: 0.6971\n",
      "Epoch 59/80\n",
      "60/60 [==============================] - 0s 770us/step - loss: 0.6580 - mean_absolute_error: 0.6580 - val_loss: 0.6962 - val_mean_absolute_error: 0.6962\n",
      "Epoch 60/80\n",
      "60/60 [==============================] - 0s 742us/step - loss: 0.6571 - mean_absolute_error: 0.6571 - val_loss: 0.6951 - val_mean_absolute_error: 0.6951\n",
      "Epoch 61/80\n",
      "60/60 [==============================] - 0s 706us/step - loss: 0.6559 - mean_absolute_error: 0.6559 - val_loss: 0.6963 - val_mean_absolute_error: 0.6963\n",
      "Epoch 62/80\n",
      "60/60 [==============================] - 0s 648us/step - loss: 0.6557 - mean_absolute_error: 0.6557 - val_loss: 0.6968 - val_mean_absolute_error: 0.6968\n",
      "Epoch 63/80\n",
      "60/60 [==============================] - 0s 636us/step - loss: 0.6543 - mean_absolute_error: 0.6543 - val_loss: 0.6945 - val_mean_absolute_error: 0.6945\n",
      "Epoch 64/80\n",
      "60/60 [==============================] - 0s 637us/step - loss: 0.6536 - mean_absolute_error: 0.6536 - val_loss: 0.6960 - val_mean_absolute_error: 0.6960\n",
      "Epoch 65/80\n",
      "60/60 [==============================] - 0s 627us/step - loss: 0.6533 - mean_absolute_error: 0.6533 - val_loss: 0.6952 - val_mean_absolute_error: 0.6952\n",
      "Epoch 66/80\n",
      "60/60 [==============================] - 0s 641us/step - loss: 0.6522 - mean_absolute_error: 0.6522 - val_loss: 0.6935 - val_mean_absolute_error: 0.6935\n",
      "Epoch 67/80\n",
      "60/60 [==============================] - 0s 647us/step - loss: 0.6514 - mean_absolute_error: 0.6514 - val_loss: 0.6954 - val_mean_absolute_error: 0.6954\n",
      "Epoch 68/80\n",
      "60/60 [==============================] - 0s 652us/step - loss: 0.6503 - mean_absolute_error: 0.6503 - val_loss: 0.6949 - val_mean_absolute_error: 0.6949\n",
      "Epoch 69/80\n",
      "60/60 [==============================] - 0s 657us/step - loss: 0.6498 - mean_absolute_error: 0.6498 - val_loss: 0.6932 - val_mean_absolute_error: 0.6932\n",
      "Epoch 70/80\n",
      "60/60 [==============================] - 0s 649us/step - loss: 0.6489 - mean_absolute_error: 0.6489 - val_loss: 0.6938 - val_mean_absolute_error: 0.6938\n",
      "Epoch 71/80\n",
      "60/60 [==============================] - 0s 645us/step - loss: 0.6484 - mean_absolute_error: 0.6484 - val_loss: 0.6927 - val_mean_absolute_error: 0.6927\n",
      "Epoch 72/80\n",
      "60/60 [==============================] - 0s 637us/step - loss: 0.6470 - mean_absolute_error: 0.6470 - val_loss: 0.6956 - val_mean_absolute_error: 0.6956\n",
      "Epoch 73/80\n",
      "60/60 [==============================] - 0s 658us/step - loss: 0.6458 - mean_absolute_error: 0.6458 - val_loss: 0.6926 - val_mean_absolute_error: 0.6926\n",
      "Epoch 74/80\n",
      "60/60 [==============================] - 0s 640us/step - loss: 0.6462 - mean_absolute_error: 0.6462 - val_loss: 0.6918 - val_mean_absolute_error: 0.6918\n",
      "Epoch 75/80\n",
      "60/60 [==============================] - 0s 663us/step - loss: 0.6448 - mean_absolute_error: 0.6448 - val_loss: 0.6907 - val_mean_absolute_error: 0.6907\n",
      "Epoch 76/80\n",
      "60/60 [==============================] - 0s 652us/step - loss: 0.6437 - mean_absolute_error: 0.6437 - val_loss: 0.6906 - val_mean_absolute_error: 0.6906\n",
      "Epoch 77/80\n",
      "60/60 [==============================] - 0s 653us/step - loss: 0.6429 - mean_absolute_error: 0.6429 - val_loss: 0.6927 - val_mean_absolute_error: 0.6927\n",
      "Epoch 78/80\n",
      "60/60 [==============================] - 0s 660us/step - loss: 0.6426 - mean_absolute_error: 0.6426 - val_loss: 0.6916 - val_mean_absolute_error: 0.6916\n",
      "Epoch 79/80\n",
      "60/60 [==============================] - 0s 647us/step - loss: 0.6416 - mean_absolute_error: 0.6416 - val_loss: 0.6904 - val_mean_absolute_error: 0.6904\n",
      "Epoch 80/80\n",
      "60/60 [==============================] - 0s 667us/step - loss: 0.6403 - mean_absolute_error: 0.6403 - val_loss: 0.6914 - val_mean_absolute_error: 0.6914\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    batch_size=64,\n",
    "    epochs=80,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(X_test, Y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20e32481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 318us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6373227621616989"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_train, model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "030a89bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 366us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6914147674234612"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_test, model.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
