{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "008a189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05eb6a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'epochs': 200,\n",
    "    'test_size': 0.2,\n",
    "    'random_state': 1337,\n",
    "    'validation_split': 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2723cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/qsc_out.random_scan_nfp2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd4eb2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.115912</td>\n",
       "      <td>-0.207162</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.012060</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>-0.736734</td>\n",
       "      <td>0.012462</td>\n",
       "      <td>0.783335</td>\n",
       "      <td>0.278748</td>\n",
       "      <td>0.497138</td>\n",
       "      <td>0.645087</td>\n",
       "      <td>0.926717</td>\n",
       "      <td>1.717088</td>\n",
       "      <td>0.338459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.081966</td>\n",
       "      <td>-0.182033</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.010903</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.755056</td>\n",
       "      <td>0.031954</td>\n",
       "      <td>1.379462</td>\n",
       "      <td>0.284927</td>\n",
       "      <td>0.386816</td>\n",
       "      <td>0.493242</td>\n",
       "      <td>0.881144</td>\n",
       "      <td>1.562226</td>\n",
       "      <td>0.326036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.098121</td>\n",
       "      <td>0.188199</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>-0.010709</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>-0.641071</td>\n",
       "      <td>0.060675</td>\n",
       "      <td>1.124535</td>\n",
       "      <td>0.342645</td>\n",
       "      <td>0.523383</td>\n",
       "      <td>0.639508</td>\n",
       "      <td>0.869696</td>\n",
       "      <td>1.574066</td>\n",
       "      <td>0.331869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.077109</td>\n",
       "      <td>-0.206706</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.006428</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>-0.000304</td>\n",
       "      <td>-0.868233</td>\n",
       "      <td>-0.092663</td>\n",
       "      <td>1.205836</td>\n",
       "      <td>0.265378</td>\n",
       "      <td>0.541464</td>\n",
       "      <td>0.512058</td>\n",
       "      <td>0.907885</td>\n",
       "      <td>1.711111</td>\n",
       "      <td>0.324205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.082828</td>\n",
       "      <td>0.221897</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>-0.008468</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>-0.758676</td>\n",
       "      <td>-0.317667</td>\n",
       "      <td>1.026909</td>\n",
       "      <td>0.273752</td>\n",
       "      <td>0.751935</td>\n",
       "      <td>0.643160</td>\n",
       "      <td>0.944501</td>\n",
       "      <td>1.518423</td>\n",
       "      <td>0.326940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6        x7   \n",
       "0 -0.115912 -0.207162  0.001411  0.012060  0.000871 -0.000108 -0.736734  \\\n",
       "1 -0.081966 -0.182033  0.001298  0.010903  0.000813 -0.000155 -0.755056   \n",
       "2 -0.098121  0.188199  0.001285 -0.010709  0.000807  0.000152 -0.641071   \n",
       "3 -0.077109 -0.206706  0.001522  0.006428  0.000926 -0.000304 -0.868233   \n",
       "4 -0.082828  0.221897  0.000230 -0.008468  0.000198  0.000174 -0.758676   \n",
       "\n",
       "         x8        y0        y1        y2        y3        y4        y5   \n",
       "0  0.012462  0.783335  0.278748  0.497138  0.645087  0.926717  1.717088  \\\n",
       "1  0.031954  1.379462  0.284927  0.386816  0.493242  0.881144  1.562226   \n",
       "2  0.060675  1.124535  0.342645  0.523383  0.639508  0.869696  1.574066   \n",
       "3 -0.092663  1.205836  0.265378  0.541464  0.512058  0.907885  1.711111   \n",
       "4 -0.317667  1.026909  0.273752  0.751935  0.643160  0.944501  1.518423   \n",
       "\n",
       "         y6  \n",
       "0  0.338459  \n",
       "1  0.326036  \n",
       "2  0.331869  \n",
       "3  0.324205  \n",
       "4  0.326940  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5dc7fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4796, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de5c3f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = [col for col in df.columns if col.startswith('x')]\n",
    "y_columns = [col for col in df.columns if col.startswith('y')]\n",
    "\n",
    "## ACTUALLY SOLVING THE INVERSE PROBLEM\n",
    "Y = df[x_columns].values\n",
    "X = df[y_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d0a510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_train, X_test, Y_train, Y_test, params):\n",
    "    scaler_x = StandardScaler().fit(X_train)\n",
    "    scaler_y = StandardScaler().fit(Y_train)\n",
    "    X_train = scaler_x.transform(X_train)\n",
    "    X_test = scaler_x.transform(X_test)\n",
    "    Y_train = scaler_y.transform(Y_train)\n",
    "    Y_test = scaler_y.transform(Y_test)\n",
    "\n",
    "    input_shape = X_train.shape[1]\n",
    "    \n",
    "    output_shape = Y_train.shape[1]\n",
    "    return X_train, X_test, Y_train, Y_test, input_shape, output_shape, scaler_x, scaler_y\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=params['test_size'], \n",
    "                                                    random_state=params['random_state'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test, input_shape, output_shape, scaler_x, scaler_y = preprocess_data(X_train, X_test, Y_train, Y_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c71932d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-4.01657042e-15,  4.72944589e-15,  2.50063555e-15, -3.41465936e-15,\n",
       "        -5.97028509e-15, -9.70058815e-15, -3.51141604e-14]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.mean(axis=0), X_train.std(axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9405c34",
   "metadata": {},
   "source": [
    "## Appears to be drift, perhaps the sample is not big enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "452beb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.03647091, 0.05036899, 0.0240539 , 0.01615513, 0.02262298,\n",
       "        0.069791  , 0.00742891]),\n",
       " array([1.04363768, 1.03365372, 1.03354061, 1.01573765, 1.04018519,\n",
       "        0.98510014, 1.0395029 ]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.mean(axis=0), X_test.std(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d951bb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.83484230e-17, -2.05489663e-17,  1.57677139e-16,  1.15291278e-16,\n",
       "        -6.44832351e-17, -3.98823600e-17,  2.63764795e-16,  9.18495381e-16]),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.mean(axis=0), Y_train.std(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4915715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.02525043,  0.00971201,  0.01397497,  0.04719729,  0.01297527,\n",
       "        -0.02875165, -0.00224075,  0.00415783]),\n",
       " array([1.00535971, 1.00234493, 1.04188367, 1.01245292, 1.03768115,\n",
       "        0.98217117, 1.014723  , 1.01594242]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.mean(axis=0), Y_test.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e83198a",
   "metadata": {},
   "source": [
    "## Dummy regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18aa56f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bcc393e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16],\n",
       "       [ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16],\n",
       "       [ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16],\n",
       "       ...,\n",
       "       [ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16],\n",
       "       [ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16],\n",
       "       [ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = MultiOutputRegressor(DummyRegressor(strategy=\"mean\")).fit(X_train, Y_train)\n",
    "regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67c75d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000007"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(Y_train, regr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8c5bd10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0291802816467932"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(Y_test, regr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1d3829",
   "metadata": {},
   "source": [
    "## Train a linear regression for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa2ad815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15676934,  0.04012469, -0.12659159, ...,  0.06290221,\n",
       "        -0.40890284,  0.03899315],\n",
       "       [ 0.098538  ,  0.02856683, -0.02685268, ..., -0.01454209,\n",
       "        -0.16032767,  0.49703159],\n",
       "       [-0.17443072,  0.00250346,  0.13851425, ..., -0.0678374 ,\n",
       "        -0.04978863,  0.27261235],\n",
       "       ...,\n",
       "       [ 0.02097198,  0.03903598,  0.03713012, ..., -0.02695103,\n",
       "        -0.3743756 ,  0.34646245],\n",
       "       [-0.26866067,  0.03050944,  0.16463002, ..., -0.05755192,\n",
       "        -0.21087286,  0.37635694],\n",
       "       [ 0.33351338,  0.08189727, -0.20413084, ...,  0.07795407,\n",
       "        -0.54412842,  0.25056948]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = MultiOutputRegressor(Ridge(random_state=123)).fit(X_train, Y_train)\n",
    "regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b25a55ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9248479543380279"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(Y_train, regr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2e7e2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.955048583856655"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(Y_test, regr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1993f23d",
   "metadata": {},
   "source": [
    "## Simplest neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efb7c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a32e1db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 8), dtype=float32, numpy=\n",
       "array([[-0.03347746, -0.00366957, -0.02873048, -0.11977457,  0.03875859,\n",
       "         0.07086838,  0.02795618,  0.0190305 ]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Sequential model with 3 layers\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(input_shape, activation=\"relu\", name=\"layer_in\"),\n",
    "        layers.Dense(128, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(64, activation=\"relu\", name=\"layer3\"),\n",
    "        layers.Dense(output_shape, name=\"layer_out\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model(X_train[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1138d39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer_in (Dense)            (1, 7)                    56        \n",
      "                                                                 \n",
      " layer2 (Dense)              (1, 128)                  1024      \n",
      "                                                                 \n",
      " layer3 (Dense)              (1, 64)                   8256      \n",
      "                                                                 \n",
      " layer_out (Dense)           (1, 8)                    520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9856 (38.50 KB)\n",
      "Trainable params: 9856 (38.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02976d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.MeanSquaredError()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44eb303e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/80\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.9635 - mean_squared_error: 0.9635 - val_loss: 0.9672 - val_mean_squared_error: 0.9672\n",
      "Epoch 2/80\n",
      "60/60 [==============================] - 0s 730us/step - loss: 0.9306 - mean_squared_error: 0.9306 - val_loss: 0.9470 - val_mean_squared_error: 0.9470\n",
      "Epoch 3/80\n",
      "60/60 [==============================] - 0s 705us/step - loss: 0.9143 - mean_squared_error: 0.9143 - val_loss: 0.9336 - val_mean_squared_error: 0.9336\n",
      "Epoch 4/80\n",
      "60/60 [==============================] - 0s 682us/step - loss: 0.9020 - mean_squared_error: 0.9020 - val_loss: 0.9231 - val_mean_squared_error: 0.9231\n",
      "Epoch 5/80\n",
      "60/60 [==============================] - 0s 696us/step - loss: 0.8922 - mean_squared_error: 0.8922 - val_loss: 0.9173 - val_mean_squared_error: 0.9173\n",
      "Epoch 6/80\n",
      "60/60 [==============================] - 0s 698us/step - loss: 0.8831 - mean_squared_error: 0.8831 - val_loss: 0.9123 - val_mean_squared_error: 0.9123\n",
      "Epoch 7/80\n",
      "60/60 [==============================] - 0s 686us/step - loss: 0.8774 - mean_squared_error: 0.8774 - val_loss: 0.9069 - val_mean_squared_error: 0.9069\n",
      "Epoch 8/80\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.8724 - mean_squared_error: 0.8724 - val_loss: 0.9063 - val_mean_squared_error: 0.9063\n",
      "Epoch 9/80\n",
      "60/60 [==============================] - 0s 655us/step - loss: 0.8688 - mean_squared_error: 0.8688 - val_loss: 0.9016 - val_mean_squared_error: 0.9016\n",
      "Epoch 10/80\n",
      "60/60 [==============================] - 0s 662us/step - loss: 0.8630 - mean_squared_error: 0.8630 - val_loss: 0.8993 - val_mean_squared_error: 0.8993\n",
      "Epoch 11/80\n",
      "60/60 [==============================] - 0s 665us/step - loss: 0.8605 - mean_squared_error: 0.8605 - val_loss: 0.8952 - val_mean_squared_error: 0.8952\n",
      "Epoch 12/80\n",
      "60/60 [==============================] - 0s 660us/step - loss: 0.8555 - mean_squared_error: 0.8555 - val_loss: 0.8950 - val_mean_squared_error: 0.8950\n",
      "Epoch 13/80\n",
      "60/60 [==============================] - 0s 683us/step - loss: 0.8526 - mean_squared_error: 0.8526 - val_loss: 0.8907 - val_mean_squared_error: 0.8907\n",
      "Epoch 14/80\n",
      "60/60 [==============================] - 0s 660us/step - loss: 0.8498 - mean_squared_error: 0.8498 - val_loss: 0.8942 - val_mean_squared_error: 0.8942\n",
      "Epoch 15/80\n",
      "60/60 [==============================] - 0s 816us/step - loss: 0.8484 - mean_squared_error: 0.8484 - val_loss: 0.8902 - val_mean_squared_error: 0.8902\n",
      "Epoch 16/80\n",
      "60/60 [==============================] - 0s 668us/step - loss: 0.8450 - mean_squared_error: 0.8450 - val_loss: 0.8912 - val_mean_squared_error: 0.8912\n",
      "Epoch 17/80\n",
      "60/60 [==============================] - 0s 661us/step - loss: 0.8421 - mean_squared_error: 0.8421 - val_loss: 0.8849 - val_mean_squared_error: 0.8849\n",
      "Epoch 18/80\n",
      "60/60 [==============================] - 0s 685us/step - loss: 0.8400 - mean_squared_error: 0.8400 - val_loss: 0.8896 - val_mean_squared_error: 0.8896\n",
      "Epoch 19/80\n",
      "60/60 [==============================] - 0s 660us/step - loss: 0.8380 - mean_squared_error: 0.8380 - val_loss: 0.8842 - val_mean_squared_error: 0.8842\n",
      "Epoch 20/80\n",
      "60/60 [==============================] - 0s 672us/step - loss: 0.8359 - mean_squared_error: 0.8359 - val_loss: 0.8815 - val_mean_squared_error: 0.8815\n",
      "Epoch 21/80\n",
      "60/60 [==============================] - 0s 679us/step - loss: 0.8337 - mean_squared_error: 0.8337 - val_loss: 0.8823 - val_mean_squared_error: 0.8823\n",
      "Epoch 22/80\n",
      "60/60 [==============================] - 0s 671us/step - loss: 0.8304 - mean_squared_error: 0.8304 - val_loss: 0.8804 - val_mean_squared_error: 0.8804\n",
      "Epoch 23/80\n",
      "60/60 [==============================] - 0s 701us/step - loss: 0.8294 - mean_squared_error: 0.8294 - val_loss: 0.8793 - val_mean_squared_error: 0.8793\n",
      "Epoch 24/80\n",
      "60/60 [==============================] - 0s 679us/step - loss: 0.8266 - mean_squared_error: 0.8266 - val_loss: 0.8801 - val_mean_squared_error: 0.8801\n",
      "Epoch 25/80\n",
      "60/60 [==============================] - 0s 664us/step - loss: 0.8256 - mean_squared_error: 0.8256 - val_loss: 0.8875 - val_mean_squared_error: 0.8875\n",
      "Epoch 26/80\n",
      "60/60 [==============================] - 0s 668us/step - loss: 0.8231 - mean_squared_error: 0.8231 - val_loss: 0.8818 - val_mean_squared_error: 0.8818\n",
      "Epoch 27/80\n",
      "60/60 [==============================] - 0s 665us/step - loss: 0.8225 - mean_squared_error: 0.8225 - val_loss: 0.8793 - val_mean_squared_error: 0.8793\n",
      "Epoch 28/80\n",
      "60/60 [==============================] - 0s 653us/step - loss: 0.8204 - mean_squared_error: 0.8204 - val_loss: 0.8786 - val_mean_squared_error: 0.8786\n",
      "Epoch 29/80\n",
      "60/60 [==============================] - 0s 670us/step - loss: 0.8185 - mean_squared_error: 0.8185 - val_loss: 0.8766 - val_mean_squared_error: 0.8766\n",
      "Epoch 30/80\n",
      "60/60 [==============================] - 0s 668us/step - loss: 0.8170 - mean_squared_error: 0.8170 - val_loss: 0.8800 - val_mean_squared_error: 0.8800\n",
      "Epoch 31/80\n",
      "60/60 [==============================] - 0s 674us/step - loss: 0.8148 - mean_squared_error: 0.8148 - val_loss: 0.8796 - val_mean_squared_error: 0.8796\n",
      "Epoch 32/80\n",
      "60/60 [==============================] - 0s 661us/step - loss: 0.8141 - mean_squared_error: 0.8141 - val_loss: 0.8816 - val_mean_squared_error: 0.8816\n",
      "Epoch 33/80\n",
      "60/60 [==============================] - 0s 668us/step - loss: 0.8127 - mean_squared_error: 0.8127 - val_loss: 0.8766 - val_mean_squared_error: 0.8766\n",
      "Epoch 34/80\n",
      "60/60 [==============================] - 0s 673us/step - loss: 0.8103 - mean_squared_error: 0.8103 - val_loss: 0.8815 - val_mean_squared_error: 0.8815\n",
      "Epoch 35/80\n",
      "60/60 [==============================] - 0s 679us/step - loss: 0.8092 - mean_squared_error: 0.8092 - val_loss: 0.8795 - val_mean_squared_error: 0.8795\n",
      "Epoch 36/80\n",
      "60/60 [==============================] - 0s 668us/step - loss: 0.8088 - mean_squared_error: 0.8088 - val_loss: 0.8772 - val_mean_squared_error: 0.8772\n",
      "Epoch 37/80\n",
      "60/60 [==============================] - 0s 668us/step - loss: 0.8067 - mean_squared_error: 0.8067 - val_loss: 0.8767 - val_mean_squared_error: 0.8767\n",
      "Epoch 38/80\n",
      "60/60 [==============================] - 0s 645us/step - loss: 0.8053 - mean_squared_error: 0.8053 - val_loss: 0.8734 - val_mean_squared_error: 0.8734\n",
      "Epoch 39/80\n",
      "60/60 [==============================] - 0s 661us/step - loss: 0.8038 - mean_squared_error: 0.8038 - val_loss: 0.8799 - val_mean_squared_error: 0.8799\n",
      "Epoch 40/80\n",
      "60/60 [==============================] - 0s 650us/step - loss: 0.8030 - mean_squared_error: 0.8030 - val_loss: 0.8760 - val_mean_squared_error: 0.8760\n",
      "Epoch 41/80\n",
      "60/60 [==============================] - 0s 642us/step - loss: 0.8020 - mean_squared_error: 0.8020 - val_loss: 0.8760 - val_mean_squared_error: 0.8760\n",
      "Epoch 42/80\n",
      "60/60 [==============================] - 0s 655us/step - loss: 0.8011 - mean_squared_error: 0.8011 - val_loss: 0.8758 - val_mean_squared_error: 0.8758\n",
      "Epoch 43/80\n",
      "60/60 [==============================] - 0s 639us/step - loss: 0.8001 - mean_squared_error: 0.8001 - val_loss: 0.8723 - val_mean_squared_error: 0.8723\n",
      "Epoch 44/80\n",
      "60/60 [==============================] - 0s 655us/step - loss: 0.7983 - mean_squared_error: 0.7983 - val_loss: 0.8729 - val_mean_squared_error: 0.8729\n",
      "Epoch 45/80\n",
      "60/60 [==============================] - 0s 666us/step - loss: 0.7972 - mean_squared_error: 0.7972 - val_loss: 0.8728 - val_mean_squared_error: 0.8728\n",
      "Epoch 46/80\n",
      "60/60 [==============================] - 0s 659us/step - loss: 0.7964 - mean_squared_error: 0.7964 - val_loss: 0.8736 - val_mean_squared_error: 0.8736\n",
      "Epoch 47/80\n",
      "60/60 [==============================] - 0s 672us/step - loss: 0.7938 - mean_squared_error: 0.7938 - val_loss: 0.8726 - val_mean_squared_error: 0.8726\n",
      "Epoch 48/80\n",
      "60/60 [==============================] - 0s 653us/step - loss: 0.7931 - mean_squared_error: 0.7931 - val_loss: 0.8774 - val_mean_squared_error: 0.8774\n",
      "Epoch 49/80\n",
      "60/60 [==============================] - 0s 657us/step - loss: 0.7918 - mean_squared_error: 0.7918 - val_loss: 0.8755 - val_mean_squared_error: 0.8755\n",
      "Epoch 50/80\n",
      "60/60 [==============================] - 0s 667us/step - loss: 0.7913 - mean_squared_error: 0.7913 - val_loss: 0.8763 - val_mean_squared_error: 0.8763\n",
      "Epoch 51/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 656us/step - loss: 0.7904 - mean_squared_error: 0.7904 - val_loss: 0.8683 - val_mean_squared_error: 0.8683\n",
      "Epoch 52/80\n",
      "60/60 [==============================] - 0s 655us/step - loss: 0.7888 - mean_squared_error: 0.7888 - val_loss: 0.8742 - val_mean_squared_error: 0.8742\n",
      "Epoch 53/80\n",
      "60/60 [==============================] - 0s 633us/step - loss: 0.7871 - mean_squared_error: 0.7871 - val_loss: 0.8725 - val_mean_squared_error: 0.8725\n",
      "Epoch 54/80\n",
      "60/60 [==============================] - 0s 637us/step - loss: 0.7865 - mean_squared_error: 0.7865 - val_loss: 0.8713 - val_mean_squared_error: 0.8713\n",
      "Epoch 55/80\n",
      "60/60 [==============================] - 0s 647us/step - loss: 0.7857 - mean_squared_error: 0.7857 - val_loss: 0.8739 - val_mean_squared_error: 0.8739\n",
      "Epoch 56/80\n",
      "60/60 [==============================] - 0s 641us/step - loss: 0.7840 - mean_squared_error: 0.7840 - val_loss: 0.8713 - val_mean_squared_error: 0.8713\n",
      "Epoch 57/80\n",
      "60/60 [==============================] - 0s 642us/step - loss: 0.7834 - mean_squared_error: 0.7834 - val_loss: 0.8717 - val_mean_squared_error: 0.8717\n",
      "Epoch 58/80\n",
      "60/60 [==============================] - 0s 653us/step - loss: 0.7808 - mean_squared_error: 0.7808 - val_loss: 0.8686 - val_mean_squared_error: 0.8686\n",
      "Epoch 59/80\n",
      "60/60 [==============================] - 0s 643us/step - loss: 0.7812 - mean_squared_error: 0.7812 - val_loss: 0.8708 - val_mean_squared_error: 0.8708\n",
      "Epoch 60/80\n",
      "60/60 [==============================] - 0s 648us/step - loss: 0.7793 - mean_squared_error: 0.7793 - val_loss: 0.8656 - val_mean_squared_error: 0.8656\n",
      "Epoch 61/80\n",
      "60/60 [==============================] - 0s 646us/step - loss: 0.7780 - mean_squared_error: 0.7780 - val_loss: 0.8705 - val_mean_squared_error: 0.8705\n",
      "Epoch 62/80\n",
      "60/60 [==============================] - 0s 650us/step - loss: 0.7778 - mean_squared_error: 0.7778 - val_loss: 0.8712 - val_mean_squared_error: 0.8712\n",
      "Epoch 63/80\n",
      "60/60 [==============================] - 0s 645us/step - loss: 0.7762 - mean_squared_error: 0.7762 - val_loss: 0.8682 - val_mean_squared_error: 0.8682\n",
      "Epoch 64/80\n",
      "60/60 [==============================] - 0s 640us/step - loss: 0.7764 - mean_squared_error: 0.7764 - val_loss: 0.8701 - val_mean_squared_error: 0.8701\n",
      "Epoch 65/80\n",
      "60/60 [==============================] - 0s 643us/step - loss: 0.7739 - mean_squared_error: 0.7739 - val_loss: 0.8772 - val_mean_squared_error: 0.8772\n",
      "Epoch 66/80\n",
      "60/60 [==============================] - 0s 645us/step - loss: 0.7740 - mean_squared_error: 0.7740 - val_loss: 0.8672 - val_mean_squared_error: 0.8672\n",
      "Epoch 67/80\n",
      "60/60 [==============================] - 0s 641us/step - loss: 0.7724 - mean_squared_error: 0.7724 - val_loss: 0.8688 - val_mean_squared_error: 0.8688\n",
      "Epoch 68/80\n",
      "60/60 [==============================] - 0s 649us/step - loss: 0.7709 - mean_squared_error: 0.7709 - val_loss: 0.8701 - val_mean_squared_error: 0.8701\n",
      "Epoch 69/80\n",
      "60/60 [==============================] - 0s 633us/step - loss: 0.7693 - mean_squared_error: 0.7693 - val_loss: 0.8686 - val_mean_squared_error: 0.8686\n",
      "Epoch 70/80\n",
      "60/60 [==============================] - 0s 646us/step - loss: 0.7684 - mean_squared_error: 0.7684 - val_loss: 0.8784 - val_mean_squared_error: 0.8784\n",
      "Epoch 71/80\n",
      "60/60 [==============================] - 0s 639us/step - loss: 0.7682 - mean_squared_error: 0.7682 - val_loss: 0.8703 - val_mean_squared_error: 0.8703\n",
      "Epoch 72/80\n",
      "60/60 [==============================] - 0s 638us/step - loss: 0.7657 - mean_squared_error: 0.7657 - val_loss: 0.8714 - val_mean_squared_error: 0.8714\n",
      "Epoch 73/80\n",
      "60/60 [==============================] - 0s 644us/step - loss: 0.7664 - mean_squared_error: 0.7664 - val_loss: 0.8656 - val_mean_squared_error: 0.8656\n",
      "Epoch 74/80\n",
      "60/60 [==============================] - 0s 639us/step - loss: 0.7655 - mean_squared_error: 0.7655 - val_loss: 0.8670 - val_mean_squared_error: 0.8670\n",
      "Epoch 75/80\n",
      "60/60 [==============================] - 0s 646us/step - loss: 0.7638 - mean_squared_error: 0.7638 - val_loss: 0.8747 - val_mean_squared_error: 0.8747\n",
      "Epoch 76/80\n",
      "60/60 [==============================] - 0s 651us/step - loss: 0.7637 - mean_squared_error: 0.7637 - val_loss: 0.8670 - val_mean_squared_error: 0.8670\n",
      "Epoch 77/80\n",
      "60/60 [==============================] - 0s 655us/step - loss: 0.7627 - mean_squared_error: 0.7627 - val_loss: 0.8652 - val_mean_squared_error: 0.8652\n",
      "Epoch 78/80\n",
      "60/60 [==============================] - 0s 649us/step - loss: 0.7611 - mean_squared_error: 0.7611 - val_loss: 0.8663 - val_mean_squared_error: 0.8663\n",
      "Epoch 79/80\n",
      "60/60 [==============================] - 0s 656us/step - loss: 0.7594 - mean_squared_error: 0.7594 - val_loss: 0.8673 - val_mean_squared_error: 0.8673\n",
      "Epoch 80/80\n",
      "60/60 [==============================] - 0s 642us/step - loss: 0.7595 - mean_squared_error: 0.7595 - val_loss: 0.8704 - val_mean_squared_error: 0.8704\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    batch_size=64,\n",
    "    epochs=80,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(X_test, Y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d578b468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 372us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7476152937632317"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(Y_train, model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c98a1e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 437us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8704384652711461"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(Y_test, model.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
