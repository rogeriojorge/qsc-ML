{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b50697e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30346186",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'epochs': 200,\n",
    "    'test_size': 0.2,\n",
    "    'random_state': 1337,\n",
    "    'validation_split': 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6776a886",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/qsc_out.random_scan_nfp2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3599d370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.104856</td>\n",
       "      <td>0.197790</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>-0.011792</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>-0.687180</td>\n",
       "      <td>-0.215177</td>\n",
       "      <td>0.948834</td>\n",
       "      <td>0.264545</td>\n",
       "      <td>0.404154</td>\n",
       "      <td>0.631039</td>\n",
       "      <td>0.898928</td>\n",
       "      <td>1.581192</td>\n",
       "      <td>0.334374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.110385</td>\n",
       "      <td>0.188144</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>-0.011358</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>-0.658897</td>\n",
       "      <td>-0.233486</td>\n",
       "      <td>0.930837</td>\n",
       "      <td>0.298531</td>\n",
       "      <td>0.469811</td>\n",
       "      <td>0.639501</td>\n",
       "      <td>0.876879</td>\n",
       "      <td>1.568947</td>\n",
       "      <td>0.336379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.095042</td>\n",
       "      <td>0.132051</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.008909</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>-0.671871</td>\n",
       "      <td>-0.944641</td>\n",
       "      <td>1.526347</td>\n",
       "      <td>0.385624</td>\n",
       "      <td>0.334515</td>\n",
       "      <td>0.468280</td>\n",
       "      <td>0.804239</td>\n",
       "      <td>1.288313</td>\n",
       "      <td>0.331086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.115912</td>\n",
       "      <td>-0.207162</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.012060</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>-0.736734</td>\n",
       "      <td>0.012462</td>\n",
       "      <td>0.783335</td>\n",
       "      <td>0.278748</td>\n",
       "      <td>0.497138</td>\n",
       "      <td>0.645087</td>\n",
       "      <td>0.926717</td>\n",
       "      <td>1.717088</td>\n",
       "      <td>0.338459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.096390</td>\n",
       "      <td>-0.217079</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.010517</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>-0.000126</td>\n",
       "      <td>-0.764525</td>\n",
       "      <td>-0.048433</td>\n",
       "      <td>0.925351</td>\n",
       "      <td>0.272636</td>\n",
       "      <td>0.548743</td>\n",
       "      <td>0.631384</td>\n",
       "      <td>0.941509</td>\n",
       "      <td>1.549327</td>\n",
       "      <td>0.331432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6        x7   \n",
       "0 -0.104856  0.197790  0.001260 -0.011792  0.000794  0.000120 -0.687180  \\\n",
       "1 -0.110385  0.188144  0.001381 -0.011358  0.000855  0.000138 -0.658897   \n",
       "2 -0.095042  0.132051  0.000675 -0.008909  0.000477  0.000348 -0.671871   \n",
       "3 -0.115912 -0.207162  0.001411  0.012060  0.000871 -0.000108 -0.736734   \n",
       "4 -0.096390 -0.217079  0.000933  0.010517  0.000621 -0.000126 -0.764525   \n",
       "\n",
       "         x8        y0        y1        y2        y3        y4        y5   \n",
       "0 -0.215177  0.948834  0.264545  0.404154  0.631039  0.898928  1.581192  \\\n",
       "1 -0.233486  0.930837  0.298531  0.469811  0.639501  0.876879  1.568947   \n",
       "2 -0.944641  1.526347  0.385624  0.334515  0.468280  0.804239  1.288313   \n",
       "3  0.012462  0.783335  0.278748  0.497138  0.645087  0.926717  1.717088   \n",
       "4 -0.048433  0.925351  0.272636  0.548743  0.631384  0.941509  1.549327   \n",
       "\n",
       "         y6  \n",
       "0  0.334374  \n",
       "1  0.336379  \n",
       "2  0.331086  \n",
       "3  0.338459  \n",
       "4  0.331432  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4177caeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGdCAYAAADnrPLBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmfElEQVR4nO3df3RU9Z3/8VcSkgnBDBFofkmACK1AAQNhgVGLgCFZTS0e2VM8pchR1CMNng05X2lYWAT8gYcKSCVIq0jcXVmULbqVUJJpaGBZgtBIzkJQdkW6eJZmWLUQfshkSO73DzZ3GMOvGWYmfMLzcQ5H5t7P3Hnf1xnhde7MDTGWZVkCAAAwVGxHDwAAAHA9KDMAAMBolBkAAGA0ygwAADAaZQYAABiNMgMAAIxGmQEAAEajzAAAAKN16egBIqW1tVXHjh1TcnKyYmJiOnocAABwDSzL0qlTp5SZmanY2Gu75tJpy8yxY8eUlZXV0WMAAIAQfPHFF+rdu/c1re20ZSY5OVnShTCcTmdYjunz+VRVVaX8/HzFx8eH5ZgmIgc/svAjiwvIwY8s/MjC72pZNDU1KSsry/57/Fp02jLT9tGS0+kMa5lJSkqS0+m8qd+M5OBHFn5kcQE5+JGFH1n4XWsWwXxFhC8AAwAAo1FmAACA0SgzAADAaJQZAABgNMoMAAAwGmUGAAAYjTIDAACMRpkBAABGo8wAAACjUWYAAIDRKDMAAMBolBkAAGA0ygwAADAaZQYAABiNMhNG/Uor1K+0oqPHAADgpkKZAQAARqPMAAAAo1FmAACA0SgzAADAaJQZAABgNMoMAAAwGmUGAAAYjTIDAACMRpkBAABGo8wAAACjUWYAAIDRKDMAAMBolBkAAGA0ygwAADAaZSZM+pVWdPQIAADclCgzAADAaJQZAABgNMoMAAAwGmUGAAAYjTIDAACMdl1l5uWXX1ZMTIyKi4vtbefOnVNRUZF69uypW265RZMnT5bH4wl43tGjR1VYWKikpCSlpqbq2Wef1fnz5wPW1NTUaMSIEXI4HBowYIDKy8uvZ9So4s4mAACiJ+Qys3fvXv3qV7/SsGHDArbPnj1bH374oTZu3Kjt27fr2LFjevjhh+39LS0tKiwsVHNzs3bt2qW3335b5eXlWrBggb3myJEjKiws1Pjx41VfX6/i4mI98cQTqqysDHVcAADQSYVUZk6fPq2pU6fqjTfe0K233mpvP3nypNauXavly5drwoQJys3N1bp167Rr1y7t3r1bklRVVaWDBw/qn/7pn5STk6P7779fzz//vMrKytTc3CxJWrNmjbKzs7Vs2TINGjRIs2bN0t/8zd9oxYoVYThlAADQmXQJ5UlFRUUqLCxUXl6eXnjhBXt7XV2dfD6f8vLy7G0DBw5Unz59VFtbqzFjxqi2tlZDhw5VWlqavaagoEAzZ85UQ0ODhg8frtra2oBjtK25+OOsb/N6vfJ6vfbjpqYmSZLP55PP5wvlNNtpO86ljueIsy65tjO6Ug43G7LwI4sLyMGPLPzIwu9qWYSSUdBlZsOGDfr444+1d+/edvsaGxuVkJCglJSUgO1paWlqbGy011xcZNr2t+270pqmpiZ988036tq1a7vXXrJkiRYtWtRue1VVlZKSkq79BK+B2+1ut23pqMDHW7ZsCetr3ogulcPNiiz8yOICcvAjCz+y8LtcFmfPng36WEGVmS+++EJ/+7d/K7fbrcTExKBfLJLmzp2rkpIS+3FTU5OysrKUn58vp9MZltfw+Xxyu92aOHGi4uPjA/YNWRj4fZ4DCwvC8po3oivlcLMhCz+yuIAc/MjCjyz8rpZF2ycrwQiqzNTV1en48eMaMWKEva2lpUU7duzQqlWrVFlZqebmZp04cSLg6ozH41F6erokKT09XXv27Ak4btvdThev+fYdUB6PR06n85JXZSTJ4XDI4XC02x4fHx/2N86ljultiWm3prOLRLamIgs/sriAHPzIwo8s/C6XRSj5BPUF4Pvuu0/79+9XfX29/WvkyJGaOnWq/fv4+HhVV1fbzzl06JCOHj0ql8slSXK5XNq/f7+OHz9ur3G73XI6nRo8eLC95uJjtK1pOwYAAECboK7MJCcna8iQIQHbunXrpp49e9rbZ8yYoZKSEvXo0UNOp1PPPPOMXC6XxowZI0nKz8/X4MGDNW3aNC1dulSNjY2aP3++ioqK7CsrTz/9tFatWqU5c+bo8ccf17Zt2/Tee++pooKf3wIAAAKFdDfTlaxYsUKxsbGaPHmyvF6vCgoKtHr1ant/XFycNm/erJkzZ8rlcqlbt26aPn26Fi9ebK/Jzs5WRUWFZs+erZUrV6p379568803VVDQeb+HAgAAQnPdZaampibgcWJiosrKylRWVnbZ5/Tt2/eqd/uMGzdO+/btu97xAABAJ8e/zQQAAIxGmQEAAEajzAAAAKNRZgAAgNEoMwAAwGiUGQAAYDTKDAAAMBplBgAAGI0yAwAAjEaZAQAARqPMAAAAo1FmAACA0SgzAADAaJQZAABgNMoMAAAwGmUGAAAYjTIDAACMRpkBAABGo8wAAACjUWYAAIDRKDMAAMBolBkAAGA0ygwAADAaZQYAABiNMgMAAIxGmQEAAEajzAAAAKNRZgAAgNEoMwAAwGiUGQAAYDTKDAAAMBplBgAAGI0yAwAAjEaZAQAARqPMAAAAo1FmAACA0SgzAADAaJQZAABgNMoMAAAwGmUGAAAYjTIDAACMRpkBAABGo8wAAACjUWYipF9phfqVVnT0GAAAdHqUGQAAYDTKDAAAMBplBgAAGI0yAwAAjEaZAQAARqPMAAAAo1FmAACA0SgzAADAaJQZAABgNMoMAAAwGmUGAAAYjTIDAACMRpkBAABGo8wAAACjUWYAAIDRKDMAAMBolBkAAGA0ygwAADAaZQYAABiNMgMAAIxGmQEAAEajzAAAAKNRZgAAgNEoMwAAwGiUGQAAYDTKDAAAMBplBgAAGC2oMvP6669r2LBhcjqdcjqdcrlc+t3vfmfvP3funIqKitSzZ0/dcsstmjx5sjweT8Axjh49qsLCQiUlJSk1NVXPPvuszp8/H7CmpqZGI0aMkMPh0IABA1ReXh76GQIAgE4tqDLTu3dvvfzyy6qrq9Mf//hHTZgwQZMmTVJDQ4Mkafbs2frwww+1ceNGbd++XceOHdPDDz9sP7+lpUWFhYVqbm7Wrl279Pbbb6u8vFwLFiyw1xw5ckSFhYUaP3686uvrVVxcrCeeeEKVlZVhOuXw6ldaoX6lFR09BgAAN60uwSx+8MEHAx6/+OKLev3117V792717t1ba9eu1fr16zVhwgRJ0rp16zRo0CDt3r1bY8aMUVVVlQ4ePKjf//73SktLU05Ojp5//nn9/Oc/18KFC5WQkKA1a9YoOztby5YtkyQNGjRIO3fu1IoVK1RQUBCm0wYAAJ1FUGXmYi0tLdq4caPOnDkjl8uluro6+Xw+5eXl2WsGDhyoPn36qLa2VmPGjFFtba2GDh2qtLQ0e01BQYFmzpyphoYGDR8+XLW1tQHHaFtTXFx8xXm8Xq+8Xq/9uKmpSZLk8/nk8/lCPc0Abce5+HiOOOuantOZXCqHmxVZ+JHFBeTgRxZ+ZOF3tSxCySjoMrN//365XC6dO3dOt9xyi95//30NHjxY9fX1SkhIUEpKSsD6tLQ0NTY2SpIaGxsDikzb/rZ9V1rT1NSkb775Rl27dr3kXEuWLNGiRYvaba+qqlJSUlKwp3lFbrfb/v3SUVdeu2XLlrC+9o3k4hxudmThRxYXkIMfWfiRhd/lsjh79mzQxwq6zNxxxx2qr6/XyZMn9S//8i+aPn26tm/fHvQLh9vcuXNVUlJiP25qalJWVpby8/PldDrD8ho+n09ut1sTJ05UfHy8JGnIwit/l+fAws730dilcrhZkYUfWVxADn5k4UcWflfLou2TlWAEXWYSEhI0YMAASVJubq727t2rlStXasqUKWpubtaJEycCrs54PB6lp6dLktLT07Vnz56A47Xd7XTxmm/fAeXxeOR0Oi97VUaSHA6HHA5Hu+3x8fFhf+NcfExvS8xV13ZWkcjWVGThRxYXkIMfWfiRhd/lsggln+v+OTOtra3yer3Kzc1VfHy8qqur7X2HDh3S0aNH5XK5JEkul0v79+/X8ePH7TVut1tOp1ODBw+211x8jLY1bccAAAC4WFBXZubOnav7779fffr00alTp7R+/XrV1NSosrJS3bt314wZM1RSUqIePXrI6XTqmWeekcvl0pgxYyRJ+fn5Gjx4sKZNm6alS5eqsbFR8+fPV1FRkX1V5emnn9aqVas0Z84cPf7449q2bZvee+89VVRw+zMAAGgvqDJz/PhxPfroo/rzn/+s7t27a9iwYaqsrNTEiRMlSStWrFBsbKwmT54sr9ergoICrV692n5+XFycNm/erJkzZ8rlcqlbt26aPn26Fi9ebK/Jzs5WRUWFZs+erZUrV6p379568803uS0bAABcUlBlZu3atVfcn5iYqLKyMpWVlV12Td++fa96h8+4ceO0b9++YEYDAAA3Kf5tJgAAYDTKDAAAMBplBgAAGI0yAwAAjEaZAQAARqPMAAAAo1FmAACA0SgzEdavlJ9cDABAJFFmAACA0SgzAADAaJQZAABgNMoMAAAwGmUGAAAYjTIDAACMRpkBAABGo8wAAACjUWYAAIDRKDMAAMBolBkAAGA0ygwAADAaZQYAABiNMgMAAIxGmQEAAEajzAAAAKNRZgAAgNEoMwAAwGiUGQAAYDTKDAAAMBplBgAAGI0yAwAAjEaZAQAARqPMAAAAo1FmAACA0SgzAADAaJQZAABgNMoMAAAwGmUGAAAYjTIDAACMRpkBAABGo8wAAACjUWYAAIDRKDMAAMBolBkAAGA0ygwAADAaZQYAABiNMgMAAIxGmQEAAEajzAAAAKNRZgAAgNEoMwAAwGiUGQAAYDTKDAAAMBplBgAAGI0yAwAAjEaZAQAARqPMAAAAo1FmAACA0SgzAADAaJSZKOhXWqF+pRUdPQYAAJ0SZQYAABiNMgMAAIxGmQEAAEajzAAAAKNRZgAAgNEoMwAAwGiUGQAAYDTKDAAAMBplBgAAGI0yAwAAjEaZAQAARqPMAAAAowVVZpYsWaK/+qu/UnJyslJTU/XQQw/p0KFDAWvOnTunoqIi9ezZU7fccosmT54sj8cTsObo0aMqLCxUUlKSUlNT9eyzz+r8+fMBa2pqajRixAg5HA4NGDBA5eXloZ0hAADo1IIqM9u3b1dRUZF2794tt9stn8+n/Px8nTlzxl4ze/Zsffjhh9q4caO2b9+uY8eO6eGHH7b3t7S0qLCwUM3Nzdq1a5fefvttlZeXa8GCBfaaI0eOqLCwUOPHj1d9fb2Ki4v1xBNPqLKyMgynDAAAOpMuwSzeunVrwOPy8nKlpqaqrq5OY8eO1cmTJ7V27VqtX79eEyZMkCStW7dOgwYN0u7duzVmzBhVVVXp4MGD+v3vf6+0tDTl5OTo+eef189//nMtXLhQCQkJWrNmjbKzs7Vs2TJJ0qBBg7Rz506tWLFCBQUFYTp1AADQGQRVZr7t5MmTkqQePXpIkurq6uTz+ZSXl2evGThwoPr06aPa2lqNGTNGtbW1Gjp0qNLS0uw1BQUFmjlzphoaGjR8+HDV1tYGHKNtTXFx8WVn8Xq98nq99uOmpiZJks/nk8/nu57TtLUd5+LjOeKsoJ9vukvlcLMiCz+yuIAc/MjCjyz8rpZFKBmFXGZaW1tVXFysu+++W0OGDJEkNTY2KiEhQSkpKQFr09LS1NjYaK+5uMi07W/bd6U1TU1N+uabb9S1a9d28yxZskSLFi1qt72qqkpJSUmhneRluN1u+/dLR13787Zs2RLWOTraxTnc7MjCjywuIAc/svAjC7/LZXH27NmgjxVymSkqKtKBAwe0c+fOUA8RVnPnzlVJSYn9uKmpSVlZWcrPz5fT6QzLa/h8Prndbk2cOFHx8fGSpCELr/17PAcWdo6PyC6Vw82KLPzI4gJy8CMLP7Lwu1oWbZ+sBCOkMjNr1ixt3rxZO3bsUO/eve3t6enpam5u1okTJwKuzng8HqWnp9tr9uzZE3C8trudLl7z7TugPB6PnE7nJa/KSJLD4ZDD4Wi3PT4+PuxvnIuP6W2JCep5nUkksjUVWfiRxQXk4EcWfmThd7ksQsknqLuZLMvSrFmz9P7772vbtm3Kzs4O2J+bm6v4+HhVV1fb2w4dOqSjR4/K5XJJklwul/bv36/jx4/ba9xut5xOpwYPHmyvufgYbWvajgEAANAmqCszRUVFWr9+vf71X/9VycnJ9ndcunfvrq5du6p79+6aMWOGSkpK1KNHDzmdTj3zzDNyuVwaM2aMJCk/P1+DBw/WtGnTtHTpUjU2Nmr+/PkqKiqyr6w8/fTTWrVqlebMmaPHH39c27Zt03vvvaeKioownz4AADBdUFdmXn/9dZ08eVLjxo1TRkaG/evdd9+116xYsUI//OEPNXnyZI0dO1bp6enatGmTvT8uLk6bN29WXFycXC6XfvrTn+rRRx/V4sWL7TXZ2dmqqKiQ2+3WnXfeqWXLlunNN9/ktmwAANBOUFdmLOvqtyEnJiaqrKxMZWVll13Tt2/fq97ZM27cOO3bty+Y8QAAwE2If5sJAAAYjTIDAACMRpkBAABGo8wAAACjUWYAAIDRKDMAAMBolBkAAGA0ygwAADAaZQYAABiNMgMAAIxGmQEAAEajzAAAAKNRZgAAgNEoMwAAwGiUGQAAYDTKDAAAMBplBgAAGI0yAwAAjEaZAQAARqPMAAAAo1FmAACA0SgzAADAaJSZKOpXWtHRIwAA0OlQZgAAgNEoMwAAwGiUGQAAYDTKDAAAMBplBgAAGI0yAwAAjEaZAQAARqPMAAAAo1FmAACA0SgzAADAaJQZAABgNMoMAAAwGmUGAAAYjTIDAACMRpkBAABGo8xch36lFR09AgAANz3KDAAAMBplBgAAGI0yAwAAjEaZAQAARqPMAAAAo1FmAACA0SgzAADAaJQZAABgNMoMAAAwGmUGAAAYjTIDAACMRpkBAABGo8wAAACjUWYAAIDRKDMAAMBolBkAAGA0ygwAADAaZQYAABiNMgMAAIxGmQEAAEajzAAAAKNRZgAAgNEoMwAAwGiUGQAAYDTKDAAAMBplBgAAGI0yAwAAjEaZAQAARqPMAAAAo1FmAACA0SgzAADAaEGXmR07dujBBx9UZmamYmJi9MEHHwTstyxLCxYsUEZGhrp27aq8vDz913/9V8Car7/+WlOnTpXT6VRKSopmzJih06dPB6z5j//4D/3gBz9QYmKisrKytHTp0uDPDgAAdHpBl5kzZ87ozjvvVFlZ2SX3L126VL/85S+1Zs0affTRR+rWrZsKCgp07tw5e83UqVPV0NAgt9utzZs3a8eOHXrqqafs/U1NTcrPz1ffvn1VV1enX/ziF1q4cKF+/etfh3CKAACgM+sS7BPuv/9+3X///ZfcZ1mWXn31Vc2fP1+TJk2SJP3DP/yD0tLS9MEHH+iRRx7RJ598oq1bt2rv3r0aOXKkJOm1117TAw88oFdeeUWZmZl655131NzcrLfeeksJCQn6/ve/r/r6ei1fvjyg9JioX2mFJOlPLxd28CQAAHQOYf3OzJEjR9TY2Ki8vDx7W/fu3TV69GjV1tZKkmpra5WSkmIXGUnKy8tTbGysPvroI3vN2LFjlZCQYK8pKCjQoUOH9Je//CWcIwMAAMMFfWXmShobGyVJaWlpAdvT0tLsfY2NjUpNTQ0coksX9ejRI2BNdnZ2u2O07bv11lvbvbbX65XX67UfNzU1SZJ8Pp98Pt/1nJat7Tht/3XEWdd9LBN9O4ebGVn4kcUF5OBHFn5k4Xe1LELJKKxlpiMtWbJEixYtare9qqpKSUlJYX0tt9stSVo6KvRjbNmyJUzTdJy2HEAWFyOLC8jBjyz8yMLvclmcPXs26GOFtcykp6dLkjwejzIyMuztHo9HOTk59prjx48HPO/8+fP6+uuv7eenp6fL4/EErGl73Lbm2+bOnauSkhL7cVNTk7KyspSfny+n03l9J/Z/fD6f3G63Jk6cqPj4eA1ZWBnysQ4sLAjLTB3h2znczMjCjywuIAc/svAjC7+rZdH2yUowwlpmsrOzlZ6erurqaru8NDU16aOPPtLMmTMlSS6XSydOnFBdXZ1yc3MlSdu2bVNra6tGjx5tr5k3b558Pp99om63W3fcccclP2KSJIfDIYfD0W57fHx82N84bcf0tsRc1zFMF4lsTUUWfmRxATn4kYUfWfhdLotQ8gn6C8CnT59WfX296uvrJV340m99fb2OHj2qmJgYFRcX64UXXtBvf/tb7d+/X48++qgyMzP10EMPSZIGDRqkv/7rv9aTTz6pPXv26N///d81a9YsPfLII8rMzJQk/eQnP1FCQoJmzJihhoYGvfvuu1q5cmXAlRcAAAAphCszf/zjHzV+/Hj7cVvBmD59usrLyzVnzhydOXNGTz31lE6cOKF77rlHW7duVWJiov2cd955R7NmzdJ9992n2NhYTZ48Wb/85S/t/d27d1dVVZWKioqUm5urXr16acGCBcbflg0AAMIv6DIzbtw4Wdbl7+KJiYnR4sWLtXjx4suu6dGjh9avX3/F1xk2bJj+7d/+LdjxAADATYZ/mwkAABiNMgMAAIxGmQEAAEajzAAAAKNRZgAAgNEoMwAAwGiUGQAAYDTKDAAAMBplBgAAGI0yAwAAjEaZAQAARqPMAAAAo1FmAACA0SgzAADAaJQZAABgNMoMAAAwGmUGAAAYjTIDAACMRpkBAABGo8wAAACjUWYAAIDRKDMAAMBolBkAAGA0ykwH6Vda0dEjAADQKVBmAACA0SgzAADAaJQZAABgNMoMAAAwGmUGAAAYjTIDAACMRpkBAABGo8wAAACjUWYAAIDRKDMAAMBolBkAAGA0ygwAADAaZQYAABiNMgMAAIxGmQEAAEajzAAAAKNRZgAAgNEoMwAAwGiUGQAAYDTKDAAAMBplBgAAGI0yAwAAjEaZAQAARqPMdKB+pRXqV1rR0WMAAGA0ygwAADAaZQYAABiNMgMAAIxGmQEAAEajzAAAAKNRZgAAgNEoMwAAwGiUGQAAYDTKDAAAMBplBgAAGI0ycwPgnzQAACB0XTp6ABMNWVgpb0tMR48BAADElRkAAGA4ygwAADAaZQYAABiNMgMAAIxGmQEAAEajzAAAAKNRZm4Q/Uor+HkzAACEgDIDAACMRpkBAABGo8wAAACjUWYAAIDRbugyU1ZWpn79+ikxMVGjR4/Wnj17OnqkiONLwAAABOeGLTPvvvuuSkpK9Nxzz+njjz/WnXfeqYKCAh0/fryjRwMAADeQG7bMLF++XE8++aQee+wxDR48WGvWrFFSUpLeeuutjh4t4rhNGwCAa9elowe4lObmZtXV1Wnu3Ln2ttjYWOXl5am2tvaSz/F6vfJ6vfbjkydPSpK+/vpr+Xy+sMzl8/l09uxZdfHFqqU1JizHvJIB/+89+/cfzb0v4q93rdpy+OqrrxQfH9/R43QosvAjiwvIwY8s/MjC72pZnDp1SpJkWdY1H/OGLDNffvmlWlpalJaWFrA9LS1Nn3766SWfs2TJEi1atKjd9uzs7IjMGG29lnX0BAAARM+pU6fUvXv3a1p7Q5aZUMydO1clJSX249bWVn399dfq2bOnYmLCcxWlqalJWVlZ+uKLL+R0OsNyTBORgx9Z+JHFBeTgRxZ+ZOF3tSwsy9KpU6eUmZl5zce8IctMr169FBcXJ4/HE7Dd4/EoPT39ks9xOBxyOBwB21JSUiIyn9PpvOnfjBI5XIws/MjiAnLwIws/svC7UhbXekWmzQ35BeCEhATl5uaqurra3tba2qrq6mq5XK4OnAwAANxobsgrM5JUUlKi6dOna+TIkRo1apReffVVnTlzRo899lhHjwYAAG4gN2yZmTJliv73f/9XCxYsUGNjo3JycrR169Z2XwqOJofDoeeee67dx1k3G3LwIws/sriAHPzIwo8s/CKRRYwVzL1PAAAAN5gb8jszAAAA14oyAwAAjEaZAQAARqPMAAAAo1FmvqWsrEz9+vVTYmKiRo8erT179lx27aZNmzRy5EilpKSoW7duysnJ0T/+4z9GcdrICSaHi23YsEExMTF66KGHIjtgFAWTRXl5uWJiYgJ+JSYmRnHayAr2fXHixAkVFRUpIyNDDodD3/ve97Rly5YoTRs5weQwbty4du+JmJgYFRYWRnHiyAn2PfHqq6/qjjvuUNeuXZWVlaXZs2fr3LlzUZo2soLJwufzafHixerfv78SExN15513auvWrVGcNjJ27NihBx98UJmZmYqJidEHH3xw1efU1NRoxIgRcjgcGjBggMrLy4N/YQu2DRs2WAkJCdZbb71lNTQ0WE8++aSVkpJieTyeS67/wx/+YG3atMk6ePCg9dlnn1mvvvqqFRcXZ23dujXKk4dXsDm0OXLkiHXbbbdZP/jBD6xJkyZFZ9gICzaLdevWWU6n0/rzn/9s/2psbIzy1JERbBZer9caOXKk9cADD1g7d+60jhw5YtXU1Fj19fVRnjy8gs3hq6++Cng/HDhwwIqLi7PWrVsX3cEjINgs3nnnHcvhcFjvvPOOdeTIEauystLKyMiwZs+eHeXJwy/YLObMmWNlZmZaFRUV1uHDh63Vq1dbiYmJ1scffxzlycNry5Yt1rx586xNmzZZkqz333//ius///xzKykpySopKbEOHjxovfbaayH9PUqZucioUaOsoqIi+3FLS4uVmZlpLVmy5JqPMXz4cGv+/PmRGC9qQsnh/Pnz1l133WW9+eab1vTp0ztNmQk2i3Xr1lndu3eP0nTRFWwWr7/+unX77bdbzc3N0RoxKq73z4kVK1ZYycnJ1unTpyM1YtQEm0VRUZE1YcKEgG0lJSXW3XffHdE5oyHYLDIyMqxVq1YFbHv44YetqVOnRnTOaLqWMjNnzhzr+9//fsC2KVOmWAUFBUG9Fh8z/Z/m5mbV1dUpLy/P3hYbG6u8vDzV1tZe9fmWZam6ulqHDh3S2LFjIzlqRIWaw+LFi5WamqoZM2ZEY8yoCDWL06dPq2/fvsrKytKkSZPU0NAQjXEjKpQsfvvb38rlcqmoqEhpaWkaMmSIXnrpJbW0tERr7LC73j8nJGnt2rV65JFH1K1bt0iNGRWhZHHXXXeprq7O/vjl888/15YtW/TAAw9EZeZICSULr9fb7iPorl27aufOnRGd9UZTW1sbkJskFRQUXPP/T21u2J8AHG1ffvmlWlpa2v2E4bS0NH366aeXfd7Jkyd12223yev1Ki4uTqtXr9bEiRMjPW7EhJLDzp07tXbtWtXX10dhwugJJYs77rhDb731loYNG6aTJ0/qlVde0V133aWGhgb17t07GmNHRChZfP7559q2bZumTp2qLVu26LPPPtPPfvYz+Xw+Pffcc9EYO+xC/XOizZ49e3TgwAGtXbs2UiNGTShZ/OQnP9GXX36pe+65R5Zl6fz583r66af1d3/3d9EYOWJCyaKgoEDLly/X2LFj1b9/f1VXV2vTpk1Gl/1QNDY2XjK3pqYmffPNN+rates1HYcrM9cpOTlZ9fX12rt3r1588UWVlJSopqamo8eKmlOnTmnatGl644031KtXr44ep8O5XC49+uijysnJ0b333qtNmzbpO9/5jn71q1919GhR19raqtTUVP36179Wbm6upkyZonnz5mnNmjUdPVqHWbt2rYYOHapRo0Z19CgdoqamRi+99JJWr16tjz/+WJs2bVJFRYWef/75jh4t6lauXKnvfve7GjhwoBISEjRr1iw99thjio3lr+VQcGXm//Tq1UtxcXHyeDwB2z0ej9LT0y/7vNjYWA0YMECSlJOTo08++URLlizRuHHjIjluxASbw+HDh/WnP/1JDz74oL2ttbVVktSlSxcdOnRI/fv3j+zQERLqe+Ji8fHxGj58uD777LNIjBg1oWSRkZGh+Ph4xcXF2dsGDRqkxsZGNTc3KyEhIaIzR8L1vCfOnDmjDRs2aPHixZEcMWpCyeLv//7vNW3aND3xxBOSpKFDh+rMmTN66qmnNG/ePGP/Ig8li+985zv64IMPdO7cOX311VfKzMxUaWmpbr/99miMfMNIT0+/ZG5Op/Oar8pIXJmxJSQkKDc3V9XV1fa21tZWVVdXy+VyXfNxWltb5fV6IzFiVASbw8CBA7V//37V19fbv370ox9p/Pjxqq+vV1ZWVjTHD6twvCdaWlq0f/9+ZWRkRGrMqAgli7vvvlufffaZXW4l6T//8z+VkZFhZJGRru89sXHjRnm9Xv30pz+N9JhREUoWZ8+ebVdY2squZfA/E3g974vExETddtttOn/+vH7zm99o0qRJkR73huJyuQJykyS32x3U37uSuDX7Yhs2bLAcDodVXl5uHTx40HrqqaeslJQU+9baadOmWaWlpfb6l156yaqqqrIOHz5sHTx40HrllVesLl26WG+88UZHnUJYBJvDt3Wmu5mCzWLRokVWZWWldfjwYauurs565JFHrMTERKuhoaGjTiFsgs3i6NGjVnJysjVr1izr0KFD1ubNm63U1FTrhRde6KhTCItQ//+45557rClTpkR73IgKNovnnnvOSk5Otv75n//Z+vzzz62qqiqrf//+1o9//OOOOoWwCTaL3bt3W7/5zW+sw4cPWzt27LAmTJhgZWdnW3/5y1866AzC49SpU9a+ffusffv2WZKs5cuXW/v27bP++7//27IsyyotLbWmTZtmr2+7NfvZZ5+1PvnkE6usrIxbs8Phtddes/r06WMlJCRYo0aNsnbv3m3vu/fee63p06fbj+fNm2cNGDDASkxMtG699VbL5XJZGzZs6ICpwy+YHL6tM5UZywoui+LiYnttWlqa9cADDxj/cyMuFuz7YteuXdbo0aMth8Nh3X777daLL75onT9/PspTh1+wOXz66aeWJKuqqirKk0ZeMFn4fD5r4cKFVv/+/a3ExEQrKyvL+tnPfmb8X+BtgsmipqbGGjRokOVwOKyePXta06ZNs/7nf/6nA6YOrz/84Q+WpHa/2s59+vTp1r333tvuOTk5OVZCQoJ1++23h/QzmGIsy+BrewAA4KbHd2YAAIDRKDMAAMBolBkAAGA0ygwAADAaZQYAABiNMgMAAIxGmQEAAEajzAAAAKNRZgAAgNEoMwAAwGiUGQAAYDTKDAAAMNr/B275AxTYNQlVAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['y6'].hist(bins=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30eff059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9784476541301952"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['y6'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed54624a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29674, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ae249e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = [col for col in df.columns if col.startswith('x')]\n",
    "y_columns = [col for col in df.columns if col.startswith('y')]\n",
    "\n",
    "Y = df[y_columns].values\n",
    "X = df[x_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "064de500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_train, X_test, Y_train, Y_test, params):\n",
    "    scaler_x = StandardScaler().fit(X_train)\n",
    "    scaler_y = StandardScaler().fit(Y_train)\n",
    "    X_train = scaler_x.transform(X_train)\n",
    "    X_test = scaler_x.transform(X_test)\n",
    "    Y_train = scaler_y.transform(Y_train)\n",
    "    Y_test = scaler_y.transform(Y_test)\n",
    "\n",
    "    input_shape = X_train.shape[1]\n",
    "    \n",
    "    output_shape = Y_train.shape[1]\n",
    "    return X_train, X_test, Y_train, Y_test, input_shape, output_shape, scaler_x, scaler_y\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=params['test_size'], \n",
    "                                                    random_state=params['random_state'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test, input_shape, output_shape, scaler_x, scaler_y = preprocess_data(X_train, X_test, Y_train, Y_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a10ed4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.86603895e-17, -2.39778990e-17, -4.12750044e-17, -8.97978632e-17,\n",
       "         1.45237693e-17,  4.88584184e-17, -7.02959790e-15, -1.74744727e-15]),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.mean(axis=0), X_train.std(axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ccb03a",
   "metadata": {},
   "source": [
    "## Appears to be drift, perhaps the sample is not big enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c161da77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.01621399, -0.00112999,  0.01755134,  0.01955565,  0.01673425,\n",
       "         0.00871709, -0.01095845, -0.02030808]),\n",
       " array([0.99488322, 0.99650294, 0.78686316, 0.96749519, 0.93053514,\n",
       "        0.90833692, 1.01170468, 1.00410648]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.mean(axis=0), X_test.std(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53e58115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.23324421e-14,  2.75938148e-14, -7.59591967e-15, -1.74703992e-14,\n",
       "        -3.12392412e-14, -5.68256506e-14, -1.97065971e-13]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.mean(axis=0), Y_train.std(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2baf62f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.002863  ,  0.0093879 , -0.00576779, -0.01150026, -0.01160122,\n",
       "        -0.01466698, -0.0055547 ]),\n",
       " array([1.00800321, 1.00616058, 1.0009353 , 0.99290648, 0.99481008,\n",
       "        1.00920012, 0.71155792]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.mean(axis=0), Y_test.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdca24f",
   "metadata": {},
   "source": [
    "## Dummy regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a74f6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d32b7301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.23299623e-14,  2.76159547e-14, -7.59899700e-15, ...,\n",
       "        -3.12143139e-14, -5.68119908e-14, -1.97071672e-13],\n",
       "       [-1.23299623e-14,  2.76159547e-14, -7.59899700e-15, ...,\n",
       "        -3.12143139e-14, -5.68119908e-14, -1.97071672e-13],\n",
       "       [-1.23299623e-14,  2.76159547e-14, -7.59899700e-15, ...,\n",
       "        -3.12143139e-14, -5.68119908e-14, -1.97071672e-13],\n",
       "       ...,\n",
       "       [-1.23299623e-14,  2.76159547e-14, -7.59899700e-15, ...,\n",
       "        -3.12143139e-14, -5.68119908e-14, -1.97071672e-13],\n",
       "       [-1.23299623e-14,  2.76159547e-14, -7.59899700e-15, ...,\n",
       "        -3.12143139e-14, -5.68119908e-14, -1.97071672e-13],\n",
       "       [-1.23299623e-14,  2.76159547e-14, -7.59899700e-15, ...,\n",
       "        -3.12143139e-14, -5.68119908e-14, -1.97071672e-13]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = MultiOutputRegressor(DummyRegressor(strategy=\"mean\")).fit(X_train, Y_train)\n",
    "regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e960bbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7819301538758372"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_train, regr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5fa73bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7826444903716244"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_test, regr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ac703",
   "metadata": {},
   "source": [
    "## Train a linear regression for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb67a16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01118562, -0.25258042, -0.07693146, ...,  0.15934534,\n",
       "         0.02889025, -0.02566576],\n",
       "       [ 0.33075672,  0.74101837,  0.27335388, ..., -0.3718137 ,\n",
       "        -0.14318812, -0.4488022 ],\n",
       "       [-0.22386175, -0.38369246, -0.11028056, ...,  0.22433786,\n",
       "         0.10529634,  0.09333019],\n",
       "       ...,\n",
       "       [ 0.01024576, -0.05781049, -0.02785113, ..., -0.06734454,\n",
       "        -0.04966926,  0.16428362],\n",
       "       [-0.09533647, -0.20393649, -0.04846468, ...,  0.42137434,\n",
       "         0.14091655,  1.00339397],\n",
       "       [-0.10952675, -0.16497835, -0.03597803, ...,  0.16906614,\n",
       "         0.06585663,  0.100133  ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = MultiOutputRegressor(Ridge(random_state=123)).fit(X_train, Y_train)\n",
    "regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f8b7880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7420778534372884"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_train, regr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93fe236e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7453412087802475"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_test, regr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909b3bd7",
   "metadata": {},
   "source": [
    "## Simplest neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "606b1b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43d73ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 7), dtype=float32, numpy=\n",
       "array([[-0.10294949, -0.28713128,  0.07401746, -0.14377841, -0.08267734,\n",
       "         0.33238086,  0.27510813]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Sequential model with 3 layers\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(input_shape, activation=\"relu\", name=\"layer_in\"),\n",
    "        layers.Dense(128, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(64, activation=\"relu\", name=\"layer3\"),\n",
    "        layers.Dense(output_shape, name=\"layer_out\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model(X_train[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d43388b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer_in (Dense)            (1, 8)                    72        \n",
      "                                                                 \n",
      " layer2 (Dense)              (1, 128)                  1152      \n",
      "                                                                 \n",
      " layer3 (Dense)              (1, 64)                   8256      \n",
      "                                                                 \n",
      " layer_out (Dense)           (1, 7)                    455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9935 (38.81 KB)\n",
      "Trainable params: 9935 (38.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67a8182d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.MeanAbsoluteError(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.MeanAbsoluteError()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b11ea593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/400\n",
      "371/371 [==============================] - 0s 719us/step - loss: 0.6620 - mean_absolute_error: 0.6620 - val_loss: 0.5994 - val_mean_absolute_error: 0.5994\n",
      "Epoch 2/400\n",
      "371/371 [==============================] - 0s 550us/step - loss: 0.5583 - mean_absolute_error: 0.5583 - val_loss: 0.5222 - val_mean_absolute_error: 0.5222\n",
      "Epoch 3/400\n",
      "371/371 [==============================] - 0s 593us/step - loss: 0.4880 - mean_absolute_error: 0.4880 - val_loss: 0.4619 - val_mean_absolute_error: 0.4619\n",
      "Epoch 4/400\n",
      "371/371 [==============================] - 0s 540us/step - loss: 0.4404 - mean_absolute_error: 0.4404 - val_loss: 0.4132 - val_mean_absolute_error: 0.4132\n",
      "Epoch 5/400\n",
      "371/371 [==============================] - 0s 603us/step - loss: 0.4111 - mean_absolute_error: 0.4111 - val_loss: 0.3835 - val_mean_absolute_error: 0.3835\n",
      "Epoch 6/400\n",
      "371/371 [==============================] - 0s 535us/step - loss: 0.3922 - mean_absolute_error: 0.3922 - val_loss: 0.4112 - val_mean_absolute_error: 0.4112\n",
      "Epoch 7/400\n",
      "371/371 [==============================] - 0s 540us/step - loss: 0.3763 - mean_absolute_error: 0.3763 - val_loss: 0.3542 - val_mean_absolute_error: 0.3542\n",
      "Epoch 8/400\n",
      "371/371 [==============================] - 0s 566us/step - loss: 0.3627 - mean_absolute_error: 0.3627 - val_loss: 0.3714 - val_mean_absolute_error: 0.3714\n",
      "Epoch 9/400\n",
      "371/371 [==============================] - 0s 523us/step - loss: 0.3513 - mean_absolute_error: 0.3513 - val_loss: 0.3611 - val_mean_absolute_error: 0.3611\n",
      "Epoch 10/400\n",
      "371/371 [==============================] - 0s 513us/step - loss: 0.3406 - mean_absolute_error: 0.3406 - val_loss: 0.3386 - val_mean_absolute_error: 0.3386\n",
      "Epoch 11/400\n",
      "371/371 [==============================] - 0s 519us/step - loss: 0.3320 - mean_absolute_error: 0.3320 - val_loss: 0.3166 - val_mean_absolute_error: 0.3166\n",
      "Epoch 12/400\n",
      "371/371 [==============================] - 0s 514us/step - loss: 0.3231 - mean_absolute_error: 0.3231 - val_loss: 0.3309 - val_mean_absolute_error: 0.3309\n",
      "Epoch 13/400\n",
      "371/371 [==============================] - 0s 512us/step - loss: 0.3159 - mean_absolute_error: 0.3159 - val_loss: 0.3663 - val_mean_absolute_error: 0.3663\n",
      "Epoch 14/400\n",
      "371/371 [==============================] - 0s 514us/step - loss: 0.3092 - mean_absolute_error: 0.3092 - val_loss: 0.3017 - val_mean_absolute_error: 0.3017\n",
      "Epoch 15/400\n",
      "371/371 [==============================] - 0s 506us/step - loss: 0.3038 - mean_absolute_error: 0.3038 - val_loss: 0.2821 - val_mean_absolute_error: 0.2821\n",
      "Epoch 16/400\n",
      "371/371 [==============================] - 0s 509us/step - loss: 0.2976 - mean_absolute_error: 0.2976 - val_loss: 0.2788 - val_mean_absolute_error: 0.2788\n",
      "Epoch 17/400\n",
      "371/371 [==============================] - 0s 518us/step - loss: 0.2918 - mean_absolute_error: 0.2918 - val_loss: 0.2836 - val_mean_absolute_error: 0.2836\n",
      "Epoch 18/400\n",
      "371/371 [==============================] - 0s 519us/step - loss: 0.2865 - mean_absolute_error: 0.2865 - val_loss: 0.2841 - val_mean_absolute_error: 0.2841\n",
      "Epoch 19/400\n",
      "371/371 [==============================] - 0s 517us/step - loss: 0.2815 - mean_absolute_error: 0.2815 - val_loss: 0.2788 - val_mean_absolute_error: 0.2788\n",
      "Epoch 20/400\n",
      "371/371 [==============================] - 0s 623us/step - loss: 0.2770 - mean_absolute_error: 0.2770 - val_loss: 0.2550 - val_mean_absolute_error: 0.2550\n",
      "Epoch 21/400\n",
      "371/371 [==============================] - 0s 535us/step - loss: 0.2731 - mean_absolute_error: 0.2731 - val_loss: 0.2677 - val_mean_absolute_error: 0.2677\n",
      "Epoch 22/400\n",
      "371/371 [==============================] - 0s 545us/step - loss: 0.2694 - mean_absolute_error: 0.2694 - val_loss: 0.2575 - val_mean_absolute_error: 0.2575\n",
      "Epoch 23/400\n",
      "371/371 [==============================] - 0s 525us/step - loss: 0.2663 - mean_absolute_error: 0.2663 - val_loss: 0.2475 - val_mean_absolute_error: 0.2475\n",
      "Epoch 24/400\n",
      "371/371 [==============================] - 0s 522us/step - loss: 0.2627 - mean_absolute_error: 0.2627 - val_loss: 0.2491 - val_mean_absolute_error: 0.2491\n",
      "Epoch 25/400\n",
      "371/371 [==============================] - 0s 522us/step - loss: 0.2599 - mean_absolute_error: 0.2599 - val_loss: 0.2702 - val_mean_absolute_error: 0.2702\n",
      "Epoch 26/400\n",
      "371/371 [==============================] - 0s 521us/step - loss: 0.2562 - mean_absolute_error: 0.2562 - val_loss: 0.2793 - val_mean_absolute_error: 0.2793\n",
      "Epoch 27/400\n",
      "371/371 [==============================] - 0s 521us/step - loss: 0.2543 - mean_absolute_error: 0.2543 - val_loss: 0.2339 - val_mean_absolute_error: 0.2339\n",
      "Epoch 28/400\n",
      "371/371 [==============================] - 0s 517us/step - loss: 0.2521 - mean_absolute_error: 0.2521 - val_loss: 0.2467 - val_mean_absolute_error: 0.2467\n",
      "Epoch 29/400\n",
      "371/371 [==============================] - 0s 527us/step - loss: 0.2492 - mean_absolute_error: 0.2492 - val_loss: 0.2391 - val_mean_absolute_error: 0.2391\n",
      "Epoch 30/400\n",
      "371/371 [==============================] - 0s 519us/step - loss: 0.2474 - mean_absolute_error: 0.2474 - val_loss: 0.2421 - val_mean_absolute_error: 0.2421\n",
      "Epoch 31/400\n",
      "371/371 [==============================] - 0s 527us/step - loss: 0.2452 - mean_absolute_error: 0.2452 - val_loss: 0.2313 - val_mean_absolute_error: 0.2313\n",
      "Epoch 32/400\n",
      "371/371 [==============================] - 0s 513us/step - loss: 0.2434 - mean_absolute_error: 0.2434 - val_loss: 0.2452 - val_mean_absolute_error: 0.2452\n",
      "Epoch 33/400\n",
      "371/371 [==============================] - 0s 518us/step - loss: 0.2413 - mean_absolute_error: 0.2413 - val_loss: 0.2446 - val_mean_absolute_error: 0.2446\n",
      "Epoch 34/400\n",
      "371/371 [==============================] - 0s 516us/step - loss: 0.2394 - mean_absolute_error: 0.2394 - val_loss: 0.2483 - val_mean_absolute_error: 0.2483\n",
      "Epoch 35/400\n",
      "371/371 [==============================] - 0s 517us/step - loss: 0.2373 - mean_absolute_error: 0.2373 - val_loss: 0.2271 - val_mean_absolute_error: 0.2271\n",
      "Epoch 36/400\n",
      "371/371 [==============================] - 0s 518us/step - loss: 0.2364 - mean_absolute_error: 0.2364 - val_loss: 0.2238 - val_mean_absolute_error: 0.2238\n",
      "Epoch 37/400\n",
      "371/371 [==============================] - 0s 512us/step - loss: 0.2343 - mean_absolute_error: 0.2343 - val_loss: 0.2300 - val_mean_absolute_error: 0.2300\n",
      "Epoch 38/400\n",
      "371/371 [==============================] - 0s 515us/step - loss: 0.2334 - mean_absolute_error: 0.2334 - val_loss: 0.2171 - val_mean_absolute_error: 0.2171\n",
      "Epoch 39/400\n",
      "371/371 [==============================] - 0s 510us/step - loss: 0.2308 - mean_absolute_error: 0.2308 - val_loss: 0.2204 - val_mean_absolute_error: 0.2204\n",
      "Epoch 40/400\n",
      "371/371 [==============================] - 0s 517us/step - loss: 0.2300 - mean_absolute_error: 0.2300 - val_loss: 0.2456 - val_mean_absolute_error: 0.2456\n",
      "Epoch 41/400\n",
      "371/371 [==============================] - 0s 509us/step - loss: 0.2288 - mean_absolute_error: 0.2288 - val_loss: 0.2426 - val_mean_absolute_error: 0.2426\n",
      "Epoch 42/400\n",
      "371/371 [==============================] - 0s 514us/step - loss: 0.2272 - mean_absolute_error: 0.2272 - val_loss: 0.2266 - val_mean_absolute_error: 0.2266\n",
      "Epoch 43/400\n",
      "371/371 [==============================] - 0s 509us/step - loss: 0.2255 - mean_absolute_error: 0.2255 - val_loss: 0.2455 - val_mean_absolute_error: 0.2455\n",
      "Epoch 44/400\n",
      "371/371 [==============================] - 0s 506us/step - loss: 0.2245 - mean_absolute_error: 0.2245 - val_loss: 0.2163 - val_mean_absolute_error: 0.2163\n",
      "Epoch 45/400\n",
      "371/371 [==============================] - 0s 514us/step - loss: 0.2237 - mean_absolute_error: 0.2237 - val_loss: 0.2111 - val_mean_absolute_error: 0.2111\n",
      "Epoch 46/400\n",
      "371/371 [==============================] - 0s 512us/step - loss: 0.2223 - mean_absolute_error: 0.2223 - val_loss: 0.2279 - val_mean_absolute_error: 0.2279\n",
      "Epoch 47/400\n",
      "371/371 [==============================] - 0s 509us/step - loss: 0.2215 - mean_absolute_error: 0.2215 - val_loss: 0.2158 - val_mean_absolute_error: 0.2158\n",
      "Epoch 48/400\n",
      "371/371 [==============================] - 0s 509us/step - loss: 0.2196 - mean_absolute_error: 0.2196 - val_loss: 0.2163 - val_mean_absolute_error: 0.2163\n",
      "Epoch 49/400\n",
      "371/371 [==============================] - 0s 514us/step - loss: 0.2189 - mean_absolute_error: 0.2189 - val_loss: 0.2102 - val_mean_absolute_error: 0.2102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/400\n",
      "371/371 [==============================] - 0s 511us/step - loss: 0.2182 - mean_absolute_error: 0.2182 - val_loss: 0.2194 - val_mean_absolute_error: 0.2194\n",
      "Epoch 51/400\n",
      "371/371 [==============================] - 0s 512us/step - loss: 0.2163 - mean_absolute_error: 0.2163 - val_loss: 0.2099 - val_mean_absolute_error: 0.2099\n",
      "Epoch 52/400\n",
      "371/371 [==============================] - 0s 508us/step - loss: 0.2158 - mean_absolute_error: 0.2158 - val_loss: 0.2121 - val_mean_absolute_error: 0.2121\n",
      "Epoch 53/400\n",
      "371/371 [==============================] - 0s 564us/step - loss: 0.2142 - mean_absolute_error: 0.2142 - val_loss: 0.2257 - val_mean_absolute_error: 0.2257\n",
      "Epoch 54/400\n",
      "371/371 [==============================] - 0s 511us/step - loss: 0.2137 - mean_absolute_error: 0.2137 - val_loss: 0.2161 - val_mean_absolute_error: 0.2161\n",
      "Epoch 55/400\n",
      "371/371 [==============================] - 0s 507us/step - loss: 0.2129 - mean_absolute_error: 0.2129 - val_loss: 0.2064 - val_mean_absolute_error: 0.2064\n",
      "Epoch 56/400\n",
      "371/371 [==============================] - 0s 505us/step - loss: 0.2120 - mean_absolute_error: 0.2120 - val_loss: 0.2111 - val_mean_absolute_error: 0.2111\n",
      "Epoch 57/400\n",
      "371/371 [==============================] - 0s 550us/step - loss: 0.2108 - mean_absolute_error: 0.2108 - val_loss: 0.2073 - val_mean_absolute_error: 0.2073\n",
      "Epoch 58/400\n",
      "371/371 [==============================] - 0s 548us/step - loss: 0.2103 - mean_absolute_error: 0.2103 - val_loss: 0.2054 - val_mean_absolute_error: 0.2054\n",
      "Epoch 59/400\n",
      "371/371 [==============================] - 0s 652us/step - loss: 0.2092 - mean_absolute_error: 0.2092 - val_loss: 0.2000 - val_mean_absolute_error: 0.2000\n",
      "Epoch 60/400\n",
      "371/371 [==============================] - 0s 555us/step - loss: 0.2085 - mean_absolute_error: 0.2085 - val_loss: 0.1940 - val_mean_absolute_error: 0.1940\n",
      "Epoch 61/400\n",
      "371/371 [==============================] - 0s 702us/step - loss: 0.2079 - mean_absolute_error: 0.2079 - val_loss: 0.2013 - val_mean_absolute_error: 0.2013\n",
      "Epoch 62/400\n",
      "371/371 [==============================] - 0s 529us/step - loss: 0.2064 - mean_absolute_error: 0.2064 - val_loss: 0.2267 - val_mean_absolute_error: 0.2267\n",
      "Epoch 63/400\n",
      "371/371 [==============================] - 0s 543us/step - loss: 0.2062 - mean_absolute_error: 0.2062 - val_loss: 0.2047 - val_mean_absolute_error: 0.2047\n",
      "Epoch 64/400\n",
      "371/371 [==============================] - 0s 573us/step - loss: 0.2053 - mean_absolute_error: 0.2053 - val_loss: 0.2052 - val_mean_absolute_error: 0.2052\n",
      "Epoch 65/400\n",
      "371/371 [==============================] - 0s 634us/step - loss: 0.2047 - mean_absolute_error: 0.2047 - val_loss: 0.2113 - val_mean_absolute_error: 0.2113\n",
      "Epoch 66/400\n",
      "371/371 [==============================] - 0s 533us/step - loss: 0.2042 - mean_absolute_error: 0.2042 - val_loss: 0.1922 - val_mean_absolute_error: 0.1922\n",
      "Epoch 67/400\n",
      "371/371 [==============================] - 0s 526us/step - loss: 0.2027 - mean_absolute_error: 0.2027 - val_loss: 0.2152 - val_mean_absolute_error: 0.2152\n",
      "Epoch 68/400\n",
      "371/371 [==============================] - 0s 518us/step - loss: 0.2027 - mean_absolute_error: 0.2027 - val_loss: 0.2065 - val_mean_absolute_error: 0.2065\n",
      "Epoch 69/400\n",
      "371/371 [==============================] - 0s 514us/step - loss: 0.2018 - mean_absolute_error: 0.2018 - val_loss: 0.1966 - val_mean_absolute_error: 0.1966\n",
      "Epoch 70/400\n",
      "371/371 [==============================] - 0s 578us/step - loss: 0.2011 - mean_absolute_error: 0.2011 - val_loss: 0.1987 - val_mean_absolute_error: 0.1987\n",
      "Epoch 71/400\n",
      "371/371 [==============================] - 0s 524us/step - loss: 0.2005 - mean_absolute_error: 0.2005 - val_loss: 0.2146 - val_mean_absolute_error: 0.2146\n",
      "Epoch 72/400\n",
      "371/371 [==============================] - 0s 524us/step - loss: 0.1997 - mean_absolute_error: 0.1997 - val_loss: 0.1998 - val_mean_absolute_error: 0.1998\n",
      "Epoch 73/400\n",
      "371/371 [==============================] - 0s 514us/step - loss: 0.1993 - mean_absolute_error: 0.1993 - val_loss: 0.1943 - val_mean_absolute_error: 0.1943\n",
      "Epoch 74/400\n",
      "371/371 [==============================] - 0s 519us/step - loss: 0.1985 - mean_absolute_error: 0.1985 - val_loss: 0.1955 - val_mean_absolute_error: 0.1955\n",
      "Epoch 75/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1981 - mean_absolute_error: 0.1981 - val_loss: 0.1994 - val_mean_absolute_error: 0.1994\n",
      "Epoch 76/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1977 - mean_absolute_error: 0.1977 - val_loss: 0.1872 - val_mean_absolute_error: 0.1872\n",
      "Epoch 77/400\n",
      "371/371 [==============================] - 0s 517us/step - loss: 0.1965 - mean_absolute_error: 0.1965 - val_loss: 0.1824 - val_mean_absolute_error: 0.1824\n",
      "Epoch 78/400\n",
      "371/371 [==============================] - 0s 632us/step - loss: 0.1962 - mean_absolute_error: 0.1962 - val_loss: 0.1899 - val_mean_absolute_error: 0.1899\n",
      "Epoch 79/400\n",
      "371/371 [==============================] - 0s 538us/step - loss: 0.1959 - mean_absolute_error: 0.1959 - val_loss: 0.2015 - val_mean_absolute_error: 0.2015\n",
      "Epoch 80/400\n",
      "371/371 [==============================] - 0s 589us/step - loss: 0.1951 - mean_absolute_error: 0.1951 - val_loss: 0.2044 - val_mean_absolute_error: 0.2044\n",
      "Epoch 81/400\n",
      "371/371 [==============================] - 0s 605us/step - loss: 0.1949 - mean_absolute_error: 0.1949 - val_loss: 0.1852 - val_mean_absolute_error: 0.1852\n",
      "Epoch 82/400\n",
      "371/371 [==============================] - 0s 551us/step - loss: 0.1944 - mean_absolute_error: 0.1944 - val_loss: 0.1843 - val_mean_absolute_error: 0.1843\n",
      "Epoch 83/400\n",
      "371/371 [==============================] - 0s 592us/step - loss: 0.1933 - mean_absolute_error: 0.1933 - val_loss: 0.2196 - val_mean_absolute_error: 0.2196\n",
      "Epoch 84/400\n",
      "371/371 [==============================] - 0s 683us/step - loss: 0.1932 - mean_absolute_error: 0.1932 - val_loss: 0.2145 - val_mean_absolute_error: 0.2145\n",
      "Epoch 85/400\n",
      "371/371 [==============================] - 0s 517us/step - loss: 0.1930 - mean_absolute_error: 0.1930 - val_loss: 0.1982 - val_mean_absolute_error: 0.1982\n",
      "Epoch 86/400\n",
      "371/371 [==============================] - 0s 509us/step - loss: 0.1923 - mean_absolute_error: 0.1923 - val_loss: 0.1800 - val_mean_absolute_error: 0.1800\n",
      "Epoch 87/400\n",
      "371/371 [==============================] - 0s 572us/step - loss: 0.1910 - mean_absolute_error: 0.1910 - val_loss: 0.1811 - val_mean_absolute_error: 0.1811\n",
      "Epoch 88/400\n",
      "371/371 [==============================] - 0s 529us/step - loss: 0.1907 - mean_absolute_error: 0.1907 - val_loss: 0.1955 - val_mean_absolute_error: 0.1955\n",
      "Epoch 89/400\n",
      "371/371 [==============================] - 0s 505us/step - loss: 0.1901 - mean_absolute_error: 0.1901 - val_loss: 0.1866 - val_mean_absolute_error: 0.1866\n",
      "Epoch 90/400\n",
      "371/371 [==============================] - 0s 508us/step - loss: 0.1902 - mean_absolute_error: 0.1902 - val_loss: 0.1830 - val_mean_absolute_error: 0.1830\n",
      "Epoch 91/400\n",
      "371/371 [==============================] - 0s 508us/step - loss: 0.1893 - mean_absolute_error: 0.1893 - val_loss: 0.1917 - val_mean_absolute_error: 0.1917\n",
      "Epoch 92/400\n",
      "371/371 [==============================] - 0s 517us/step - loss: 0.1892 - mean_absolute_error: 0.1892 - val_loss: 0.1809 - val_mean_absolute_error: 0.1809\n",
      "Epoch 93/400\n",
      "371/371 [==============================] - 0s 547us/step - loss: 0.1886 - mean_absolute_error: 0.1886 - val_loss: 0.1821 - val_mean_absolute_error: 0.1821\n",
      "Epoch 94/400\n",
      "371/371 [==============================] - 0s 508us/step - loss: 0.1871 - mean_absolute_error: 0.1871 - val_loss: 0.1867 - val_mean_absolute_error: 0.1867\n",
      "Epoch 95/400\n",
      "371/371 [==============================] - 0s 514us/step - loss: 0.1873 - mean_absolute_error: 0.1873 - val_loss: 0.1812 - val_mean_absolute_error: 0.1812\n",
      "Epoch 96/400\n",
      "371/371 [==============================] - 0s 507us/step - loss: 0.1868 - mean_absolute_error: 0.1868 - val_loss: 0.1952 - val_mean_absolute_error: 0.1952\n",
      "Epoch 97/400\n",
      "371/371 [==============================] - 0s 507us/step - loss: 0.1858 - mean_absolute_error: 0.1858 - val_loss: 0.1917 - val_mean_absolute_error: 0.1917\n",
      "Epoch 98/400\n",
      "371/371 [==============================] - 0s 510us/step - loss: 0.1857 - mean_absolute_error: 0.1857 - val_loss: 0.1857 - val_mean_absolute_error: 0.1857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/400\n",
      "371/371 [==============================] - 0s 511us/step - loss: 0.1853 - mean_absolute_error: 0.1853 - val_loss: 0.1912 - val_mean_absolute_error: 0.1912\n",
      "Epoch 100/400\n",
      "371/371 [==============================] - 0s 507us/step - loss: 0.1844 - mean_absolute_error: 0.1844 - val_loss: 0.1867 - val_mean_absolute_error: 0.1867\n",
      "Epoch 101/400\n",
      "371/371 [==============================] - 0s 504us/step - loss: 0.1836 - mean_absolute_error: 0.1836 - val_loss: 0.1818 - val_mean_absolute_error: 0.1818\n",
      "Epoch 102/400\n",
      "371/371 [==============================] - 0s 505us/step - loss: 0.1833 - mean_absolute_error: 0.1833 - val_loss: 0.1783 - val_mean_absolute_error: 0.1783\n",
      "Epoch 103/400\n",
      "371/371 [==============================] - 0s 507us/step - loss: 0.1828 - mean_absolute_error: 0.1828 - val_loss: 0.1751 - val_mean_absolute_error: 0.1751\n",
      "Epoch 104/400\n",
      "371/371 [==============================] - 0s 506us/step - loss: 0.1823 - mean_absolute_error: 0.1823 - val_loss: 0.1929 - val_mean_absolute_error: 0.1929\n",
      "Epoch 105/400\n",
      "371/371 [==============================] - 0s 504us/step - loss: 0.1812 - mean_absolute_error: 0.1812 - val_loss: 0.1825 - val_mean_absolute_error: 0.1825\n",
      "Epoch 106/400\n",
      "371/371 [==============================] - 0s 507us/step - loss: 0.1807 - mean_absolute_error: 0.1807 - val_loss: 0.1854 - val_mean_absolute_error: 0.1854\n",
      "Epoch 107/400\n",
      "371/371 [==============================] - 0s 511us/step - loss: 0.1805 - mean_absolute_error: 0.1805 - val_loss: 0.1755 - val_mean_absolute_error: 0.1755\n",
      "Epoch 108/400\n",
      "371/371 [==============================] - 0s 508us/step - loss: 0.1795 - mean_absolute_error: 0.1795 - val_loss: 0.1741 - val_mean_absolute_error: 0.1741\n",
      "Epoch 109/400\n",
      "371/371 [==============================] - 0s 506us/step - loss: 0.1790 - mean_absolute_error: 0.1790 - val_loss: 0.1774 - val_mean_absolute_error: 0.1774\n",
      "Epoch 110/400\n",
      "371/371 [==============================] - 0s 502us/step - loss: 0.1782 - mean_absolute_error: 0.1782 - val_loss: 0.1714 - val_mean_absolute_error: 0.1714\n",
      "Epoch 111/400\n",
      "371/371 [==============================] - 0s 506us/step - loss: 0.1772 - mean_absolute_error: 0.1772 - val_loss: 0.1741 - val_mean_absolute_error: 0.1741\n",
      "Epoch 112/400\n",
      "371/371 [==============================] - 0s 505us/step - loss: 0.1769 - mean_absolute_error: 0.1769 - val_loss: 0.1818 - val_mean_absolute_error: 0.1818\n",
      "Epoch 113/400\n",
      "371/371 [==============================] - 0s 505us/step - loss: 0.1765 - mean_absolute_error: 0.1765 - val_loss: 0.1979 - val_mean_absolute_error: 0.1979\n",
      "Epoch 114/400\n",
      "371/371 [==============================] - 0s 509us/step - loss: 0.1751 - mean_absolute_error: 0.1751 - val_loss: 0.1879 - val_mean_absolute_error: 0.1879\n",
      "Epoch 115/400\n",
      "371/371 [==============================] - 0s 510us/step - loss: 0.1745 - mean_absolute_error: 0.1745 - val_loss: 0.1815 - val_mean_absolute_error: 0.1815\n",
      "Epoch 116/400\n",
      "371/371 [==============================] - 0s 509us/step - loss: 0.1737 - mean_absolute_error: 0.1737 - val_loss: 0.1848 - val_mean_absolute_error: 0.1848\n",
      "Epoch 117/400\n",
      "371/371 [==============================] - 0s 509us/step - loss: 0.1730 - mean_absolute_error: 0.1730 - val_loss: 0.1767 - val_mean_absolute_error: 0.1767\n",
      "Epoch 118/400\n",
      "371/371 [==============================] - 0s 527us/step - loss: 0.1725 - mean_absolute_error: 0.1725 - val_loss: 0.1764 - val_mean_absolute_error: 0.1764\n",
      "Epoch 119/400\n",
      "371/371 [==============================] - 0s 508us/step - loss: 0.1717 - mean_absolute_error: 0.1717 - val_loss: 0.1690 - val_mean_absolute_error: 0.1690\n",
      "Epoch 120/400\n",
      "371/371 [==============================] - 0s 524us/step - loss: 0.1705 - mean_absolute_error: 0.1705 - val_loss: 0.1669 - val_mean_absolute_error: 0.1669\n",
      "Epoch 121/400\n",
      "371/371 [==============================] - 0s 533us/step - loss: 0.1699 - mean_absolute_error: 0.1699 - val_loss: 0.1654 - val_mean_absolute_error: 0.1654\n",
      "Epoch 122/400\n",
      "371/371 [==============================] - 0s 521us/step - loss: 0.1693 - mean_absolute_error: 0.1693 - val_loss: 0.1665 - val_mean_absolute_error: 0.1665\n",
      "Epoch 123/400\n",
      "371/371 [==============================] - 0s 512us/step - loss: 0.1684 - mean_absolute_error: 0.1684 - val_loss: 0.1745 - val_mean_absolute_error: 0.1745\n",
      "Epoch 124/400\n",
      "371/371 [==============================] - 0s 524us/step - loss: 0.1679 - mean_absolute_error: 0.1679 - val_loss: 0.1768 - val_mean_absolute_error: 0.1768\n",
      "Epoch 125/400\n",
      "371/371 [==============================] - 0s 530us/step - loss: 0.1670 - mean_absolute_error: 0.1670 - val_loss: 0.1566 - val_mean_absolute_error: 0.1566\n",
      "Epoch 126/400\n",
      "371/371 [==============================] - 0s 548us/step - loss: 0.1666 - mean_absolute_error: 0.1666 - val_loss: 0.1675 - val_mean_absolute_error: 0.1675\n",
      "Epoch 127/400\n",
      "371/371 [==============================] - 0s 528us/step - loss: 0.1659 - mean_absolute_error: 0.1659 - val_loss: 0.1583 - val_mean_absolute_error: 0.1583\n",
      "Epoch 128/400\n",
      "371/371 [==============================] - 0s 529us/step - loss: 0.1647 - mean_absolute_error: 0.1647 - val_loss: 0.1633 - val_mean_absolute_error: 0.1633\n",
      "Epoch 129/400\n",
      "371/371 [==============================] - 0s 545us/step - loss: 0.1639 - mean_absolute_error: 0.1639 - val_loss: 0.1647 - val_mean_absolute_error: 0.1647\n",
      "Epoch 130/400\n",
      "371/371 [==============================] - 0s 522us/step - loss: 0.1632 - mean_absolute_error: 0.1632 - val_loss: 0.1742 - val_mean_absolute_error: 0.1742\n",
      "Epoch 131/400\n",
      "371/371 [==============================] - 0s 508us/step - loss: 0.1630 - mean_absolute_error: 0.1630 - val_loss: 0.1624 - val_mean_absolute_error: 0.1624\n",
      "Epoch 132/400\n",
      "371/371 [==============================] - 0s 504us/step - loss: 0.1619 - mean_absolute_error: 0.1619 - val_loss: 0.1597 - val_mean_absolute_error: 0.1597\n",
      "Epoch 133/400\n",
      "371/371 [==============================] - 0s 522us/step - loss: 0.1615 - mean_absolute_error: 0.1615 - val_loss: 0.1615 - val_mean_absolute_error: 0.1615\n",
      "Epoch 134/400\n",
      "371/371 [==============================] - 0s 515us/step - loss: 0.1605 - mean_absolute_error: 0.1605 - val_loss: 0.1675 - val_mean_absolute_error: 0.1675\n",
      "Epoch 135/400\n",
      "371/371 [==============================] - 0s 510us/step - loss: 0.1600 - mean_absolute_error: 0.1600 - val_loss: 0.1561 - val_mean_absolute_error: 0.1561\n",
      "Epoch 136/400\n",
      "371/371 [==============================] - 0s 511us/step - loss: 0.1591 - mean_absolute_error: 0.1591 - val_loss: 0.1555 - val_mean_absolute_error: 0.1555\n",
      "Epoch 137/400\n",
      "371/371 [==============================] - 0s 517us/step - loss: 0.1590 - mean_absolute_error: 0.1590 - val_loss: 0.1641 - val_mean_absolute_error: 0.1641\n",
      "Epoch 138/400\n",
      "371/371 [==============================] - 0s 512us/step - loss: 0.1580 - mean_absolute_error: 0.1580 - val_loss: 0.1524 - val_mean_absolute_error: 0.1524\n",
      "Epoch 139/400\n",
      "371/371 [==============================] - 0s 514us/step - loss: 0.1573 - mean_absolute_error: 0.1573 - val_loss: 0.1555 - val_mean_absolute_error: 0.1555\n",
      "Epoch 140/400\n",
      "371/371 [==============================] - 0s 514us/step - loss: 0.1567 - mean_absolute_error: 0.1567 - val_loss: 0.1610 - val_mean_absolute_error: 0.1610\n",
      "Epoch 141/400\n",
      "371/371 [==============================] - 0s 514us/step - loss: 0.1563 - mean_absolute_error: 0.1563 - val_loss: 0.1586 - val_mean_absolute_error: 0.1586\n",
      "Epoch 142/400\n",
      "371/371 [==============================] - 0s 511us/step - loss: 0.1557 - mean_absolute_error: 0.1557 - val_loss: 0.1578 - val_mean_absolute_error: 0.1578\n",
      "Epoch 143/400\n",
      "371/371 [==============================] - 0s 507us/step - loss: 0.1551 - mean_absolute_error: 0.1551 - val_loss: 0.1531 - val_mean_absolute_error: 0.1531\n",
      "Epoch 144/400\n",
      "371/371 [==============================] - 0s 503us/step - loss: 0.1540 - mean_absolute_error: 0.1540 - val_loss: 0.1563 - val_mean_absolute_error: 0.1563\n",
      "Epoch 145/400\n",
      "371/371 [==============================] - 0s 512us/step - loss: 0.1539 - mean_absolute_error: 0.1539 - val_loss: 0.1605 - val_mean_absolute_error: 0.1605\n",
      "Epoch 146/400\n",
      "371/371 [==============================] - 0s 514us/step - loss: 0.1532 - mean_absolute_error: 0.1532 - val_loss: 0.1543 - val_mean_absolute_error: 0.1543\n",
      "Epoch 147/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371/371 [==============================] - 0s 515us/step - loss: 0.1529 - mean_absolute_error: 0.1529 - val_loss: 0.1698 - val_mean_absolute_error: 0.1698\n",
      "Epoch 148/400\n",
      "371/371 [==============================] - 0s 511us/step - loss: 0.1524 - mean_absolute_error: 0.1524 - val_loss: 0.1508 - val_mean_absolute_error: 0.1508\n",
      "Epoch 149/400\n",
      "371/371 [==============================] - 0s 504us/step - loss: 0.1517 - mean_absolute_error: 0.1517 - val_loss: 0.1455 - val_mean_absolute_error: 0.1455\n",
      "Epoch 150/400\n",
      "371/371 [==============================] - 0s 516us/step - loss: 0.1507 - mean_absolute_error: 0.1507 - val_loss: 0.1546 - val_mean_absolute_error: 0.1546\n",
      "Epoch 151/400\n",
      "371/371 [==============================] - 0s 515us/step - loss: 0.1509 - mean_absolute_error: 0.1509 - val_loss: 0.1474 - val_mean_absolute_error: 0.1474\n",
      "Epoch 152/400\n",
      "371/371 [==============================] - 0s 513us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1523 - val_mean_absolute_error: 0.1523\n",
      "Epoch 153/400\n",
      "371/371 [==============================] - 0s 512us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1455 - val_mean_absolute_error: 0.1455\n",
      "Epoch 154/400\n",
      "371/371 [==============================] - 0s 513us/step - loss: 0.1493 - mean_absolute_error: 0.1493 - val_loss: 0.1514 - val_mean_absolute_error: 0.1514\n",
      "Epoch 155/400\n",
      "371/371 [==============================] - 0s 513us/step - loss: 0.1487 - mean_absolute_error: 0.1487 - val_loss: 0.1508 - val_mean_absolute_error: 0.1508\n",
      "Epoch 156/400\n",
      "371/371 [==============================] - 0s 513us/step - loss: 0.1487 - mean_absolute_error: 0.1487 - val_loss: 0.1495 - val_mean_absolute_error: 0.1495\n",
      "Epoch 157/400\n",
      "371/371 [==============================] - 0s 515us/step - loss: 0.1481 - mean_absolute_error: 0.1481 - val_loss: 0.1512 - val_mean_absolute_error: 0.1512\n",
      "Epoch 158/400\n",
      "371/371 [==============================] - 0s 506us/step - loss: 0.1476 - mean_absolute_error: 0.1476 - val_loss: 0.1641 - val_mean_absolute_error: 0.1641\n",
      "Epoch 159/400\n",
      "371/371 [==============================] - 0s 508us/step - loss: 0.1473 - mean_absolute_error: 0.1473 - val_loss: 0.1443 - val_mean_absolute_error: 0.1443\n",
      "Epoch 160/400\n",
      "371/371 [==============================] - 0s 504us/step - loss: 0.1465 - mean_absolute_error: 0.1465 - val_loss: 0.1439 - val_mean_absolute_error: 0.1439\n",
      "Epoch 161/400\n",
      "371/371 [==============================] - 0s 508us/step - loss: 0.1461 - mean_absolute_error: 0.1461 - val_loss: 0.1423 - val_mean_absolute_error: 0.1423\n",
      "Epoch 162/400\n",
      "371/371 [==============================] - 0s 507us/step - loss: 0.1462 - mean_absolute_error: 0.1462 - val_loss: 0.1452 - val_mean_absolute_error: 0.1452\n",
      "Epoch 163/400\n",
      "371/371 [==============================] - 0s 505us/step - loss: 0.1454 - mean_absolute_error: 0.1454 - val_loss: 0.1508 - val_mean_absolute_error: 0.1508\n",
      "Epoch 164/400\n",
      "371/371 [==============================] - 0s 515us/step - loss: 0.1452 - mean_absolute_error: 0.1452 - val_loss: 0.1459 - val_mean_absolute_error: 0.1459\n",
      "Epoch 165/400\n",
      "371/371 [==============================] - 0s 508us/step - loss: 0.1447 - mean_absolute_error: 0.1447 - val_loss: 0.1552 - val_mean_absolute_error: 0.1552\n",
      "Epoch 166/400\n",
      "371/371 [==============================] - 0s 510us/step - loss: 0.1444 - mean_absolute_error: 0.1444 - val_loss: 0.1487 - val_mean_absolute_error: 0.1487\n",
      "Epoch 167/400\n",
      "371/371 [==============================] - 0s 514us/step - loss: 0.1441 - mean_absolute_error: 0.1441 - val_loss: 0.1446 - val_mean_absolute_error: 0.1446\n",
      "Epoch 168/400\n",
      "371/371 [==============================] - 0s 514us/step - loss: 0.1438 - mean_absolute_error: 0.1438 - val_loss: 0.1436 - val_mean_absolute_error: 0.1436\n",
      "Epoch 169/400\n",
      "371/371 [==============================] - 0s 506us/step - loss: 0.1437 - mean_absolute_error: 0.1437 - val_loss: 0.1506 - val_mean_absolute_error: 0.1506\n",
      "Epoch 170/400\n",
      "371/371 [==============================] - 0s 515us/step - loss: 0.1432 - mean_absolute_error: 0.1432 - val_loss: 0.1420 - val_mean_absolute_error: 0.1420\n",
      "Epoch 171/400\n",
      "371/371 [==============================] - 0s 513us/step - loss: 0.1428 - mean_absolute_error: 0.1428 - val_loss: 0.1345 - val_mean_absolute_error: 0.1345\n",
      "Epoch 172/400\n",
      "371/371 [==============================] - 0s 510us/step - loss: 0.1420 - mean_absolute_error: 0.1420 - val_loss: 0.1428 - val_mean_absolute_error: 0.1428\n",
      "Epoch 173/400\n",
      "371/371 [==============================] - 0s 503us/step - loss: 0.1419 - mean_absolute_error: 0.1419 - val_loss: 0.1421 - val_mean_absolute_error: 0.1421\n",
      "Epoch 174/400\n",
      "371/371 [==============================] - 0s 514us/step - loss: 0.1415 - mean_absolute_error: 0.1415 - val_loss: 0.1461 - val_mean_absolute_error: 0.1461\n",
      "Epoch 175/400\n",
      "371/371 [==============================] - 0s 510us/step - loss: 0.1413 - mean_absolute_error: 0.1413 - val_loss: 0.1389 - val_mean_absolute_error: 0.1389\n",
      "Epoch 176/400\n",
      "371/371 [==============================] - 0s 518us/step - loss: 0.1407 - mean_absolute_error: 0.1407 - val_loss: 0.1356 - val_mean_absolute_error: 0.1356\n",
      "Epoch 177/400\n",
      "371/371 [==============================] - 0s 516us/step - loss: 0.1406 - mean_absolute_error: 0.1406 - val_loss: 0.1430 - val_mean_absolute_error: 0.1430\n",
      "Epoch 178/400\n",
      "371/371 [==============================] - 0s 512us/step - loss: 0.1405 - mean_absolute_error: 0.1405 - val_loss: 0.1459 - val_mean_absolute_error: 0.1459\n",
      "Epoch 179/400\n",
      "371/371 [==============================] - 0s 512us/step - loss: 0.1398 - mean_absolute_error: 0.1398 - val_loss: 0.1400 - val_mean_absolute_error: 0.1400\n",
      "Epoch 180/400\n",
      "371/371 [==============================] - 0s 509us/step - loss: 0.1397 - mean_absolute_error: 0.1397 - val_loss: 0.1425 - val_mean_absolute_error: 0.1425\n",
      "Epoch 181/400\n",
      "371/371 [==============================] - 0s 516us/step - loss: 0.1394 - mean_absolute_error: 0.1394 - val_loss: 0.1364 - val_mean_absolute_error: 0.1364\n",
      "Epoch 182/400\n",
      "371/371 [==============================] - 0s 513us/step - loss: 0.1393 - mean_absolute_error: 0.1393 - val_loss: 0.1345 - val_mean_absolute_error: 0.1345\n",
      "Epoch 183/400\n",
      "371/371 [==============================] - 0s 507us/step - loss: 0.1388 - mean_absolute_error: 0.1388 - val_loss: 0.1495 - val_mean_absolute_error: 0.1495\n",
      "Epoch 184/400\n",
      "371/371 [==============================] - 0s 509us/step - loss: 0.1392 - mean_absolute_error: 0.1392 - val_loss: 0.1416 - val_mean_absolute_error: 0.1416\n",
      "Epoch 185/400\n",
      "371/371 [==============================] - 0s 510us/step - loss: 0.1385 - mean_absolute_error: 0.1385 - val_loss: 0.1524 - val_mean_absolute_error: 0.1524\n",
      "Epoch 186/400\n",
      "371/371 [==============================] - 0s 506us/step - loss: 0.1379 - mean_absolute_error: 0.1379 - val_loss: 0.1417 - val_mean_absolute_error: 0.1417\n",
      "Epoch 187/400\n",
      "371/371 [==============================] - 0s 516us/step - loss: 0.1377 - mean_absolute_error: 0.1377 - val_loss: 0.1419 - val_mean_absolute_error: 0.1419\n",
      "Epoch 188/400\n",
      "371/371 [==============================] - 0s 511us/step - loss: 0.1375 - mean_absolute_error: 0.1375 - val_loss: 0.1420 - val_mean_absolute_error: 0.1420\n",
      "Epoch 189/400\n",
      "371/371 [==============================] - 0s 508us/step - loss: 0.1372 - mean_absolute_error: 0.1372 - val_loss: 0.1367 - val_mean_absolute_error: 0.1367\n",
      "Epoch 190/400\n",
      "371/371 [==============================] - 0s 507us/step - loss: 0.1366 - mean_absolute_error: 0.1366 - val_loss: 0.1396 - val_mean_absolute_error: 0.1396\n",
      "Epoch 191/400\n",
      "371/371 [==============================] - 0s 511us/step - loss: 0.1366 - mean_absolute_error: 0.1366 - val_loss: 0.1416 - val_mean_absolute_error: 0.1416\n",
      "Epoch 192/400\n",
      "371/371 [==============================] - 0s 506us/step - loss: 0.1363 - mean_absolute_error: 0.1363 - val_loss: 0.1377 - val_mean_absolute_error: 0.1377\n",
      "Epoch 193/400\n",
      "371/371 [==============================] - 0s 609us/step - loss: 0.1362 - mean_absolute_error: 0.1362 - val_loss: 0.1364 - val_mean_absolute_error: 0.1364\n",
      "Epoch 194/400\n",
      "371/371 [==============================] - 0s 573us/step - loss: 0.1361 - mean_absolute_error: 0.1361 - val_loss: 0.1440 - val_mean_absolute_error: 0.1440\n",
      "Epoch 195/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371/371 [==============================] - 0s 535us/step - loss: 0.1361 - mean_absolute_error: 0.1361 - val_loss: 0.1341 - val_mean_absolute_error: 0.1341\n",
      "Epoch 196/400\n",
      "371/371 [==============================] - 0s 512us/step - loss: 0.1354 - mean_absolute_error: 0.1354 - val_loss: 0.1397 - val_mean_absolute_error: 0.1397\n",
      "Epoch 197/400\n",
      "371/371 [==============================] - 0s 509us/step - loss: 0.1352 - mean_absolute_error: 0.1352 - val_loss: 0.1390 - val_mean_absolute_error: 0.1390\n",
      "Epoch 198/400\n",
      "371/371 [==============================] - 0s 506us/step - loss: 0.1348 - mean_absolute_error: 0.1348 - val_loss: 0.1401 - val_mean_absolute_error: 0.1401\n",
      "Epoch 199/400\n",
      "371/371 [==============================] - 0s 505us/step - loss: 0.1349 - mean_absolute_error: 0.1349 - val_loss: 0.1317 - val_mean_absolute_error: 0.1317\n",
      "Epoch 200/400\n",
      "371/371 [==============================] - 0s 515us/step - loss: 0.1344 - mean_absolute_error: 0.1344 - val_loss: 0.1434 - val_mean_absolute_error: 0.1434\n",
      "Epoch 201/400\n",
      "371/371 [==============================] - 0s 507us/step - loss: 0.1342 - mean_absolute_error: 0.1342 - val_loss: 0.1373 - val_mean_absolute_error: 0.1373\n",
      "Epoch 202/400\n",
      "371/371 [==============================] - 0s 509us/step - loss: 0.1340 - mean_absolute_error: 0.1340 - val_loss: 0.1418 - val_mean_absolute_error: 0.1418\n",
      "Epoch 203/400\n",
      "371/371 [==============================] - 0s 508us/step - loss: 0.1336 - mean_absolute_error: 0.1336 - val_loss: 0.1370 - val_mean_absolute_error: 0.1370\n",
      "Epoch 204/400\n",
      "371/371 [==============================] - 0s 513us/step - loss: 0.1339 - mean_absolute_error: 0.1339 - val_loss: 0.1369 - val_mean_absolute_error: 0.1369\n",
      "Epoch 205/400\n",
      "371/371 [==============================] - 0s 511us/step - loss: 0.1337 - mean_absolute_error: 0.1337 - val_loss: 0.1298 - val_mean_absolute_error: 0.1298\n",
      "Epoch 206/400\n",
      "371/371 [==============================] - 0s 506us/step - loss: 0.1335 - mean_absolute_error: 0.1335 - val_loss: 0.1418 - val_mean_absolute_error: 0.1418\n",
      "Epoch 207/400\n",
      "371/371 [==============================] - 0s 506us/step - loss: 0.1330 - mean_absolute_error: 0.1330 - val_loss: 0.1326 - val_mean_absolute_error: 0.1326\n",
      "Epoch 208/400\n",
      "371/371 [==============================] - 0s 507us/step - loss: 0.1324 - mean_absolute_error: 0.1324 - val_loss: 0.1353 - val_mean_absolute_error: 0.1353\n",
      "Epoch 209/400\n",
      "371/371 [==============================] - 0s 512us/step - loss: 0.1324 - mean_absolute_error: 0.1324 - val_loss: 0.1258 - val_mean_absolute_error: 0.1258\n",
      "Epoch 210/400\n",
      "371/371 [==============================] - 0s 512us/step - loss: 0.1323 - mean_absolute_error: 0.1323 - val_loss: 0.1442 - val_mean_absolute_error: 0.1442\n",
      "Epoch 211/400\n",
      "371/371 [==============================] - 0s 512us/step - loss: 0.1323 - mean_absolute_error: 0.1323 - val_loss: 0.1499 - val_mean_absolute_error: 0.1499\n",
      "Epoch 212/400\n",
      "371/371 [==============================] - 0s 508us/step - loss: 0.1322 - mean_absolute_error: 0.1322 - val_loss: 0.1445 - val_mean_absolute_error: 0.1445\n",
      "Epoch 213/400\n",
      "371/371 [==============================] - 0s 509us/step - loss: 0.1319 - mean_absolute_error: 0.1319 - val_loss: 0.1415 - val_mean_absolute_error: 0.1415\n",
      "Epoch 214/400\n",
      "371/371 [==============================] - 0s 511us/step - loss: 0.1312 - mean_absolute_error: 0.1312 - val_loss: 0.1431 - val_mean_absolute_error: 0.1431\n",
      "Epoch 215/400\n",
      "371/371 [==============================] - 0s 511us/step - loss: 0.1311 - mean_absolute_error: 0.1311 - val_loss: 0.1400 - val_mean_absolute_error: 0.1400\n",
      "Epoch 216/400\n",
      "371/371 [==============================] - 0s 511us/step - loss: 0.1310 - mean_absolute_error: 0.1310 - val_loss: 0.1291 - val_mean_absolute_error: 0.1291\n",
      "Epoch 217/400\n",
      "371/371 [==============================] - 0s 507us/step - loss: 0.1306 - mean_absolute_error: 0.1306 - val_loss: 0.1400 - val_mean_absolute_error: 0.1400\n",
      "Epoch 218/400\n",
      "371/371 [==============================] - 0s 506us/step - loss: 0.1307 - mean_absolute_error: 0.1307 - val_loss: 0.1340 - val_mean_absolute_error: 0.1340\n",
      "Epoch 219/400\n",
      "371/371 [==============================] - 0s 510us/step - loss: 0.1305 - mean_absolute_error: 0.1305 - val_loss: 0.1324 - val_mean_absolute_error: 0.1324\n",
      "Epoch 220/400\n",
      "371/371 [==============================] - 0s 509us/step - loss: 0.1305 - mean_absolute_error: 0.1305 - val_loss: 0.1340 - val_mean_absolute_error: 0.1340\n",
      "Epoch 221/400\n",
      "371/371 [==============================] - 0s 507us/step - loss: 0.1299 - mean_absolute_error: 0.1299 - val_loss: 0.1299 - val_mean_absolute_error: 0.1299\n",
      "Epoch 222/400\n",
      "371/371 [==============================] - 0s 508us/step - loss: 0.1302 - mean_absolute_error: 0.1302 - val_loss: 0.1277 - val_mean_absolute_error: 0.1277\n",
      "Epoch 223/400\n",
      "371/371 [==============================] - 0s 513us/step - loss: 0.1299 - mean_absolute_error: 0.1299 - val_loss: 0.1334 - val_mean_absolute_error: 0.1334\n",
      "Epoch 224/400\n",
      "371/371 [==============================] - 0s 513us/step - loss: 0.1292 - mean_absolute_error: 0.1292 - val_loss: 0.1381 - val_mean_absolute_error: 0.1381\n",
      "Epoch 225/400\n",
      "371/371 [==============================] - 0s 515us/step - loss: 0.1296 - mean_absolute_error: 0.1296 - val_loss: 0.1322 - val_mean_absolute_error: 0.1322\n",
      "Epoch 226/400\n",
      "371/371 [==============================] - 0s 510us/step - loss: 0.1292 - mean_absolute_error: 0.1292 - val_loss: 0.1285 - val_mean_absolute_error: 0.1285\n",
      "Epoch 227/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1292 - mean_absolute_error: 0.1292 - val_loss: 0.1352 - val_mean_absolute_error: 0.1352\n",
      "Epoch 228/400\n",
      "371/371 [==============================] - 0s 504us/step - loss: 0.1290 - mean_absolute_error: 0.1290 - val_loss: 0.1257 - val_mean_absolute_error: 0.1257\n",
      "Epoch 229/400\n",
      "371/371 [==============================] - 0s 507us/step - loss: 0.1285 - mean_absolute_error: 0.1285 - val_loss: 0.1242 - val_mean_absolute_error: 0.1242\n",
      "Epoch 230/400\n",
      "371/371 [==============================] - 0s 507us/step - loss: 0.1284 - mean_absolute_error: 0.1284 - val_loss: 0.1406 - val_mean_absolute_error: 0.1406\n",
      "Epoch 231/400\n",
      "371/371 [==============================] - 0s 505us/step - loss: 0.1282 - mean_absolute_error: 0.1282 - val_loss: 0.1288 - val_mean_absolute_error: 0.1288\n",
      "Epoch 232/400\n",
      "371/371 [==============================] - 0s 526us/step - loss: 0.1282 - mean_absolute_error: 0.1282 - val_loss: 0.1294 - val_mean_absolute_error: 0.1294\n",
      "Epoch 233/400\n",
      "371/371 [==============================] - 0s 664us/step - loss: 0.1279 - mean_absolute_error: 0.1279 - val_loss: 0.1268 - val_mean_absolute_error: 0.1268\n",
      "Epoch 234/400\n",
      "371/371 [==============================] - 0s 552us/step - loss: 0.1276 - mean_absolute_error: 0.1276 - val_loss: 0.1310 - val_mean_absolute_error: 0.1310\n",
      "Epoch 235/400\n",
      "371/371 [==============================] - 0s 583us/step - loss: 0.1277 - mean_absolute_error: 0.1277 - val_loss: 0.1307 - val_mean_absolute_error: 0.1307\n",
      "Epoch 236/400\n",
      "371/371 [==============================] - 0s 506us/step - loss: 0.1275 - mean_absolute_error: 0.1275 - val_loss: 0.1292 - val_mean_absolute_error: 0.1292\n",
      "Epoch 237/400\n",
      "371/371 [==============================] - 0s 506us/step - loss: 0.1273 - mean_absolute_error: 0.1273 - val_loss: 0.1338 - val_mean_absolute_error: 0.1338\n",
      "Epoch 238/400\n",
      "371/371 [==============================] - 0s 533us/step - loss: 0.1269 - mean_absolute_error: 0.1269 - val_loss: 0.1234 - val_mean_absolute_error: 0.1234\n",
      "Epoch 239/400\n",
      "371/371 [==============================] - 0s 546us/step - loss: 0.1267 - mean_absolute_error: 0.1267 - val_loss: 0.1275 - val_mean_absolute_error: 0.1275\n",
      "Epoch 240/400\n",
      "371/371 [==============================] - 0s 533us/step - loss: 0.1266 - mean_absolute_error: 0.1266 - val_loss: 0.1216 - val_mean_absolute_error: 0.1216\n",
      "Epoch 241/400\n",
      "371/371 [==============================] - 0s 665us/step - loss: 0.1264 - mean_absolute_error: 0.1264 - val_loss: 0.1338 - val_mean_absolute_error: 0.1338\n",
      "Epoch 242/400\n",
      "371/371 [==============================] - 0s 598us/step - loss: 0.1260 - mean_absolute_error: 0.1260 - val_loss: 0.1241 - val_mean_absolute_error: 0.1241\n",
      "Epoch 243/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371/371 [==============================] - 0s 562us/step - loss: 0.1266 - mean_absolute_error: 0.1266 - val_loss: 0.1237 - val_mean_absolute_error: 0.1237\n",
      "Epoch 244/400\n",
      "371/371 [==============================] - 0s 512us/step - loss: 0.1263 - mean_absolute_error: 0.1263 - val_loss: 0.1188 - val_mean_absolute_error: 0.1188\n",
      "Epoch 245/400\n",
      "371/371 [==============================] - 0s 593us/step - loss: 0.1260 - mean_absolute_error: 0.1260 - val_loss: 0.1302 - val_mean_absolute_error: 0.1302\n",
      "Epoch 246/400\n",
      "371/371 [==============================] - 0s 535us/step - loss: 0.1257 - mean_absolute_error: 0.1257 - val_loss: 0.1340 - val_mean_absolute_error: 0.1340\n",
      "Epoch 247/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1256 - mean_absolute_error: 0.1256 - val_loss: 0.1295 - val_mean_absolute_error: 0.1295\n",
      "Epoch 248/400\n",
      "371/371 [==============================] - 0s 512us/step - loss: 0.1256 - mean_absolute_error: 0.1256 - val_loss: 0.1229 - val_mean_absolute_error: 0.1229\n",
      "Epoch 249/400\n",
      "371/371 [==============================] - 0s 556us/step - loss: 0.1253 - mean_absolute_error: 0.1253 - val_loss: 0.1383 - val_mean_absolute_error: 0.1383\n",
      "Epoch 250/400\n",
      "371/371 [==============================] - 0s 574us/step - loss: 0.1251 - mean_absolute_error: 0.1251 - val_loss: 0.1391 - val_mean_absolute_error: 0.1391\n",
      "Epoch 251/400\n",
      "371/371 [==============================] - 0s 518us/step - loss: 0.1250 - mean_absolute_error: 0.1250 - val_loss: 0.1212 - val_mean_absolute_error: 0.1212\n",
      "Epoch 252/400\n",
      "371/371 [==============================] - 0s 517us/step - loss: 0.1250 - mean_absolute_error: 0.1250 - val_loss: 0.1278 - val_mean_absolute_error: 0.1278\n",
      "Epoch 253/400\n",
      "371/371 [==============================] - 0s 517us/step - loss: 0.1246 - mean_absolute_error: 0.1246 - val_loss: 0.1215 - val_mean_absolute_error: 0.1215\n",
      "Epoch 254/400\n",
      "371/371 [==============================] - 0s 515us/step - loss: 0.1244 - mean_absolute_error: 0.1244 - val_loss: 0.1231 - val_mean_absolute_error: 0.1231\n",
      "Epoch 255/400\n",
      "371/371 [==============================] - 0s 536us/step - loss: 0.1243 - mean_absolute_error: 0.1243 - val_loss: 0.1327 - val_mean_absolute_error: 0.1327\n",
      "Epoch 256/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1245 - mean_absolute_error: 0.1245 - val_loss: 0.1321 - val_mean_absolute_error: 0.1321\n",
      "Epoch 257/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1242 - mean_absolute_error: 0.1242 - val_loss: 0.1311 - val_mean_absolute_error: 0.1311\n",
      "Epoch 258/400\n",
      "371/371 [==============================] - 0s 516us/step - loss: 0.1241 - mean_absolute_error: 0.1241 - val_loss: 0.1259 - val_mean_absolute_error: 0.1259\n",
      "Epoch 259/400\n",
      "371/371 [==============================] - 0s 518us/step - loss: 0.1239 - mean_absolute_error: 0.1239 - val_loss: 0.1290 - val_mean_absolute_error: 0.1290\n",
      "Epoch 260/400\n",
      "371/371 [==============================] - 0s 522us/step - loss: 0.1240 - mean_absolute_error: 0.1240 - val_loss: 0.1252 - val_mean_absolute_error: 0.1252\n",
      "Epoch 261/400\n",
      "371/371 [==============================] - 0s 517us/step - loss: 0.1233 - mean_absolute_error: 0.1233 - val_loss: 0.1257 - val_mean_absolute_error: 0.1257\n",
      "Epoch 262/400\n",
      "371/371 [==============================] - 0s 519us/step - loss: 0.1236 - mean_absolute_error: 0.1236 - val_loss: 0.1339 - val_mean_absolute_error: 0.1339\n",
      "Epoch 263/400\n",
      "371/371 [==============================] - 0s 518us/step - loss: 0.1234 - mean_absolute_error: 0.1234 - val_loss: 0.1241 - val_mean_absolute_error: 0.1241\n",
      "Epoch 264/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1230 - mean_absolute_error: 0.1230 - val_loss: 0.1211 - val_mean_absolute_error: 0.1211\n",
      "Epoch 265/400\n",
      "371/371 [==============================] - 0s 528us/step - loss: 0.1233 - mean_absolute_error: 0.1233 - val_loss: 0.1222 - val_mean_absolute_error: 0.1222\n",
      "Epoch 266/400\n",
      "371/371 [==============================] - 0s 521us/step - loss: 0.1231 - mean_absolute_error: 0.1231 - val_loss: 0.1270 - val_mean_absolute_error: 0.1270\n",
      "Epoch 267/400\n",
      "371/371 [==============================] - 0s 516us/step - loss: 0.1230 - mean_absolute_error: 0.1230 - val_loss: 0.1274 - val_mean_absolute_error: 0.1274\n",
      "Epoch 268/400\n",
      "371/371 [==============================] - 0s 523us/step - loss: 0.1228 - mean_absolute_error: 0.1228 - val_loss: 0.1241 - val_mean_absolute_error: 0.1241\n",
      "Epoch 269/400\n",
      "371/371 [==============================] - 0s 539us/step - loss: 0.1224 - mean_absolute_error: 0.1224 - val_loss: 0.1338 - val_mean_absolute_error: 0.1338\n",
      "Epoch 270/400\n",
      "371/371 [==============================] - 0s 524us/step - loss: 0.1227 - mean_absolute_error: 0.1227 - val_loss: 0.1221 - val_mean_absolute_error: 0.1221\n",
      "Epoch 271/400\n",
      "371/371 [==============================] - 0s 559us/step - loss: 0.1227 - mean_absolute_error: 0.1227 - val_loss: 0.1274 - val_mean_absolute_error: 0.1274\n",
      "Epoch 272/400\n",
      "371/371 [==============================] - 0s 524us/step - loss: 0.1218 - mean_absolute_error: 0.1218 - val_loss: 0.1260 - val_mean_absolute_error: 0.1260\n",
      "Epoch 273/400\n",
      "371/371 [==============================] - 0s 519us/step - loss: 0.1221 - mean_absolute_error: 0.1221 - val_loss: 0.1307 - val_mean_absolute_error: 0.1307\n",
      "Epoch 274/400\n",
      "371/371 [==============================] - 0s 517us/step - loss: 0.1221 - mean_absolute_error: 0.1221 - val_loss: 0.1279 - val_mean_absolute_error: 0.1279\n",
      "Epoch 275/400\n",
      "371/371 [==============================] - 0s 524us/step - loss: 0.1218 - mean_absolute_error: 0.1218 - val_loss: 0.1330 - val_mean_absolute_error: 0.1330\n",
      "Epoch 276/400\n",
      "371/371 [==============================] - 0s 518us/step - loss: 0.1218 - mean_absolute_error: 0.1218 - val_loss: 0.1309 - val_mean_absolute_error: 0.1309\n",
      "Epoch 277/400\n",
      "371/371 [==============================] - 0s 526us/step - loss: 0.1217 - mean_absolute_error: 0.1217 - val_loss: 0.1294 - val_mean_absolute_error: 0.1294\n",
      "Epoch 278/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1214 - mean_absolute_error: 0.1214 - val_loss: 0.1300 - val_mean_absolute_error: 0.1300\n",
      "Epoch 279/400\n",
      "371/371 [==============================] - 0s 523us/step - loss: 0.1215 - mean_absolute_error: 0.1215 - val_loss: 0.1279 - val_mean_absolute_error: 0.1279\n",
      "Epoch 280/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1212 - mean_absolute_error: 0.1212 - val_loss: 0.1258 - val_mean_absolute_error: 0.1258\n",
      "Epoch 281/400\n",
      "371/371 [==============================] - 0s 516us/step - loss: 0.1208 - mean_absolute_error: 0.1208 - val_loss: 0.1161 - val_mean_absolute_error: 0.1161\n",
      "Epoch 282/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1210 - mean_absolute_error: 0.1210 - val_loss: 0.1205 - val_mean_absolute_error: 0.1205\n",
      "Epoch 283/400\n",
      "371/371 [==============================] - 0s 517us/step - loss: 0.1210 - mean_absolute_error: 0.1210 - val_loss: 0.1203 - val_mean_absolute_error: 0.1203\n",
      "Epoch 284/400\n",
      "371/371 [==============================] - 0s 522us/step - loss: 0.1209 - mean_absolute_error: 0.1209 - val_loss: 0.1273 - val_mean_absolute_error: 0.1273\n",
      "Epoch 285/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1208 - mean_absolute_error: 0.1208 - val_loss: 0.1204 - val_mean_absolute_error: 0.1204\n",
      "Epoch 286/400\n",
      "371/371 [==============================] - 0s 521us/step - loss: 0.1205 - mean_absolute_error: 0.1205 - val_loss: 0.1279 - val_mean_absolute_error: 0.1279\n",
      "Epoch 287/400\n",
      "371/371 [==============================] - 0s 519us/step - loss: 0.1205 - mean_absolute_error: 0.1205 - val_loss: 0.1257 - val_mean_absolute_error: 0.1257\n",
      "Epoch 288/400\n",
      "371/371 [==============================] - 0s 525us/step - loss: 0.1206 - mean_absolute_error: 0.1206 - val_loss: 0.1133 - val_mean_absolute_error: 0.1133\n",
      "Epoch 289/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1202 - mean_absolute_error: 0.1202 - val_loss: 0.1267 - val_mean_absolute_error: 0.1267\n",
      "Epoch 290/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1199 - mean_absolute_error: 0.1199 - val_loss: 0.1170 - val_mean_absolute_error: 0.1170\n",
      "Epoch 291/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371/371 [==============================] - 0s 523us/step - loss: 0.1205 - mean_absolute_error: 0.1205 - val_loss: 0.1227 - val_mean_absolute_error: 0.1227\n",
      "Epoch 292/400\n",
      "371/371 [==============================] - 0s 511us/step - loss: 0.1200 - mean_absolute_error: 0.1200 - val_loss: 0.1303 - val_mean_absolute_error: 0.1303\n",
      "Epoch 293/400\n",
      "371/371 [==============================] - 0s 516us/step - loss: 0.1195 - mean_absolute_error: 0.1195 - val_loss: 0.1211 - val_mean_absolute_error: 0.1211\n",
      "Epoch 294/400\n",
      "371/371 [==============================] - 0s 531us/step - loss: 0.1199 - mean_absolute_error: 0.1199 - val_loss: 0.1177 - val_mean_absolute_error: 0.1177\n",
      "Epoch 295/400\n",
      "371/371 [==============================] - 0s 513us/step - loss: 0.1198 - mean_absolute_error: 0.1198 - val_loss: 0.1243 - val_mean_absolute_error: 0.1243\n",
      "Epoch 296/400\n",
      "371/371 [==============================] - 0s 511us/step - loss: 0.1193 - mean_absolute_error: 0.1193 - val_loss: 0.1170 - val_mean_absolute_error: 0.1170\n",
      "Epoch 297/400\n",
      "371/371 [==============================] - 0s 519us/step - loss: 0.1191 - mean_absolute_error: 0.1191 - val_loss: 0.1218 - val_mean_absolute_error: 0.1218\n",
      "Epoch 298/400\n",
      "371/371 [==============================] - 0s 518us/step - loss: 0.1191 - mean_absolute_error: 0.1191 - val_loss: 0.1231 - val_mean_absolute_error: 0.1231\n",
      "Epoch 299/400\n",
      "371/371 [==============================] - 0s 591us/step - loss: 0.1193 - mean_absolute_error: 0.1193 - val_loss: 0.1239 - val_mean_absolute_error: 0.1239\n",
      "Epoch 300/400\n",
      "371/371 [==============================] - 0s 592us/step - loss: 0.1190 - mean_absolute_error: 0.1190 - val_loss: 0.1169 - val_mean_absolute_error: 0.1169\n",
      "Epoch 301/400\n",
      "371/371 [==============================] - 0s 595us/step - loss: 0.1192 - mean_absolute_error: 0.1192 - val_loss: 0.1215 - val_mean_absolute_error: 0.1215\n",
      "Epoch 302/400\n",
      "371/371 [==============================] - 0s 639us/step - loss: 0.1190 - mean_absolute_error: 0.1190 - val_loss: 0.1248 - val_mean_absolute_error: 0.1248\n",
      "Epoch 303/400\n",
      "371/371 [==============================] - 0s 580us/step - loss: 0.1188 - mean_absolute_error: 0.1188 - val_loss: 0.1242 - val_mean_absolute_error: 0.1242\n",
      "Epoch 304/400\n",
      "371/371 [==============================] - 0s 667us/step - loss: 0.1187 - mean_absolute_error: 0.1187 - val_loss: 0.1345 - val_mean_absolute_error: 0.1345\n",
      "Epoch 305/400\n",
      "371/371 [==============================] - 0s 523us/step - loss: 0.1186 - mean_absolute_error: 0.1186 - val_loss: 0.1197 - val_mean_absolute_error: 0.1197\n",
      "Epoch 306/400\n",
      "371/371 [==============================] - 0s 509us/step - loss: 0.1185 - mean_absolute_error: 0.1185 - val_loss: 0.1267 - val_mean_absolute_error: 0.1267\n",
      "Epoch 307/400\n",
      "371/371 [==============================] - 0s 625us/step - loss: 0.1183 - mean_absolute_error: 0.1183 - val_loss: 0.1183 - val_mean_absolute_error: 0.1183\n",
      "Epoch 308/400\n",
      "371/371 [==============================] - 0s 645us/step - loss: 0.1181 - mean_absolute_error: 0.1181 - val_loss: 0.1176 - val_mean_absolute_error: 0.1176\n",
      "Epoch 309/400\n",
      "371/371 [==============================] - 0s 557us/step - loss: 0.1181 - mean_absolute_error: 0.1181 - val_loss: 0.1207 - val_mean_absolute_error: 0.1207\n",
      "Epoch 310/400\n",
      "371/371 [==============================] - 0s 541us/step - loss: 0.1183 - mean_absolute_error: 0.1183 - val_loss: 0.1201 - val_mean_absolute_error: 0.1201\n",
      "Epoch 311/400\n",
      "371/371 [==============================] - 0s 540us/step - loss: 0.1175 - mean_absolute_error: 0.1175 - val_loss: 0.1187 - val_mean_absolute_error: 0.1187\n",
      "Epoch 312/400\n",
      "371/371 [==============================] - 0s 669us/step - loss: 0.1176 - mean_absolute_error: 0.1176 - val_loss: 0.1174 - val_mean_absolute_error: 0.1174\n",
      "Epoch 313/400\n",
      "371/371 [==============================] - 0s 560us/step - loss: 0.1178 - mean_absolute_error: 0.1178 - val_loss: 0.1207 - val_mean_absolute_error: 0.1207\n",
      "Epoch 314/400\n",
      "371/371 [==============================] - 0s 517us/step - loss: 0.1176 - mean_absolute_error: 0.1176 - val_loss: 0.1266 - val_mean_absolute_error: 0.1266\n",
      "Epoch 315/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1175 - mean_absolute_error: 0.1175 - val_loss: 0.1276 - val_mean_absolute_error: 0.1276\n",
      "Epoch 316/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1177 - mean_absolute_error: 0.1177 - val_loss: 0.1268 - val_mean_absolute_error: 0.1268\n",
      "Epoch 317/400\n",
      "371/371 [==============================] - 0s 517us/step - loss: 0.1173 - mean_absolute_error: 0.1173 - val_loss: 0.1296 - val_mean_absolute_error: 0.1296\n",
      "Epoch 318/400\n",
      "371/371 [==============================] - 0s 519us/step - loss: 0.1174 - mean_absolute_error: 0.1174 - val_loss: 0.1166 - val_mean_absolute_error: 0.1166\n",
      "Epoch 319/400\n",
      "371/371 [==============================] - 0s 518us/step - loss: 0.1174 - mean_absolute_error: 0.1174 - val_loss: 0.1183 - val_mean_absolute_error: 0.1183\n",
      "Epoch 320/400\n",
      "371/371 [==============================] - 0s 516us/step - loss: 0.1175 - mean_absolute_error: 0.1175 - val_loss: 0.1205 - val_mean_absolute_error: 0.1205\n",
      "Epoch 321/400\n",
      "371/371 [==============================] - 0s 518us/step - loss: 0.1170 - mean_absolute_error: 0.1170 - val_loss: 0.1202 - val_mean_absolute_error: 0.1202\n",
      "Epoch 322/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1171 - mean_absolute_error: 0.1171 - val_loss: 0.1321 - val_mean_absolute_error: 0.1321\n",
      "Epoch 323/400\n",
      "371/371 [==============================] - 0s 519us/step - loss: 0.1169 - mean_absolute_error: 0.1169 - val_loss: 0.1211 - val_mean_absolute_error: 0.1211\n",
      "Epoch 324/400\n",
      "371/371 [==============================] - 0s 516us/step - loss: 0.1166 - mean_absolute_error: 0.1166 - val_loss: 0.1224 - val_mean_absolute_error: 0.1224\n",
      "Epoch 325/400\n",
      "371/371 [==============================] - 0s 525us/step - loss: 0.1167 - mean_absolute_error: 0.1167 - val_loss: 0.1233 - val_mean_absolute_error: 0.1233\n",
      "Epoch 326/400\n",
      "371/371 [==============================] - 0s 517us/step - loss: 0.1166 - mean_absolute_error: 0.1166 - val_loss: 0.1203 - val_mean_absolute_error: 0.1203\n",
      "Epoch 327/400\n",
      "371/371 [==============================] - 0s 516us/step - loss: 0.1163 - mean_absolute_error: 0.1163 - val_loss: 0.1158 - val_mean_absolute_error: 0.1158\n",
      "Epoch 328/400\n",
      "371/371 [==============================] - 0s 517us/step - loss: 0.1166 - mean_absolute_error: 0.1166 - val_loss: 0.1164 - val_mean_absolute_error: 0.1164\n",
      "Epoch 329/400\n",
      "371/371 [==============================] - 0s 516us/step - loss: 0.1163 - mean_absolute_error: 0.1163 - val_loss: 0.1320 - val_mean_absolute_error: 0.1320\n",
      "Epoch 330/400\n",
      "371/371 [==============================] - 0s 524us/step - loss: 0.1164 - mean_absolute_error: 0.1164 - val_loss: 0.1197 - val_mean_absolute_error: 0.1197\n",
      "Epoch 331/400\n",
      "371/371 [==============================] - 0s 518us/step - loss: 0.1164 - mean_absolute_error: 0.1164 - val_loss: 0.1215 - val_mean_absolute_error: 0.1215\n",
      "Epoch 332/400\n",
      "371/371 [==============================] - 0s 527us/step - loss: 0.1163 - mean_absolute_error: 0.1163 - val_loss: 0.1179 - val_mean_absolute_error: 0.1179\n",
      "Epoch 333/400\n",
      "371/371 [==============================] - 0s 518us/step - loss: 0.1162 - mean_absolute_error: 0.1162 - val_loss: 0.1183 - val_mean_absolute_error: 0.1183\n",
      "Epoch 334/400\n",
      "371/371 [==============================] - 0s 518us/step - loss: 0.1162 - mean_absolute_error: 0.1162 - val_loss: 0.1221 - val_mean_absolute_error: 0.1221\n",
      "Epoch 335/400\n",
      "371/371 [==============================] - 0s 535us/step - loss: 0.1158 - mean_absolute_error: 0.1158 - val_loss: 0.1116 - val_mean_absolute_error: 0.1116\n",
      "Epoch 336/400\n",
      "371/371 [==============================] - 0s 526us/step - loss: 0.1161 - mean_absolute_error: 0.1161 - val_loss: 0.1196 - val_mean_absolute_error: 0.1196\n",
      "Epoch 337/400\n",
      "371/371 [==============================] - 0s 519us/step - loss: 0.1157 - mean_absolute_error: 0.1157 - val_loss: 0.1235 - val_mean_absolute_error: 0.1235\n",
      "Epoch 338/400\n",
      "371/371 [==============================] - 0s 529us/step - loss: 0.1158 - mean_absolute_error: 0.1158 - val_loss: 0.1232 - val_mean_absolute_error: 0.1232\n",
      "Epoch 339/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371/371 [==============================] - 0s 570us/step - loss: 0.1156 - mean_absolute_error: 0.1156 - val_loss: 0.1223 - val_mean_absolute_error: 0.1223\n",
      "Epoch 340/400\n",
      "371/371 [==============================] - 0s 521us/step - loss: 0.1153 - mean_absolute_error: 0.1153 - val_loss: 0.1153 - val_mean_absolute_error: 0.1153\n",
      "Epoch 341/400\n",
      "371/371 [==============================] - 0s 515us/step - loss: 0.1150 - mean_absolute_error: 0.1150 - val_loss: 0.1180 - val_mean_absolute_error: 0.1180\n",
      "Epoch 342/400\n",
      "371/371 [==============================] - 0s 512us/step - loss: 0.1154 - mean_absolute_error: 0.1154 - val_loss: 0.1174 - val_mean_absolute_error: 0.1174\n",
      "Epoch 343/400\n",
      "371/371 [==============================] - 0s 518us/step - loss: 0.1155 - mean_absolute_error: 0.1155 - val_loss: 0.1118 - val_mean_absolute_error: 0.1118\n",
      "Epoch 344/400\n",
      "371/371 [==============================] - 0s 514us/step - loss: 0.1151 - mean_absolute_error: 0.1151 - val_loss: 0.1210 - val_mean_absolute_error: 0.1210\n",
      "Epoch 345/400\n",
      "371/371 [==============================] - 0s 517us/step - loss: 0.1150 - mean_absolute_error: 0.1150 - val_loss: 0.1156 - val_mean_absolute_error: 0.1156\n",
      "Epoch 346/400\n",
      "371/371 [==============================] - 0s 516us/step - loss: 0.1146 - mean_absolute_error: 0.1146 - val_loss: 0.1315 - val_mean_absolute_error: 0.1315\n",
      "Epoch 347/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1150 - mean_absolute_error: 0.1150 - val_loss: 0.1136 - val_mean_absolute_error: 0.1136\n",
      "Epoch 348/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1146 - mean_absolute_error: 0.1146 - val_loss: 0.1233 - val_mean_absolute_error: 0.1233\n",
      "Epoch 349/400\n",
      "371/371 [==============================] - 0s 521us/step - loss: 0.1149 - mean_absolute_error: 0.1149 - val_loss: 0.1204 - val_mean_absolute_error: 0.1204\n",
      "Epoch 350/400\n",
      "371/371 [==============================] - 0s 519us/step - loss: 0.1148 - mean_absolute_error: 0.1148 - val_loss: 0.1245 - val_mean_absolute_error: 0.1245\n",
      "Epoch 351/400\n",
      "371/371 [==============================] - 0s 519us/step - loss: 0.1146 - mean_absolute_error: 0.1146 - val_loss: 0.1283 - val_mean_absolute_error: 0.1283\n",
      "Epoch 352/400\n",
      "371/371 [==============================] - 0s 524us/step - loss: 0.1145 - mean_absolute_error: 0.1145 - val_loss: 0.1287 - val_mean_absolute_error: 0.1287\n",
      "Epoch 353/400\n",
      "371/371 [==============================] - 0s 517us/step - loss: 0.1146 - mean_absolute_error: 0.1146 - val_loss: 0.1169 - val_mean_absolute_error: 0.1169\n",
      "Epoch 354/400\n",
      "371/371 [==============================] - 0s 519us/step - loss: 0.1139 - mean_absolute_error: 0.1139 - val_loss: 0.1175 - val_mean_absolute_error: 0.1175\n",
      "Epoch 355/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1142 - mean_absolute_error: 0.1142 - val_loss: 0.1243 - val_mean_absolute_error: 0.1243\n",
      "Epoch 356/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1143 - mean_absolute_error: 0.1143 - val_loss: 0.1263 - val_mean_absolute_error: 0.1263\n",
      "Epoch 357/400\n",
      "371/371 [==============================] - 0s 521us/step - loss: 0.1143 - mean_absolute_error: 0.1143 - val_loss: 0.1259 - val_mean_absolute_error: 0.1259\n",
      "Epoch 358/400\n",
      "371/371 [==============================] - 0s 521us/step - loss: 0.1136 - mean_absolute_error: 0.1136 - val_loss: 0.1138 - val_mean_absolute_error: 0.1138\n",
      "Epoch 359/400\n",
      "371/371 [==============================] - 0s 523us/step - loss: 0.1139 - mean_absolute_error: 0.1139 - val_loss: 0.1293 - val_mean_absolute_error: 0.1293\n",
      "Epoch 360/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1135 - mean_absolute_error: 0.1135 - val_loss: 0.1194 - val_mean_absolute_error: 0.1194\n",
      "Epoch 361/400\n",
      "371/371 [==============================] - 0s 519us/step - loss: 0.1142 - mean_absolute_error: 0.1142 - val_loss: 0.1217 - val_mean_absolute_error: 0.1217\n",
      "Epoch 362/400\n",
      "371/371 [==============================] - 0s 518us/step - loss: 0.1137 - mean_absolute_error: 0.1137 - val_loss: 0.1115 - val_mean_absolute_error: 0.1115\n",
      "Epoch 363/400\n",
      "371/371 [==============================] - 0s 522us/step - loss: 0.1133 - mean_absolute_error: 0.1133 - val_loss: 0.1142 - val_mean_absolute_error: 0.1142\n",
      "Epoch 364/400\n",
      "371/371 [==============================] - 0s 518us/step - loss: 0.1137 - mean_absolute_error: 0.1137 - val_loss: 0.1163 - val_mean_absolute_error: 0.1163\n",
      "Epoch 365/400\n",
      "371/371 [==============================] - 0s 517us/step - loss: 0.1138 - mean_absolute_error: 0.1138 - val_loss: 0.1176 - val_mean_absolute_error: 0.1176\n",
      "Epoch 366/400\n",
      "371/371 [==============================] - 0s 522us/step - loss: 0.1131 - mean_absolute_error: 0.1131 - val_loss: 0.1163 - val_mean_absolute_error: 0.1163\n",
      "Epoch 367/400\n",
      "371/371 [==============================] - 0s 521us/step - loss: 0.1133 - mean_absolute_error: 0.1133 - val_loss: 0.1280 - val_mean_absolute_error: 0.1280\n",
      "Epoch 368/400\n",
      "371/371 [==============================] - 0s 519us/step - loss: 0.1139 - mean_absolute_error: 0.1139 - val_loss: 0.1202 - val_mean_absolute_error: 0.1202\n",
      "Epoch 369/400\n",
      "371/371 [==============================] - 0s 523us/step - loss: 0.1132 - mean_absolute_error: 0.1132 - val_loss: 0.1210 - val_mean_absolute_error: 0.1210\n",
      "Epoch 370/400\n",
      "371/371 [==============================] - 0s 521us/step - loss: 0.1133 - mean_absolute_error: 0.1133 - val_loss: 0.1201 - val_mean_absolute_error: 0.1201\n",
      "Epoch 371/400\n",
      "371/371 [==============================] - 0s 523us/step - loss: 0.1130 - mean_absolute_error: 0.1130 - val_loss: 0.1299 - val_mean_absolute_error: 0.1299\n",
      "Epoch 372/400\n",
      "371/371 [==============================] - 0s 517us/step - loss: 0.1132 - mean_absolute_error: 0.1132 - val_loss: 0.1161 - val_mean_absolute_error: 0.1161\n",
      "Epoch 373/400\n",
      "371/371 [==============================] - 0s 524us/step - loss: 0.1130 - mean_absolute_error: 0.1130 - val_loss: 0.1263 - val_mean_absolute_error: 0.1263\n",
      "Epoch 374/400\n",
      "371/371 [==============================] - 0s 526us/step - loss: 0.1132 - mean_absolute_error: 0.1132 - val_loss: 0.1230 - val_mean_absolute_error: 0.1230\n",
      "Epoch 375/400\n",
      "371/371 [==============================] - 0s 538us/step - loss: 0.1130 - mean_absolute_error: 0.1130 - val_loss: 0.1134 - val_mean_absolute_error: 0.1134\n",
      "Epoch 376/400\n",
      "371/371 [==============================] - 0s 523us/step - loss: 0.1128 - mean_absolute_error: 0.1128 - val_loss: 0.1162 - val_mean_absolute_error: 0.1162\n",
      "Epoch 377/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1128 - mean_absolute_error: 0.1128 - val_loss: 0.1158 - val_mean_absolute_error: 0.1158\n",
      "Epoch 378/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1126 - mean_absolute_error: 0.1126 - val_loss: 0.1182 - val_mean_absolute_error: 0.1182\n",
      "Epoch 379/400\n",
      "371/371 [==============================] - 0s 517us/step - loss: 0.1126 - mean_absolute_error: 0.1126 - val_loss: 0.1136 - val_mean_absolute_error: 0.1136\n",
      "Epoch 380/400\n",
      "371/371 [==============================] - 0s 538us/step - loss: 0.1129 - mean_absolute_error: 0.1129 - val_loss: 0.1126 - val_mean_absolute_error: 0.1126\n",
      "Epoch 381/400\n",
      "371/371 [==============================] - 0s 576us/step - loss: 0.1125 - mean_absolute_error: 0.1125 - val_loss: 0.1127 - val_mean_absolute_error: 0.1127\n",
      "Epoch 382/400\n",
      "371/371 [==============================] - 0s 521us/step - loss: 0.1124 - mean_absolute_error: 0.1124 - val_loss: 0.1192 - val_mean_absolute_error: 0.1192\n",
      "Epoch 383/400\n",
      "371/371 [==============================] - 0s 522us/step - loss: 0.1123 - mean_absolute_error: 0.1123 - val_loss: 0.1175 - val_mean_absolute_error: 0.1175\n",
      "Epoch 384/400\n",
      "371/371 [==============================] - 0s 592us/step - loss: 0.1123 - mean_absolute_error: 0.1123 - val_loss: 0.1108 - val_mean_absolute_error: 0.1108\n",
      "Epoch 385/400\n",
      "371/371 [==============================] - 0s 533us/step - loss: 0.1121 - mean_absolute_error: 0.1121 - val_loss: 0.1172 - val_mean_absolute_error: 0.1172\n",
      "Epoch 386/400\n",
      "371/371 [==============================] - 0s 524us/step - loss: 0.1124 - mean_absolute_error: 0.1124 - val_loss: 0.1138 - val_mean_absolute_error: 0.1138\n",
      "Epoch 387/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371/371 [==============================] - 0s 525us/step - loss: 0.1120 - mean_absolute_error: 0.1120 - val_loss: 0.1183 - val_mean_absolute_error: 0.1183\n",
      "Epoch 388/400\n",
      "371/371 [==============================] - 0s 514us/step - loss: 0.1118 - mean_absolute_error: 0.1118 - val_loss: 0.1097 - val_mean_absolute_error: 0.1097\n",
      "Epoch 389/400\n",
      "371/371 [==============================] - 0s 528us/step - loss: 0.1122 - mean_absolute_error: 0.1122 - val_loss: 0.1144 - val_mean_absolute_error: 0.1144\n",
      "Epoch 390/400\n",
      "371/371 [==============================] - 0s 520us/step - loss: 0.1113 - mean_absolute_error: 0.1113 - val_loss: 0.1100 - val_mean_absolute_error: 0.1100\n",
      "Epoch 391/400\n",
      "371/371 [==============================] - 0s 517us/step - loss: 0.1122 - mean_absolute_error: 0.1122 - val_loss: 0.1183 - val_mean_absolute_error: 0.1183\n",
      "Epoch 392/400\n",
      "371/371 [==============================] - 0s 545us/step - loss: 0.1115 - mean_absolute_error: 0.1115 - val_loss: 0.1165 - val_mean_absolute_error: 0.1165\n",
      "Epoch 393/400\n",
      "371/371 [==============================] - 0s 514us/step - loss: 0.1120 - mean_absolute_error: 0.1120 - val_loss: 0.1167 - val_mean_absolute_error: 0.1167\n",
      "Epoch 394/400\n",
      "371/371 [==============================] - 0s 524us/step - loss: 0.1117 - mean_absolute_error: 0.1117 - val_loss: 0.1243 - val_mean_absolute_error: 0.1243\n",
      "Epoch 395/400\n",
      "371/371 [==============================] - 0s 518us/step - loss: 0.1117 - mean_absolute_error: 0.1117 - val_loss: 0.1195 - val_mean_absolute_error: 0.1195\n",
      "Epoch 396/400\n",
      "371/371 [==============================] - 0s 521us/step - loss: 0.1118 - mean_absolute_error: 0.1118 - val_loss: 0.1173 - val_mean_absolute_error: 0.1173\n",
      "Epoch 397/400\n",
      "371/371 [==============================] - 0s 514us/step - loss: 0.1114 - mean_absolute_error: 0.1114 - val_loss: 0.1163 - val_mean_absolute_error: 0.1163\n",
      "Epoch 398/400\n",
      "371/371 [==============================] - 0s 515us/step - loss: 0.1117 - mean_absolute_error: 0.1117 - val_loss: 0.1148 - val_mean_absolute_error: 0.1148\n",
      "Epoch 399/400\n",
      "371/371 [==============================] - 0s 519us/step - loss: 0.1111 - mean_absolute_error: 0.1111 - val_loss: 0.1089 - val_mean_absolute_error: 0.1089\n",
      "Epoch 400/400\n",
      "371/371 [==============================] - 0s 639us/step - loss: 0.1111 - mean_absolute_error: 0.1111 - val_loss: 0.1141 - val_mean_absolute_error: 0.1141\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    batch_size=64,\n",
    "    epochs=400,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(X_test, Y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93629dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 315us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10905128717603396"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_train, model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04ad8c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 0s 311us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11408455206590504"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_test, model.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
