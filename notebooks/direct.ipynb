{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b50697e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30346186",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'epochs': 200,\n",
    "    'test_size': 0.2,\n",
    "    'random_state': 1337,\n",
    "    'validation_split': 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6776a886",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/qsc_out.random_scan_nfp2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3599d370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.115912</td>\n",
       "      <td>-0.207162</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.012060</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>-0.736734</td>\n",
       "      <td>0.012462</td>\n",
       "      <td>0.783335</td>\n",
       "      <td>0.278748</td>\n",
       "      <td>0.497138</td>\n",
       "      <td>0.645087</td>\n",
       "      <td>0.926717</td>\n",
       "      <td>1.717088</td>\n",
       "      <td>0.338459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.081966</td>\n",
       "      <td>-0.182033</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.010903</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.755056</td>\n",
       "      <td>0.031954</td>\n",
       "      <td>1.379462</td>\n",
       "      <td>0.284927</td>\n",
       "      <td>0.386816</td>\n",
       "      <td>0.493242</td>\n",
       "      <td>0.881144</td>\n",
       "      <td>1.562226</td>\n",
       "      <td>0.326036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.098121</td>\n",
       "      <td>0.188199</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>-0.010709</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>-0.641071</td>\n",
       "      <td>0.060675</td>\n",
       "      <td>1.124535</td>\n",
       "      <td>0.342645</td>\n",
       "      <td>0.523383</td>\n",
       "      <td>0.639508</td>\n",
       "      <td>0.869696</td>\n",
       "      <td>1.574066</td>\n",
       "      <td>0.331869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.077109</td>\n",
       "      <td>-0.206706</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.006428</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>-0.000304</td>\n",
       "      <td>-0.868233</td>\n",
       "      <td>-0.092663</td>\n",
       "      <td>1.205836</td>\n",
       "      <td>0.265378</td>\n",
       "      <td>0.541464</td>\n",
       "      <td>0.512058</td>\n",
       "      <td>0.907885</td>\n",
       "      <td>1.711111</td>\n",
       "      <td>0.324205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.082828</td>\n",
       "      <td>0.221897</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>-0.008468</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>-0.758676</td>\n",
       "      <td>-0.317667</td>\n",
       "      <td>1.026909</td>\n",
       "      <td>0.273752</td>\n",
       "      <td>0.751935</td>\n",
       "      <td>0.643160</td>\n",
       "      <td>0.944501</td>\n",
       "      <td>1.518423</td>\n",
       "      <td>0.326940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6        x7   \n",
       "0 -0.115912 -0.207162  0.001411  0.012060  0.000871 -0.000108 -0.736734  \\\n",
       "1 -0.081966 -0.182033  0.001298  0.010903  0.000813 -0.000155 -0.755056   \n",
       "2 -0.098121  0.188199  0.001285 -0.010709  0.000807  0.000152 -0.641071   \n",
       "3 -0.077109 -0.206706  0.001522  0.006428  0.000926 -0.000304 -0.868233   \n",
       "4 -0.082828  0.221897  0.000230 -0.008468  0.000198  0.000174 -0.758676   \n",
       "\n",
       "         x8        y0        y1        y2        y3        y4        y5   \n",
       "0  0.012462  0.783335  0.278748  0.497138  0.645087  0.926717  1.717088  \\\n",
       "1  0.031954  1.379462  0.284927  0.386816  0.493242  0.881144  1.562226   \n",
       "2  0.060675  1.124535  0.342645  0.523383  0.639508  0.869696  1.574066   \n",
       "3 -0.092663  1.205836  0.265378  0.541464  0.512058  0.907885  1.711111   \n",
       "4 -0.317667  1.026909  0.273752  0.751935  0.643160  0.944501  1.518423   \n",
       "\n",
       "         y6  \n",
       "0  0.338459  \n",
       "1  0.326036  \n",
       "2  0.331869  \n",
       "3  0.324205  \n",
       "4  0.326940  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed54624a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4796, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ae249e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = [col for col in df.columns if col.startswith('x')]\n",
    "y_columns = [col for col in df.columns if col.startswith('y')]\n",
    "\n",
    "Y = df[x_columns].values\n",
    "X = df[y_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "064de500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_train, X_test, Y_train, Y_test, params):\n",
    "    scaler_x = StandardScaler().fit(X_train)\n",
    "    scaler_y = StandardScaler().fit(Y_train)\n",
    "    X_train = scaler_x.transform(X_train)\n",
    "    X_test = scaler_x.transform(X_test)\n",
    "    Y_train = scaler_y.transform(Y_train)\n",
    "    Y_test = scaler_y.transform(Y_test)\n",
    "\n",
    "    input_shape = X_train.shape[1]\n",
    "    \n",
    "    output_shape = Y_train.shape[1]\n",
    "    return X_train, X_test, Y_train, Y_test, input_shape, output_shape, scaler_x, scaler_y\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=params['test_size'], \n",
    "                                                    random_state=params['random_state'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test, input_shape, output_shape, scaler_x, scaler_y = preprocess_data(X_train, X_test, Y_train, Y_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a10ed4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-4.01657042e-15,  4.72944589e-15,  2.50063555e-15, -3.41465936e-15,\n",
       "        -5.97028509e-15, -9.70058815e-15, -3.51141604e-14]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.mean(axis=0), X_train.std(axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ccb03a",
   "metadata": {},
   "source": [
    "## Appears to be drift, perhaps the sample is not big enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c161da77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.03647091, 0.05036899, 0.0240539 , 0.01615513, 0.02262298,\n",
       "        0.069791  , 0.00742891]),\n",
       " array([1.04363768, 1.03365372, 1.03354061, 1.01573765, 1.04018519,\n",
       "        0.98510014, 1.0395029 ]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.mean(axis=0), X_test.std(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53e58115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.83484230e-17, -2.05489663e-17,  1.57677139e-16,  1.15291278e-16,\n",
       "        -6.44832351e-17, -3.98823600e-17,  2.63764795e-16,  9.18495381e-16]),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.mean(axis=0), Y_train.std(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2baf62f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.02525043,  0.00971201,  0.01397497,  0.04719729,  0.01297527,\n",
       "        -0.02875165, -0.00224075,  0.00415783]),\n",
       " array([1.00535971, 1.00234493, 1.04188367, 1.01245292, 1.03768115,\n",
       "        0.98217117, 1.014723  , 1.01594242]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.mean(axis=0), Y_test.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdca24f",
   "metadata": {},
   "source": [
    "## Dummy regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a74f6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d32b7301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16],\n",
       "       [ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16],\n",
       "       [ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16],\n",
       "       ...,\n",
       "       [ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16],\n",
       "       [ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16],\n",
       "       [ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = MultiOutputRegressor(DummyRegressor(strategy=\"mean\")).fit(X_train, Y_train)\n",
    "regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e960bbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000007"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(Y_train, regr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5fa73bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0291802816467932"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(Y_test, regr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ac703",
   "metadata": {},
   "source": [
    "## Train a linear regression for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb67a16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15676934,  0.04012469, -0.12659159, ...,  0.06290221,\n",
       "        -0.40890284,  0.03899315],\n",
       "       [ 0.098538  ,  0.02856683, -0.02685268, ..., -0.01454209,\n",
       "        -0.16032767,  0.49703159],\n",
       "       [-0.17443072,  0.00250346,  0.13851425, ..., -0.0678374 ,\n",
       "        -0.04978863,  0.27261235],\n",
       "       ...,\n",
       "       [ 0.02097198,  0.03903598,  0.03713012, ..., -0.02695103,\n",
       "        -0.3743756 ,  0.34646245],\n",
       "       [-0.26866067,  0.03050944,  0.16463002, ..., -0.05755192,\n",
       "        -0.21087286,  0.37635694],\n",
       "       [ 0.33351338,  0.08189727, -0.20413084, ...,  0.07795407,\n",
       "        -0.54412842,  0.25056948]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = MultiOutputRegressor(Ridge(random_state=123)).fit(X_train, Y_train)\n",
    "regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f8b7880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9248479543380279"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(Y_train, regr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93fe236e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.955048583856655"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(Y_test, regr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909b3bd7",
   "metadata": {},
   "source": [
    "## Simplest neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "606b1b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43d73ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 8), dtype=float32, numpy=\n",
       "array([[ 0.06464694, -0.00889271,  0.06453516,  0.0415666 ,  0.01000295,\n",
       "         0.05986639, -0.02833799,  0.05403368]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Sequential model with 3 layers\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(input_shape, activation=\"relu\", name=\"layer_in\"),\n",
    "        layers.Dense(128, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(64, activation=\"relu\", name=\"layer3\"),\n",
    "        layers.Dense(output_shape, name=\"layer_out\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model(X_train[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d43388b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer_in (Dense)            (1, 7)                    56        \n",
      "                                                                 \n",
      " layer2 (Dense)              (1, 128)                  1024      \n",
      "                                                                 \n",
      " layer3 (Dense)              (1, 64)                   8256      \n",
      "                                                                 \n",
      " layer_out (Dense)           (1, 8)                    520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9856 (38.50 KB)\n",
      "Trainable params: 9856 (38.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67a8182d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.MeanSquaredError()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b11ea593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/80\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.9623 - mean_squared_error: 0.9623 - val_loss: 0.9661 - val_mean_squared_error: 0.9661\n",
      "Epoch 2/80\n",
      "60/60 [==============================] - 0s 799us/step - loss: 0.9294 - mean_squared_error: 0.9294 - val_loss: 0.9528 - val_mean_squared_error: 0.9528\n",
      "Epoch 3/80\n",
      "60/60 [==============================] - 0s 681us/step - loss: 0.9170 - mean_squared_error: 0.9170 - val_loss: 0.9435 - val_mean_squared_error: 0.9435\n",
      "Epoch 4/80\n",
      "60/60 [==============================] - 0s 690us/step - loss: 0.9082 - mean_squared_error: 0.9082 - val_loss: 0.9370 - val_mean_squared_error: 0.9370\n",
      "Epoch 5/80\n",
      "60/60 [==============================] - 0s 686us/step - loss: 0.8998 - mean_squared_error: 0.8998 - val_loss: 0.9410 - val_mean_squared_error: 0.9410\n",
      "Epoch 6/80\n",
      "60/60 [==============================] - 0s 715us/step - loss: 0.8939 - mean_squared_error: 0.8939 - val_loss: 0.9296 - val_mean_squared_error: 0.9296\n",
      "Epoch 7/80\n",
      "60/60 [==============================] - 0s 670us/step - loss: 0.8894 - mean_squared_error: 0.8894 - val_loss: 0.9229 - val_mean_squared_error: 0.9229\n",
      "Epoch 8/80\n",
      "60/60 [==============================] - 0s 664us/step - loss: 0.8836 - mean_squared_error: 0.8836 - val_loss: 0.9231 - val_mean_squared_error: 0.9231\n",
      "Epoch 9/80\n",
      "60/60 [==============================] - 0s 667us/step - loss: 0.8807 - mean_squared_error: 0.8807 - val_loss: 0.9183 - val_mean_squared_error: 0.9183\n",
      "Epoch 10/80\n",
      "60/60 [==============================] - 0s 652us/step - loss: 0.8756 - mean_squared_error: 0.8756 - val_loss: 0.9177 - val_mean_squared_error: 0.9177\n",
      "Epoch 11/80\n",
      "60/60 [==============================] - 0s 668us/step - loss: 0.8733 - mean_squared_error: 0.8733 - val_loss: 0.9154 - val_mean_squared_error: 0.9154\n",
      "Epoch 12/80\n",
      "60/60 [==============================] - 0s 660us/step - loss: 0.8705 - mean_squared_error: 0.8705 - val_loss: 0.9119 - val_mean_squared_error: 0.9119\n",
      "Epoch 13/80\n",
      "60/60 [==============================] - 0s 663us/step - loss: 0.8674 - mean_squared_error: 0.8674 - val_loss: 0.9073 - val_mean_squared_error: 0.9073\n",
      "Epoch 14/80\n",
      "60/60 [==============================] - 0s 655us/step - loss: 0.8655 - mean_squared_error: 0.8655 - val_loss: 0.9086 - val_mean_squared_error: 0.9086\n",
      "Epoch 15/80\n",
      "60/60 [==============================] - 0s 644us/step - loss: 0.8632 - mean_squared_error: 0.8632 - val_loss: 0.9054 - val_mean_squared_error: 0.9054\n",
      "Epoch 16/80\n",
      "60/60 [==============================] - 0s 662us/step - loss: 0.8607 - mean_squared_error: 0.8607 - val_loss: 0.9050 - val_mean_squared_error: 0.9050\n",
      "Epoch 17/80\n",
      "60/60 [==============================] - 0s 675us/step - loss: 0.8591 - mean_squared_error: 0.8591 - val_loss: 0.9044 - val_mean_squared_error: 0.9044\n",
      "Epoch 18/80\n",
      "60/60 [==============================] - 0s 650us/step - loss: 0.8568 - mean_squared_error: 0.8568 - val_loss: 0.9027 - val_mean_squared_error: 0.9027\n",
      "Epoch 19/80\n",
      "60/60 [==============================] - 0s 668us/step - loss: 0.8552 - mean_squared_error: 0.8552 - val_loss: 0.9073 - val_mean_squared_error: 0.9073\n",
      "Epoch 20/80\n",
      "60/60 [==============================] - 0s 649us/step - loss: 0.8528 - mean_squared_error: 0.8528 - val_loss: 0.9019 - val_mean_squared_error: 0.9019\n",
      "Epoch 21/80\n",
      "60/60 [==============================] - 0s 664us/step - loss: 0.8514 - mean_squared_error: 0.8514 - val_loss: 0.9019 - val_mean_squared_error: 0.9019\n",
      "Epoch 22/80\n",
      "60/60 [==============================] - 0s 674us/step - loss: 0.8497 - mean_squared_error: 0.8497 - val_loss: 0.9004 - val_mean_squared_error: 0.9004\n",
      "Epoch 23/80\n",
      "60/60 [==============================] - 0s 675us/step - loss: 0.8477 - mean_squared_error: 0.8477 - val_loss: 0.9058 - val_mean_squared_error: 0.9058\n",
      "Epoch 24/80\n",
      "60/60 [==============================] - 0s 646us/step - loss: 0.8456 - mean_squared_error: 0.8456 - val_loss: 0.9015 - val_mean_squared_error: 0.9015\n",
      "Epoch 25/80\n",
      "60/60 [==============================] - 0s 647us/step - loss: 0.8442 - mean_squared_error: 0.8442 - val_loss: 0.8997 - val_mean_squared_error: 0.8997\n",
      "Epoch 26/80\n",
      "60/60 [==============================] - 0s 664us/step - loss: 0.8436 - mean_squared_error: 0.8436 - val_loss: 0.8984 - val_mean_squared_error: 0.8984\n",
      "Epoch 27/80\n",
      "60/60 [==============================] - 0s 640us/step - loss: 0.8417 - mean_squared_error: 0.8417 - val_loss: 0.8959 - val_mean_squared_error: 0.8959\n",
      "Epoch 28/80\n",
      "60/60 [==============================] - 0s 656us/step - loss: 0.8405 - mean_squared_error: 0.8405 - val_loss: 0.8959 - val_mean_squared_error: 0.8959\n",
      "Epoch 29/80\n",
      "60/60 [==============================] - 0s 779us/step - loss: 0.8390 - mean_squared_error: 0.8390 - val_loss: 0.8955 - val_mean_squared_error: 0.8955\n",
      "Epoch 30/80\n",
      "60/60 [==============================] - 0s 660us/step - loss: 0.8369 - mean_squared_error: 0.8369 - val_loss: 0.8963 - val_mean_squared_error: 0.8963\n",
      "Epoch 31/80\n",
      "60/60 [==============================] - 0s 643us/step - loss: 0.8359 - mean_squared_error: 0.8359 - val_loss: 0.8952 - val_mean_squared_error: 0.8952\n",
      "Epoch 32/80\n",
      "60/60 [==============================] - 0s 648us/step - loss: 0.8333 - mean_squared_error: 0.8333 - val_loss: 0.8933 - val_mean_squared_error: 0.8933\n",
      "Epoch 33/80\n",
      "60/60 [==============================] - 0s 657us/step - loss: 0.8315 - mean_squared_error: 0.8315 - val_loss: 0.8981 - val_mean_squared_error: 0.8981\n",
      "Epoch 34/80\n",
      "60/60 [==============================] - 0s 667us/step - loss: 0.8310 - mean_squared_error: 0.8310 - val_loss: 0.8915 - val_mean_squared_error: 0.8915\n",
      "Epoch 35/80\n",
      "60/60 [==============================] - 0s 649us/step - loss: 0.8303 - mean_squared_error: 0.8303 - val_loss: 0.8913 - val_mean_squared_error: 0.8913\n",
      "Epoch 36/80\n",
      "60/60 [==============================] - 0s 656us/step - loss: 0.8285 - mean_squared_error: 0.8285 - val_loss: 0.8924 - val_mean_squared_error: 0.8924\n",
      "Epoch 37/80\n",
      "60/60 [==============================] - 0s 613us/step - loss: 0.8263 - mean_squared_error: 0.8263 - val_loss: 0.8900 - val_mean_squared_error: 0.8900\n",
      "Epoch 38/80\n",
      "60/60 [==============================] - 0s 655us/step - loss: 0.8255 - mean_squared_error: 0.8255 - val_loss: 0.8910 - val_mean_squared_error: 0.8910\n",
      "Epoch 39/80\n",
      "60/60 [==============================] - 0s 627us/step - loss: 0.8235 - mean_squared_error: 0.8235 - val_loss: 0.8913 - val_mean_squared_error: 0.8913\n",
      "Epoch 40/80\n",
      "60/60 [==============================] - 0s 637us/step - loss: 0.8230 - mean_squared_error: 0.8230 - val_loss: 0.8881 - val_mean_squared_error: 0.8881\n",
      "Epoch 41/80\n",
      "60/60 [==============================] - 0s 648us/step - loss: 0.8199 - mean_squared_error: 0.8199 - val_loss: 0.8882 - val_mean_squared_error: 0.8882\n",
      "Epoch 42/80\n",
      "60/60 [==============================] - 0s 636us/step - loss: 0.8203 - mean_squared_error: 0.8203 - val_loss: 0.8886 - val_mean_squared_error: 0.8886\n",
      "Epoch 43/80\n",
      "60/60 [==============================] - 0s 649us/step - loss: 0.8182 - mean_squared_error: 0.8182 - val_loss: 0.8886 - val_mean_squared_error: 0.8886\n",
      "Epoch 44/80\n",
      "60/60 [==============================] - 0s 633us/step - loss: 0.8163 - mean_squared_error: 0.8163 - val_loss: 0.8876 - val_mean_squared_error: 0.8876\n",
      "Epoch 45/80\n",
      "60/60 [==============================] - 0s 625us/step - loss: 0.8154 - mean_squared_error: 0.8154 - val_loss: 0.8904 - val_mean_squared_error: 0.8904\n",
      "Epoch 46/80\n",
      "60/60 [==============================] - 0s 643us/step - loss: 0.8149 - mean_squared_error: 0.8149 - val_loss: 0.8890 - val_mean_squared_error: 0.8890\n",
      "Epoch 47/80\n",
      "60/60 [==============================] - 0s 627us/step - loss: 0.8116 - mean_squared_error: 0.8116 - val_loss: 0.8856 - val_mean_squared_error: 0.8856\n",
      "Epoch 48/80\n",
      "60/60 [==============================] - 0s 653us/step - loss: 0.8114 - mean_squared_error: 0.8114 - val_loss: 0.8880 - val_mean_squared_error: 0.8880\n",
      "Epoch 49/80\n",
      "60/60 [==============================] - 0s 636us/step - loss: 0.8108 - mean_squared_error: 0.8108 - val_loss: 0.8836 - val_mean_squared_error: 0.8836\n",
      "Epoch 50/80\n",
      "60/60 [==============================] - 0s 629us/step - loss: 0.8099 - mean_squared_error: 0.8099 - val_loss: 0.8847 - val_mean_squared_error: 0.8847\n",
      "Epoch 51/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 637us/step - loss: 0.8087 - mean_squared_error: 0.8087 - val_loss: 0.8883 - val_mean_squared_error: 0.8883\n",
      "Epoch 52/80\n",
      "60/60 [==============================] - 0s 663us/step - loss: 0.8080 - mean_squared_error: 0.8080 - val_loss: 0.8876 - val_mean_squared_error: 0.8876\n",
      "Epoch 53/80\n",
      "60/60 [==============================] - 0s 662us/step - loss: 0.8061 - mean_squared_error: 0.8061 - val_loss: 0.8858 - val_mean_squared_error: 0.8858\n",
      "Epoch 54/80\n",
      "60/60 [==============================] - 0s 686us/step - loss: 0.8058 - mean_squared_error: 0.8058 - val_loss: 0.8821 - val_mean_squared_error: 0.8821\n",
      "Epoch 55/80\n",
      "60/60 [==============================] - 0s 693us/step - loss: 0.8033 - mean_squared_error: 0.8033 - val_loss: 0.8910 - val_mean_squared_error: 0.8910\n",
      "Epoch 56/80\n",
      "60/60 [==============================] - 0s 638us/step - loss: 0.8034 - mean_squared_error: 0.8034 - val_loss: 0.8803 - val_mean_squared_error: 0.8803\n",
      "Epoch 57/80\n",
      "60/60 [==============================] - 0s 630us/step - loss: 0.8016 - mean_squared_error: 0.8016 - val_loss: 0.8814 - val_mean_squared_error: 0.8814\n",
      "Epoch 58/80\n",
      "60/60 [==============================] - 0s 632us/step - loss: 0.8002 - mean_squared_error: 0.8002 - val_loss: 0.8860 - val_mean_squared_error: 0.8860\n",
      "Epoch 59/80\n",
      "60/60 [==============================] - 0s 638us/step - loss: 0.8001 - mean_squared_error: 0.8001 - val_loss: 0.8797 - val_mean_squared_error: 0.8797\n",
      "Epoch 60/80\n",
      "60/60 [==============================] - 0s 639us/step - loss: 0.7985 - mean_squared_error: 0.7985 - val_loss: 0.8814 - val_mean_squared_error: 0.8814\n",
      "Epoch 61/80\n",
      "60/60 [==============================] - 0s 632us/step - loss: 0.7974 - mean_squared_error: 0.7974 - val_loss: 0.8833 - val_mean_squared_error: 0.8833\n",
      "Epoch 62/80\n",
      "60/60 [==============================] - 0s 643us/step - loss: 0.7958 - mean_squared_error: 0.7958 - val_loss: 0.8820 - val_mean_squared_error: 0.8820\n",
      "Epoch 63/80\n",
      "60/60 [==============================] - 0s 624us/step - loss: 0.7946 - mean_squared_error: 0.7946 - val_loss: 0.8918 - val_mean_squared_error: 0.8918\n",
      "Epoch 64/80\n",
      "60/60 [==============================] - 0s 636us/step - loss: 0.7950 - mean_squared_error: 0.7950 - val_loss: 0.8830 - val_mean_squared_error: 0.8830\n",
      "Epoch 65/80\n",
      "60/60 [==============================] - 0s 623us/step - loss: 0.7916 - mean_squared_error: 0.7916 - val_loss: 0.8817 - val_mean_squared_error: 0.8817\n",
      "Epoch 66/80\n",
      "60/60 [==============================] - 0s 650us/step - loss: 0.7904 - mean_squared_error: 0.7904 - val_loss: 0.8815 - val_mean_squared_error: 0.8815\n",
      "Epoch 67/80\n",
      "60/60 [==============================] - 0s 635us/step - loss: 0.7909 - mean_squared_error: 0.7909 - val_loss: 0.8831 - val_mean_squared_error: 0.8831\n",
      "Epoch 68/80\n",
      "60/60 [==============================] - 0s 640us/step - loss: 0.7896 - mean_squared_error: 0.7896 - val_loss: 0.8830 - val_mean_squared_error: 0.8830\n",
      "Epoch 69/80\n",
      "60/60 [==============================] - 0s 638us/step - loss: 0.7880 - mean_squared_error: 0.7880 - val_loss: 0.8800 - val_mean_squared_error: 0.8800\n",
      "Epoch 70/80\n",
      "60/60 [==============================] - 0s 632us/step - loss: 0.7884 - mean_squared_error: 0.7884 - val_loss: 0.8763 - val_mean_squared_error: 0.8763\n",
      "Epoch 71/80\n",
      "60/60 [==============================] - 0s 631us/step - loss: 0.7848 - mean_squared_error: 0.7848 - val_loss: 0.8929 - val_mean_squared_error: 0.8929\n",
      "Epoch 72/80\n",
      "60/60 [==============================] - 0s 635us/step - loss: 0.7869 - mean_squared_error: 0.7869 - val_loss: 0.8796 - val_mean_squared_error: 0.8796\n",
      "Epoch 73/80\n",
      "60/60 [==============================] - 0s 636us/step - loss: 0.7840 - mean_squared_error: 0.7840 - val_loss: 0.8837 - val_mean_squared_error: 0.8837\n",
      "Epoch 74/80\n",
      "60/60 [==============================] - 0s 634us/step - loss: 0.7830 - mean_squared_error: 0.7830 - val_loss: 0.8890 - val_mean_squared_error: 0.8890\n",
      "Epoch 75/80\n",
      "60/60 [==============================] - 0s 620us/step - loss: 0.7807 - mean_squared_error: 0.7807 - val_loss: 0.8796 - val_mean_squared_error: 0.8796\n",
      "Epoch 76/80\n",
      "60/60 [==============================] - 0s 628us/step - loss: 0.7811 - mean_squared_error: 0.7811 - val_loss: 0.8808 - val_mean_squared_error: 0.8808\n",
      "Epoch 77/80\n",
      "60/60 [==============================] - 0s 641us/step - loss: 0.7794 - mean_squared_error: 0.7794 - val_loss: 0.8950 - val_mean_squared_error: 0.8950\n",
      "Epoch 78/80\n",
      "60/60 [==============================] - 0s 630us/step - loss: 0.7789 - mean_squared_error: 0.7789 - val_loss: 0.8807 - val_mean_squared_error: 0.8807\n",
      "Epoch 79/80\n",
      "60/60 [==============================] - 0s 637us/step - loss: 0.7773 - mean_squared_error: 0.7773 - val_loss: 0.8779 - val_mean_squared_error: 0.8779\n",
      "Epoch 80/80\n",
      "60/60 [==============================] - 0s 649us/step - loss: 0.7770 - mean_squared_error: 0.7770 - val_loss: 0.8776 - val_mean_squared_error: 0.8776\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    batch_size=64,\n",
    "    epochs=80,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(X_test, Y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93629dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 318us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76772865586145"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(Y_train, model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04ad8c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 378us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8776152117416222"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(Y_test, model.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
