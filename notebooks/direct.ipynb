{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b50697e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30346186",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'epochs': 200,\n",
    "    'test_size': 0.2,\n",
    "    'random_state': 1337,\n",
    "    'validation_split': 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6776a886",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/qsc_out.random_scan_nfp2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3599d370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.115912</td>\n",
       "      <td>-0.207162</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.012060</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>-0.736734</td>\n",
       "      <td>0.012462</td>\n",
       "      <td>0.783335</td>\n",
       "      <td>0.278748</td>\n",
       "      <td>0.497138</td>\n",
       "      <td>0.645087</td>\n",
       "      <td>0.926717</td>\n",
       "      <td>1.717088</td>\n",
       "      <td>0.338459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.081966</td>\n",
       "      <td>-0.182033</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.010903</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.755056</td>\n",
       "      <td>0.031954</td>\n",
       "      <td>1.379462</td>\n",
       "      <td>0.284927</td>\n",
       "      <td>0.386816</td>\n",
       "      <td>0.493242</td>\n",
       "      <td>0.881144</td>\n",
       "      <td>1.562226</td>\n",
       "      <td>0.326036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.098121</td>\n",
       "      <td>0.188199</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>-0.010709</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>-0.641071</td>\n",
       "      <td>0.060675</td>\n",
       "      <td>1.124535</td>\n",
       "      <td>0.342645</td>\n",
       "      <td>0.523383</td>\n",
       "      <td>0.639508</td>\n",
       "      <td>0.869696</td>\n",
       "      <td>1.574066</td>\n",
       "      <td>0.331869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.077109</td>\n",
       "      <td>-0.206706</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.006428</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>-0.000304</td>\n",
       "      <td>-0.868233</td>\n",
       "      <td>-0.092663</td>\n",
       "      <td>1.205836</td>\n",
       "      <td>0.265378</td>\n",
       "      <td>0.541464</td>\n",
       "      <td>0.512058</td>\n",
       "      <td>0.907885</td>\n",
       "      <td>1.711111</td>\n",
       "      <td>0.324205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.082828</td>\n",
       "      <td>0.221897</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>-0.008468</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>-0.758676</td>\n",
       "      <td>-0.317667</td>\n",
       "      <td>1.026909</td>\n",
       "      <td>0.273752</td>\n",
       "      <td>0.751935</td>\n",
       "      <td>0.643160</td>\n",
       "      <td>0.944501</td>\n",
       "      <td>1.518423</td>\n",
       "      <td>0.326940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6        x7   \n",
       "0 -0.115912 -0.207162  0.001411  0.012060  0.000871 -0.000108 -0.736734  \\\n",
       "1 -0.081966 -0.182033  0.001298  0.010903  0.000813 -0.000155 -0.755056   \n",
       "2 -0.098121  0.188199  0.001285 -0.010709  0.000807  0.000152 -0.641071   \n",
       "3 -0.077109 -0.206706  0.001522  0.006428  0.000926 -0.000304 -0.868233   \n",
       "4 -0.082828  0.221897  0.000230 -0.008468  0.000198  0.000174 -0.758676   \n",
       "\n",
       "         x8        y0        y1        y2        y3        y4        y5   \n",
       "0  0.012462  0.783335  0.278748  0.497138  0.645087  0.926717  1.717088  \\\n",
       "1  0.031954  1.379462  0.284927  0.386816  0.493242  0.881144  1.562226   \n",
       "2  0.060675  1.124535  0.342645  0.523383  0.639508  0.869696  1.574066   \n",
       "3 -0.092663  1.205836  0.265378  0.541464  0.512058  0.907885  1.711111   \n",
       "4 -0.317667  1.026909  0.273752  0.751935  0.643160  0.944501  1.518423   \n",
       "\n",
       "         y6  \n",
       "0  0.338459  \n",
       "1  0.326036  \n",
       "2  0.331869  \n",
       "3  0.324205  \n",
       "4  0.326940  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed54624a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4796, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ae249e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = [col for col in df.columns if col.startswith('x')]\n",
    "y_columns = [col for col in df.columns if col.startswith('y')]\n",
    "\n",
    "Y = df[x_columns].values\n",
    "X = df[y_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "064de500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_train, X_test, Y_train, Y_test, params):\n",
    "    scaler_x = StandardScaler().fit(X_train)\n",
    "    scaler_y = StandardScaler().fit(Y_train)\n",
    "    X_train = scaler_x.transform(X_train)\n",
    "    X_test = scaler_x.transform(X_test)\n",
    "    Y_train = scaler_y.transform(Y_train)\n",
    "    Y_test = scaler_y.transform(Y_test)\n",
    "\n",
    "    input_shape = X_train.shape[1]\n",
    "    \n",
    "    output_shape = Y_train.shape[1]\n",
    "    return X_train, X_test, Y_train, Y_test, input_shape, output_shape, scaler_x, scaler_y\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=params['test_size'], \n",
    "                                                    random_state=params['random_state'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test, input_shape, output_shape, scaler_x, scaler_y = preprocess_data(X_train, X_test, Y_train, Y_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a10ed4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-4.01657042e-15,  4.72944589e-15,  2.50063555e-15, -3.41465936e-15,\n",
       "        -5.97028509e-15, -9.70058815e-15, -3.51141604e-14]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.mean(axis=0), X_train.std(axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ccb03a",
   "metadata": {},
   "source": [
    "## Appears to be drift, perhaps the sample is not big enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c161da77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.03647091, 0.05036899, 0.0240539 , 0.01615513, 0.02262298,\n",
       "        0.069791  , 0.00742891]),\n",
       " array([1.04363768, 1.03365372, 1.03354061, 1.01573765, 1.04018519,\n",
       "        0.98510014, 1.0395029 ]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.mean(axis=0), X_test.std(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53e58115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.83484230e-17, -2.05489663e-17,  1.57677139e-16,  1.15291278e-16,\n",
       "        -6.44832351e-17, -3.98823600e-17,  2.63764795e-16,  9.18495381e-16]),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.mean(axis=0), Y_train.std(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2baf62f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.02525043,  0.00971201,  0.01397497,  0.04719729,  0.01297527,\n",
       "        -0.02875165, -0.00224075,  0.00415783]),\n",
       " array([1.00535971, 1.00234493, 1.04188367, 1.01245292, 1.03768115,\n",
       "        0.98217117, 1.014723  , 1.01594242]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.mean(axis=0), Y_test.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdca24f",
   "metadata": {},
   "source": [
    "## Dummy regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a74f6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d32b7301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16],\n",
       "       [ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16],\n",
       "       [ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16],\n",
       "       ...,\n",
       "       [ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16],\n",
       "       [ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16],\n",
       "       [ 3.14891202e-17, -9.26150594e-18,  1.42627191e-16, ...,\n",
       "        -4.35290779e-17,  2.74140576e-16,  9.03922980e-16]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = MultiOutputRegressor(DummyRegressor(strategy=\"mean\")).fit(X_train, Y_train)\n",
    "regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e960bbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.784444521947988"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_train, regr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5fa73bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7960079177938875"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_test, regr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ac703",
   "metadata": {},
   "source": [
    "## Train a linear regression for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb67a16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15676934,  0.04012469, -0.12659159, ...,  0.06290221,\n",
       "        -0.40890284,  0.03899315],\n",
       "       [ 0.098538  ,  0.02856683, -0.02685268, ..., -0.01454209,\n",
       "        -0.16032767,  0.49703159],\n",
       "       [-0.17443072,  0.00250346,  0.13851425, ..., -0.0678374 ,\n",
       "        -0.04978863,  0.27261235],\n",
       "       ...,\n",
       "       [ 0.02097198,  0.03903598,  0.03713012, ..., -0.02695103,\n",
       "        -0.3743756 ,  0.34646245],\n",
       "       [-0.26866067,  0.03050944,  0.16463002, ..., -0.05755192,\n",
       "        -0.21087286,  0.37635694],\n",
       "       [ 0.33351338,  0.08189727, -0.20413084, ...,  0.07795407,\n",
       "        -0.54412842,  0.25056948]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = MultiOutputRegressor(Ridge(random_state=123)).fit(X_train, Y_train)\n",
    "regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f8b7880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7415822877132044"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_train, regr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93fe236e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7557919677337949"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_test, regr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909b3bd7",
   "metadata": {},
   "source": [
    "## Simplest neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "606b1b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43d73ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 8), dtype=float32, numpy=\n",
       "array([[ 0.04605619, -0.00905709,  0.06936066,  0.04281695, -0.08537715,\n",
       "         0.04112462, -0.02113203,  0.06998104]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Sequential model with 3 layers\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(input_shape, activation=\"relu\", name=\"layer_in\"),\n",
    "        layers.Dense(128, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(64, activation=\"relu\", name=\"layer3\"),\n",
    "        layers.Dense(output_shape, name=\"layer_out\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model(X_train[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d43388b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer_in (Dense)            (1, 7)                    56        \n",
      "                                                                 \n",
      " layer2 (Dense)              (1, 128)                  1024      \n",
      "                                                                 \n",
      " layer3 (Dense)              (1, 64)                   8256      \n",
      "                                                                 \n",
      " layer_out (Dense)           (1, 8)                    520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9856 (38.50 KB)\n",
      "Trainable params: 9856 (38.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67a8182d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.MeanAbsoluteError(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.MeanAbsoluteError()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b11ea593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/80\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.7605 - mean_absolute_error: 0.7605 - val_loss: 0.7560 - val_mean_absolute_error: 0.7560\n",
      "Epoch 2/80\n",
      "60/60 [==============================] - 0s 707us/step - loss: 0.7369 - mean_absolute_error: 0.7369 - val_loss: 0.7426 - val_mean_absolute_error: 0.7426\n",
      "Epoch 3/80\n",
      "60/60 [==============================] - 0s 648us/step - loss: 0.7243 - mean_absolute_error: 0.7243 - val_loss: 0.7340 - val_mean_absolute_error: 0.7340\n",
      "Epoch 4/80\n",
      "60/60 [==============================] - 0s 695us/step - loss: 0.7162 - mean_absolute_error: 0.7162 - val_loss: 0.7302 - val_mean_absolute_error: 0.7302\n",
      "Epoch 5/80\n",
      "60/60 [==============================] - 0s 669us/step - loss: 0.7112 - mean_absolute_error: 0.7112 - val_loss: 0.7248 - val_mean_absolute_error: 0.7248\n",
      "Epoch 6/80\n",
      "60/60 [==============================] - 0s 704us/step - loss: 0.7072 - mean_absolute_error: 0.7072 - val_loss: 0.7243 - val_mean_absolute_error: 0.7243\n",
      "Epoch 7/80\n",
      "60/60 [==============================] - 0s 672us/step - loss: 0.7045 - mean_absolute_error: 0.7045 - val_loss: 0.7212 - val_mean_absolute_error: 0.7212\n",
      "Epoch 8/80\n",
      "60/60 [==============================] - 0s 644us/step - loss: 0.7016 - mean_absolute_error: 0.7016 - val_loss: 0.7194 - val_mean_absolute_error: 0.7194\n",
      "Epoch 9/80\n",
      "60/60 [==============================] - 0s 657us/step - loss: 0.6997 - mean_absolute_error: 0.6997 - val_loss: 0.7194 - val_mean_absolute_error: 0.7194\n",
      "Epoch 10/80\n",
      "60/60 [==============================] - 0s 649us/step - loss: 0.6976 - mean_absolute_error: 0.6976 - val_loss: 0.7179 - val_mean_absolute_error: 0.7179\n",
      "Epoch 11/80\n",
      "60/60 [==============================] - 0s 642us/step - loss: 0.6960 - mean_absolute_error: 0.6960 - val_loss: 0.7158 - val_mean_absolute_error: 0.7158\n",
      "Epoch 12/80\n",
      "60/60 [==============================] - 0s 649us/step - loss: 0.6947 - mean_absolute_error: 0.6947 - val_loss: 0.7129 - val_mean_absolute_error: 0.7129\n",
      "Epoch 13/80\n",
      "60/60 [==============================] - 0s 661us/step - loss: 0.6926 - mean_absolute_error: 0.6926 - val_loss: 0.7143 - val_mean_absolute_error: 0.7143\n",
      "Epoch 14/80\n",
      "60/60 [==============================] - 0s 659us/step - loss: 0.6915 - mean_absolute_error: 0.6915 - val_loss: 0.7142 - val_mean_absolute_error: 0.7142\n",
      "Epoch 15/80\n",
      "60/60 [==============================] - 0s 669us/step - loss: 0.6901 - mean_absolute_error: 0.6901 - val_loss: 0.7100 - val_mean_absolute_error: 0.7100\n",
      "Epoch 16/80\n",
      "60/60 [==============================] - 0s 659us/step - loss: 0.6884 - mean_absolute_error: 0.6884 - val_loss: 0.7110 - val_mean_absolute_error: 0.7110\n",
      "Epoch 17/80\n",
      "60/60 [==============================] - 0s 664us/step - loss: 0.6877 - mean_absolute_error: 0.6877 - val_loss: 0.7115 - val_mean_absolute_error: 0.7115\n",
      "Epoch 18/80\n",
      "60/60 [==============================] - 0s 671us/step - loss: 0.6862 - mean_absolute_error: 0.6862 - val_loss: 0.7097 - val_mean_absolute_error: 0.7097\n",
      "Epoch 19/80\n",
      "60/60 [==============================] - 0s 649us/step - loss: 0.6851 - mean_absolute_error: 0.6851 - val_loss: 0.7070 - val_mean_absolute_error: 0.7070\n",
      "Epoch 20/80\n",
      "60/60 [==============================] - 0s 648us/step - loss: 0.6838 - mean_absolute_error: 0.6838 - val_loss: 0.7061 - val_mean_absolute_error: 0.7061\n",
      "Epoch 21/80\n",
      "60/60 [==============================] - 0s 649us/step - loss: 0.6829 - mean_absolute_error: 0.6829 - val_loss: 0.7059 - val_mean_absolute_error: 0.7059\n",
      "Epoch 22/80\n",
      "60/60 [==============================] - 0s 661us/step - loss: 0.6816 - mean_absolute_error: 0.6816 - val_loss: 0.7066 - val_mean_absolute_error: 0.7066\n",
      "Epoch 23/80\n",
      "60/60 [==============================] - 0s 651us/step - loss: 0.6802 - mean_absolute_error: 0.6802 - val_loss: 0.7039 - val_mean_absolute_error: 0.7039\n",
      "Epoch 24/80\n",
      "60/60 [==============================] - 0s 654us/step - loss: 0.6790 - mean_absolute_error: 0.6790 - val_loss: 0.7038 - val_mean_absolute_error: 0.7038\n",
      "Epoch 25/80\n",
      "60/60 [==============================] - 0s 634us/step - loss: 0.6782 - mean_absolute_error: 0.6782 - val_loss: 0.7041 - val_mean_absolute_error: 0.7041\n",
      "Epoch 26/80\n",
      "60/60 [==============================] - 0s 663us/step - loss: 0.6769 - mean_absolute_error: 0.6769 - val_loss: 0.7021 - val_mean_absolute_error: 0.7021\n",
      "Epoch 27/80\n",
      "60/60 [==============================] - 0s 668us/step - loss: 0.6762 - mean_absolute_error: 0.6762 - val_loss: 0.7014 - val_mean_absolute_error: 0.7014\n",
      "Epoch 28/80\n",
      "60/60 [==============================] - 0s 653us/step - loss: 0.6749 - mean_absolute_error: 0.6749 - val_loss: 0.7008 - val_mean_absolute_error: 0.7008\n",
      "Epoch 29/80\n",
      "60/60 [==============================] - 0s 660us/step - loss: 0.6737 - mean_absolute_error: 0.6737 - val_loss: 0.7026 - val_mean_absolute_error: 0.7026\n",
      "Epoch 30/80\n",
      "60/60 [==============================] - 0s 670us/step - loss: 0.6729 - mean_absolute_error: 0.6729 - val_loss: 0.6996 - val_mean_absolute_error: 0.6996\n",
      "Epoch 31/80\n",
      "60/60 [==============================] - 0s 663us/step - loss: 0.6719 - mean_absolute_error: 0.6719 - val_loss: 0.6981 - val_mean_absolute_error: 0.6981\n",
      "Epoch 32/80\n",
      "60/60 [==============================] - 0s 687us/step - loss: 0.6702 - mean_absolute_error: 0.6702 - val_loss: 0.6999 - val_mean_absolute_error: 0.6999\n",
      "Epoch 33/80\n",
      "60/60 [==============================] - 0s 675us/step - loss: 0.6696 - mean_absolute_error: 0.6696 - val_loss: 0.7001 - val_mean_absolute_error: 0.7001\n",
      "Epoch 34/80\n",
      "60/60 [==============================] - 0s 690us/step - loss: 0.6687 - mean_absolute_error: 0.6687 - val_loss: 0.6985 - val_mean_absolute_error: 0.6985\n",
      "Epoch 35/80\n",
      "60/60 [==============================] - 0s 655us/step - loss: 0.6678 - mean_absolute_error: 0.6678 - val_loss: 0.6985 - val_mean_absolute_error: 0.6985\n",
      "Epoch 36/80\n",
      "60/60 [==============================] - 0s 655us/step - loss: 0.6670 - mean_absolute_error: 0.6670 - val_loss: 0.6980 - val_mean_absolute_error: 0.6980\n",
      "Epoch 37/80\n",
      "60/60 [==============================] - 0s 660us/step - loss: 0.6665 - mean_absolute_error: 0.6665 - val_loss: 0.6961 - val_mean_absolute_error: 0.6961\n",
      "Epoch 38/80\n",
      "60/60 [==============================] - 0s 639us/step - loss: 0.6654 - mean_absolute_error: 0.6654 - val_loss: 0.6961 - val_mean_absolute_error: 0.6961\n",
      "Epoch 39/80\n",
      "60/60 [==============================] - 0s 648us/step - loss: 0.6636 - mean_absolute_error: 0.6636 - val_loss: 0.6969 - val_mean_absolute_error: 0.6969\n",
      "Epoch 40/80\n",
      "60/60 [==============================] - 0s 632us/step - loss: 0.6636 - mean_absolute_error: 0.6636 - val_loss: 0.6939 - val_mean_absolute_error: 0.6939\n",
      "Epoch 41/80\n",
      "60/60 [==============================] - 0s 649us/step - loss: 0.6620 - mean_absolute_error: 0.6620 - val_loss: 0.6961 - val_mean_absolute_error: 0.6961\n",
      "Epoch 42/80\n",
      "60/60 [==============================] - 0s 652us/step - loss: 0.6614 - mean_absolute_error: 0.6614 - val_loss: 0.6954 - val_mean_absolute_error: 0.6954\n",
      "Epoch 43/80\n",
      "60/60 [==============================] - 0s 655us/step - loss: 0.6603 - mean_absolute_error: 0.6603 - val_loss: 0.6957 - val_mean_absolute_error: 0.6957\n",
      "Epoch 44/80\n",
      "60/60 [==============================] - 0s 640us/step - loss: 0.6596 - mean_absolute_error: 0.6596 - val_loss: 0.6938 - val_mean_absolute_error: 0.6938\n",
      "Epoch 45/80\n",
      "60/60 [==============================] - 0s 636us/step - loss: 0.6589 - mean_absolute_error: 0.6589 - val_loss: 0.6926 - val_mean_absolute_error: 0.6926\n",
      "Epoch 46/80\n",
      "60/60 [==============================] - 0s 649us/step - loss: 0.6572 - mean_absolute_error: 0.6572 - val_loss: 0.6918 - val_mean_absolute_error: 0.6918\n",
      "Epoch 47/80\n",
      "60/60 [==============================] - 0s 639us/step - loss: 0.6571 - mean_absolute_error: 0.6571 - val_loss: 0.6911 - val_mean_absolute_error: 0.6911\n",
      "Epoch 48/80\n",
      "60/60 [==============================] - 0s 657us/step - loss: 0.6560 - mean_absolute_error: 0.6560 - val_loss: 0.6907 - val_mean_absolute_error: 0.6907\n",
      "Epoch 49/80\n",
      "60/60 [==============================] - 0s 681us/step - loss: 0.6559 - mean_absolute_error: 0.6559 - val_loss: 0.6896 - val_mean_absolute_error: 0.6896\n",
      "Epoch 50/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 652us/step - loss: 0.6545 - mean_absolute_error: 0.6545 - val_loss: 0.6897 - val_mean_absolute_error: 0.6897\n",
      "Epoch 51/80\n",
      "60/60 [==============================] - 0s 630us/step - loss: 0.6538 - mean_absolute_error: 0.6538 - val_loss: 0.6904 - val_mean_absolute_error: 0.6904\n",
      "Epoch 52/80\n",
      "60/60 [==============================] - 0s 622us/step - loss: 0.6530 - mean_absolute_error: 0.6530 - val_loss: 0.6903 - val_mean_absolute_error: 0.6903\n",
      "Epoch 53/80\n",
      "60/60 [==============================] - 0s 627us/step - loss: 0.6526 - mean_absolute_error: 0.6526 - val_loss: 0.6911 - val_mean_absolute_error: 0.6911\n",
      "Epoch 54/80\n",
      "60/60 [==============================] - 0s 633us/step - loss: 0.6515 - mean_absolute_error: 0.6515 - val_loss: 0.6908 - val_mean_absolute_error: 0.6908\n",
      "Epoch 55/80\n",
      "60/60 [==============================] - 0s 623us/step - loss: 0.6509 - mean_absolute_error: 0.6509 - val_loss: 0.6898 - val_mean_absolute_error: 0.6898\n",
      "Epoch 56/80\n",
      "60/60 [==============================] - 0s 631us/step - loss: 0.6498 - mean_absolute_error: 0.6498 - val_loss: 0.6892 - val_mean_absolute_error: 0.6892\n",
      "Epoch 57/80\n",
      "60/60 [==============================] - 0s 625us/step - loss: 0.6492 - mean_absolute_error: 0.6492 - val_loss: 0.6903 - val_mean_absolute_error: 0.6903\n",
      "Epoch 58/80\n",
      "60/60 [==============================] - 0s 640us/step - loss: 0.6490 - mean_absolute_error: 0.6490 - val_loss: 0.6879 - val_mean_absolute_error: 0.6879\n",
      "Epoch 59/80\n",
      "60/60 [==============================] - 0s 612us/step - loss: 0.6477 - mean_absolute_error: 0.6477 - val_loss: 0.6879 - val_mean_absolute_error: 0.6879\n",
      "Epoch 60/80\n",
      "60/60 [==============================] - 0s 636us/step - loss: 0.6474 - mean_absolute_error: 0.6474 - val_loss: 0.6880 - val_mean_absolute_error: 0.6880\n",
      "Epoch 61/80\n",
      "60/60 [==============================] - 0s 643us/step - loss: 0.6468 - mean_absolute_error: 0.6468 - val_loss: 0.6868 - val_mean_absolute_error: 0.6868\n",
      "Epoch 62/80\n",
      "60/60 [==============================] - 0s 632us/step - loss: 0.6460 - mean_absolute_error: 0.6460 - val_loss: 0.6859 - val_mean_absolute_error: 0.6859\n",
      "Epoch 63/80\n",
      "60/60 [==============================] - 0s 652us/step - loss: 0.6455 - mean_absolute_error: 0.6455 - val_loss: 0.6881 - val_mean_absolute_error: 0.6881\n",
      "Epoch 64/80\n",
      "60/60 [==============================] - 0s 623us/step - loss: 0.6451 - mean_absolute_error: 0.6451 - val_loss: 0.6861 - val_mean_absolute_error: 0.6861\n",
      "Epoch 65/80\n",
      "60/60 [==============================] - 0s 637us/step - loss: 0.6437 - mean_absolute_error: 0.6437 - val_loss: 0.6868 - val_mean_absolute_error: 0.6868\n",
      "Epoch 66/80\n",
      "60/60 [==============================] - 0s 620us/step - loss: 0.6437 - mean_absolute_error: 0.6437 - val_loss: 0.6862 - val_mean_absolute_error: 0.6862\n",
      "Epoch 67/80\n",
      "60/60 [==============================] - 0s 645us/step - loss: 0.6429 - mean_absolute_error: 0.6429 - val_loss: 0.6871 - val_mean_absolute_error: 0.6871\n",
      "Epoch 68/80\n",
      "60/60 [==============================] - 0s 626us/step - loss: 0.6429 - mean_absolute_error: 0.6429 - val_loss: 0.6872 - val_mean_absolute_error: 0.6872\n",
      "Epoch 69/80\n",
      "60/60 [==============================] - 0s 639us/step - loss: 0.6420 - mean_absolute_error: 0.6420 - val_loss: 0.6883 - val_mean_absolute_error: 0.6883\n",
      "Epoch 70/80\n",
      "60/60 [==============================] - 0s 637us/step - loss: 0.6420 - mean_absolute_error: 0.6420 - val_loss: 0.6855 - val_mean_absolute_error: 0.6855\n",
      "Epoch 71/80\n",
      "60/60 [==============================] - 0s 770us/step - loss: 0.6409 - mean_absolute_error: 0.6409 - val_loss: 0.6862 - val_mean_absolute_error: 0.6862\n",
      "Epoch 72/80\n",
      "60/60 [==============================] - 0s 659us/step - loss: 0.6401 - mean_absolute_error: 0.6401 - val_loss: 0.6877 - val_mean_absolute_error: 0.6877\n",
      "Epoch 73/80\n",
      "60/60 [==============================] - 0s 619us/step - loss: 0.6397 - mean_absolute_error: 0.6397 - val_loss: 0.6872 - val_mean_absolute_error: 0.6872\n",
      "Epoch 74/80\n",
      "60/60 [==============================] - 0s 643us/step - loss: 0.6390 - mean_absolute_error: 0.6390 - val_loss: 0.6857 - val_mean_absolute_error: 0.6857\n",
      "Epoch 75/80\n",
      "60/60 [==============================] - 0s 642us/step - loss: 0.6393 - mean_absolute_error: 0.6393 - val_loss: 0.6854 - val_mean_absolute_error: 0.6854\n",
      "Epoch 76/80\n",
      "60/60 [==============================] - 0s 638us/step - loss: 0.6377 - mean_absolute_error: 0.6377 - val_loss: 0.6851 - val_mean_absolute_error: 0.6851\n",
      "Epoch 77/80\n",
      "60/60 [==============================] - 0s 643us/step - loss: 0.6379 - mean_absolute_error: 0.6379 - val_loss: 0.6858 - val_mean_absolute_error: 0.6858\n",
      "Epoch 78/80\n",
      "60/60 [==============================] - 0s 641us/step - loss: 0.6371 - mean_absolute_error: 0.6371 - val_loss: 0.6844 - val_mean_absolute_error: 0.6844\n",
      "Epoch 79/80\n",
      "60/60 [==============================] - 0s 645us/step - loss: 0.6364 - mean_absolute_error: 0.6364 - val_loss: 0.6863 - val_mean_absolute_error: 0.6863\n",
      "Epoch 80/80\n",
      "60/60 [==============================] - 0s 647us/step - loss: 0.6365 - mean_absolute_error: 0.6365 - val_loss: 0.6847 - val_mean_absolute_error: 0.6847\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    batch_size=64,\n",
    "    epochs=80,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(X_test, Y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93629dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 310us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6316352295677649"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_train, model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04ad8c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 341us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6847244920486559"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_test, model.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
