{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b50697e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30346186",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'test_size': 0.2,\n",
    "    'random_state': 1337,\n",
    "    'validation_split': 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6776a886",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../data/qsc_out.random_scan_nfp2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3599d370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.133438</td>\n",
       "      <td>-0.092950</td>\n",
       "      <td>0.011193</td>\n",
       "      <td>-0.005795</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>-0.713354</td>\n",
       "      <td>0.129141</td>\n",
       "      <td>1.482134</td>\n",
       "      <td>0.213466</td>\n",
       "      <td>0.241207</td>\n",
       "      <td>0.475203</td>\n",
       "      <td>0.852697</td>\n",
       "      <td>1.067530</td>\n",
       "      <td>0.342066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.106896</td>\n",
       "      <td>0.107480</td>\n",
       "      <td>0.007474</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>-0.718440</td>\n",
       "      <td>-0.309748</td>\n",
       "      <td>1.711563</td>\n",
       "      <td>0.178743</td>\n",
       "      <td>0.181471</td>\n",
       "      <td>0.403228</td>\n",
       "      <td>0.821898</td>\n",
       "      <td>1.052911</td>\n",
       "      <td>0.333320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100286</td>\n",
       "      <td>0.098256</td>\n",
       "      <td>0.006654</td>\n",
       "      <td>0.006411</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>-0.775836</td>\n",
       "      <td>0.064299</td>\n",
       "      <td>1.895026</td>\n",
       "      <td>0.154513</td>\n",
       "      <td>0.204983</td>\n",
       "      <td>0.335392</td>\n",
       "      <td>0.807669</td>\n",
       "      <td>0.965668</td>\n",
       "      <td>0.331046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.120435</td>\n",
       "      <td>0.114909</td>\n",
       "      <td>0.009287</td>\n",
       "      <td>0.008526</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>-0.767415</td>\n",
       "      <td>0.016524</td>\n",
       "      <td>1.380982</td>\n",
       "      <td>0.196482</td>\n",
       "      <td>0.304152</td>\n",
       "      <td>0.364896</td>\n",
       "      <td>0.833857</td>\n",
       "      <td>1.286199</td>\n",
       "      <td>0.337564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.128050</td>\n",
       "      <td>0.160498</td>\n",
       "      <td>0.009165</td>\n",
       "      <td>-0.010457</td>\n",
       "      <td>-0.000347</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>-0.719544</td>\n",
       "      <td>0.569769</td>\n",
       "      <td>0.962259</td>\n",
       "      <td>0.304666</td>\n",
       "      <td>0.529468</td>\n",
       "      <td>0.435512</td>\n",
       "      <td>0.834355</td>\n",
       "      <td>1.311465</td>\n",
       "      <td>0.340612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6        x7   \n",
       "0  0.133438 -0.092950  0.011193 -0.005795  0.000771 -0.000122 -0.713354  \\\n",
       "1  0.106896  0.107480  0.007474  0.007549  0.000577  0.000333 -0.718440   \n",
       "2  0.100286  0.098256  0.006654  0.006411  0.000179  0.000225 -0.775836   \n",
       "3  0.120435  0.114909  0.009287  0.008526  0.000167  0.000237 -0.767415   \n",
       "4 -0.128050  0.160498  0.009165 -0.010457 -0.000347  0.000200 -0.719544   \n",
       "\n",
       "         x8        y0        y1        y2        y3        y4        y5   \n",
       "0  0.129141  1.482134  0.213466  0.241207  0.475203  0.852697  1.067530  \\\n",
       "1 -0.309748  1.711563  0.178743  0.181471  0.403228  0.821898  1.052911   \n",
       "2  0.064299  1.895026  0.154513  0.204983  0.335392  0.807669  0.965668   \n",
       "3  0.016524  1.380982  0.196482  0.304152  0.364896  0.833857  1.286199   \n",
       "4  0.569769  0.962259  0.304666  0.529468  0.435512  0.834355  1.311465   \n",
       "\n",
       "         y6  \n",
       "0  0.342066  \n",
       "1  0.333320  \n",
       "2  0.331046  \n",
       "3  0.337564  \n",
       "4  0.340612  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed54624a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 15)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ae249e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = [col for col in df.columns if col.startswith('x')]\n",
    "y_columns = [col for col in df.columns if col.startswith('y')]\n",
    "\n",
    "Y = df[y_columns].values\n",
    "X = df[x_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "064de500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_train, X_test, Y_train, Y_test, params):\n",
    "    scaler_x = StandardScaler().fit(X_train)\n",
    "    scaler_y = StandardScaler().fit(Y_train)\n",
    "    X_train = scaler_x.transform(X_train)\n",
    "    X_test = scaler_x.transform(X_test)\n",
    "    Y_train = scaler_y.transform(Y_train)\n",
    "    Y_test = scaler_y.transform(Y_test)\n",
    "\n",
    "    input_shape = X_train.shape[1]\n",
    "    \n",
    "    output_shape = Y_train.shape[1]\n",
    "    return X_train, X_test, Y_train, Y_test, input_shape, output_shape, scaler_x, scaler_y\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=params['test_size'], \n",
    "                                                    random_state=params['random_state'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test, input_shape, output_shape, scaler_x, scaler_y = preprocess_data(X_train, X_test, Y_train, Y_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a10ed4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.1327621e-08,  2.1925195e-09, -5.5531042e-09,  7.3113129e-09,\n",
       "        -1.3621244e-09,  3.0783935e-09,  1.1375323e-08, -3.8778780e-09],\n",
       "       dtype=float32),\n",
       " array([0.9993136 , 0.99944884, 0.99930733, 0.9995662 , 0.99942106,\n",
       "        0.999486  , 0.9999612 , 0.9995944 ], dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.mean(axis=0), X_train.std(axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ccb03a",
   "metadata": {},
   "source": [
    "## Appears to be drift, perhaps the sample is not big enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c161da77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.00667486,  0.00326206, -0.00185904, -0.00032165, -0.00151821,\n",
       "        -0.0017868 , -0.00261114,  0.00337474], dtype=float32),\n",
       " array([0.99684393, 1.0012466 , 1.000381  , 1.002924  , 0.9978705 ,\n",
       "        0.9981674 , 1.002929  , 1.0042428 ], dtype=float32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.mean(axis=0), X_test.std(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53e58115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.8581934e-09, -5.8630110e-09, -2.2679568e-10,  1.4387071e-10,\n",
       "         4.0571391e-09,  5.9454890e-09, -1.5963987e-09], dtype=float32),\n",
       " array([1.0002788 , 0.9998443 , 0.9994234 , 0.9997594 , 0.99986285,\n",
       "        0.99981064, 0.9998727 ], dtype=float32))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.mean(axis=0), Y_train.std(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2baf62f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.00227338,  0.00395122,  0.00310262,  0.00321028,  0.00143382,\n",
       "         0.00332455, -0.00154998], dtype=float32),\n",
       " array([0.99452734, 1.0021232 , 1.0060604 , 1.008807  , 0.9999831 ,\n",
       "        1.0016111 , 0.99785244], dtype=float32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.mean(axis=0), Y_test.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdca24f",
   "metadata": {},
   "source": [
    "## Dummy regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a74f6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d32b7301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.0783155e-10, -6.2942505e-09,  6.4849853e-10, ...,\n",
       "        -2.5177003e-09, -1.7833710e-09,  3.0517577e-09],\n",
       "       [ 5.0783155e-10, -6.2942505e-09,  6.4849853e-10, ...,\n",
       "        -2.5177003e-09, -1.7833710e-09,  3.0517577e-09],\n",
       "       [ 5.0783155e-10, -6.2942505e-09,  6.4849853e-10, ...,\n",
       "        -2.5177003e-09, -1.7833710e-09,  3.0517577e-09],\n",
       "       ...,\n",
       "       [ 5.0783155e-10, -6.2942505e-09,  6.4849853e-10, ...,\n",
       "        -2.5177003e-09, -1.7833710e-09,  3.0517577e-09],\n",
       "       [ 5.0783155e-10, -6.2942505e-09,  6.4849853e-10, ...,\n",
       "        -2.5177003e-09, -1.7833710e-09,  3.0517577e-09],\n",
       "       [ 5.0783155e-10, -6.2942505e-09,  6.4849853e-10, ...,\n",
       "        -2.5177003e-09, -1.7833710e-09,  3.0517577e-09]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = MultiOutputRegressor(DummyRegressor(strategy=\"mean\")).fit(X_train, Y_train)\n",
    "regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e960bbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63178873"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_train, regr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5fa73bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6326293"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_test, regr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ac703",
   "metadata": {},
   "source": [
    "## Train a linear regression for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb67a16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.92282617e-02, -1.54025435e-01,  3.67904827e-02, ...,\n",
       "         8.91883895e-02,  1.03378534e-01, -4.63521540e-01],\n",
       "       [-2.72226613e-02, -6.77829310e-02, -2.33512698e-03, ...,\n",
       "         5.69161810e-02,  1.49837554e-01, -8.12186658e-01],\n",
       "       [-1.34016767e-01, -2.40030453e-01,  7.71415457e-02, ...,\n",
       "         1.01409532e-01,  5.49193025e-02, -7.21290754e-03],\n",
       "       ...,\n",
       "       [ 2.92817801e-01,  5.27068496e-01, -1.71872094e-01, ...,\n",
       "        -2.38644585e-01, -1.26464874e-01,  2.43872833e-02],\n",
       "       [ 8.15712567e-03,  1.36674335e-02,  7.52523541e-04, ...,\n",
       "        -1.09247095e-03, -7.78605090e-03,  9.96023323e-03],\n",
       "       [-8.90059397e-02, -1.57348022e-01,  3.95330749e-02, ...,\n",
       "         8.14322233e-02,  4.80963849e-02, -4.81136180e-02]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = MultiOutputRegressor(Ridge(random_state=params['random_state'])).fit(X_train, Y_train)\n",
    "regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f8b7880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61463964"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_train, regr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93fe236e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6148032"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_test, regr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909b3bd7",
   "metadata": {},
   "source": [
    "## Simplest neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "606b1b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43d73ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 7), dtype=float32, numpy=\n",
       "array([[ 0.0311353 ,  0.06876908, -0.1295784 , -0.09838126, -0.34702867,\n",
       "         0.04909335, -0.15615612]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Sequential model with 3 layers\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(input_shape, activation=\"relu\", name=\"layer_in\"),\n",
    "        layers.Dense(128, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(64, activation=\"relu\", name=\"layer3\"),\n",
    "        layers.Dense(output_shape, name=\"layer_out\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model(X_train[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d43388b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer_in (Dense)            (1, 8)                    72        \n",
      "                                                                 \n",
      " layer2 (Dense)              (1, 128)                  1152      \n",
      "                                                                 \n",
      " layer3 (Dense)              (1, 64)                   8256      \n",
      "                                                                 \n",
      " layer_out (Dense)           (1, 7)                    455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9935 (38.81 KB)\n",
      "Trainable params: 9935 (38.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67a8182d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.MeanAbsoluteError(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.MeanAbsoluteError()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b11ea593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/400\n",
      "12500/12500 [==============================] - 6s 470us/step - loss: 0.2756 - mean_absolute_error: 0.2756 - val_loss: 0.2315 - val_mean_absolute_error: 0.2315\n",
      "Epoch 2/400\n",
      "12500/12500 [==============================] - 6s 459us/step - loss: 0.2196 - mean_absolute_error: 0.2196 - val_loss: 0.2118 - val_mean_absolute_error: 0.2118\n",
      "Epoch 3/400\n",
      "12500/12500 [==============================] - 6s 479us/step - loss: 0.2045 - mean_absolute_error: 0.2045 - val_loss: 0.2013 - val_mean_absolute_error: 0.2013\n",
      "Epoch 4/400\n",
      "12500/12500 [==============================] - 6s 455us/step - loss: 0.1946 - mean_absolute_error: 0.1946 - val_loss: 0.1896 - val_mean_absolute_error: 0.1896\n",
      "Epoch 5/400\n",
      "12500/12500 [==============================] - 6s 458us/step - loss: 0.1882 - mean_absolute_error: 0.1882 - val_loss: 0.1882 - val_mean_absolute_error: 0.1882\n",
      "Epoch 6/400\n",
      "12500/12500 [==============================] - 6s 456us/step - loss: 0.1836 - mean_absolute_error: 0.1836 - val_loss: 0.1840 - val_mean_absolute_error: 0.1840\n",
      "Epoch 7/400\n",
      "12500/12500 [==============================] - 6s 449us/step - loss: 0.1803 - mean_absolute_error: 0.1803 - val_loss: 0.1788 - val_mean_absolute_error: 0.1788\n",
      "Epoch 8/400\n",
      "12500/12500 [==============================] - 6s 459us/step - loss: 0.1778 - mean_absolute_error: 0.1778 - val_loss: 0.1749 - val_mean_absolute_error: 0.1749\n",
      "Epoch 9/400\n",
      "12500/12500 [==============================] - 6s 455us/step - loss: 0.1760 - mean_absolute_error: 0.1760 - val_loss: 0.1729 - val_mean_absolute_error: 0.1729\n",
      "Epoch 10/400\n",
      "12500/12500 [==============================] - 6s 448us/step - loss: 0.1746 - mean_absolute_error: 0.1746 - val_loss: 0.1742 - val_mean_absolute_error: 0.1742\n",
      "Epoch 11/400\n",
      "12500/12500 [==============================] - 6s 457us/step - loss: 0.1733 - mean_absolute_error: 0.1733 - val_loss: 0.1714 - val_mean_absolute_error: 0.1714\n",
      "Epoch 12/400\n",
      "12500/12500 [==============================] - 6s 483us/step - loss: 0.1720 - mean_absolute_error: 0.1720 - val_loss: 0.1750 - val_mean_absolute_error: 0.1750\n",
      "Epoch 13/400\n",
      "12500/12500 [==============================] - 6s 493us/step - loss: 0.1707 - mean_absolute_error: 0.1707 - val_loss: 0.1727 - val_mean_absolute_error: 0.1727\n",
      "Epoch 14/400\n",
      "12500/12500 [==============================] - 6s 480us/step - loss: 0.1697 - mean_absolute_error: 0.1697 - val_loss: 0.1691 - val_mean_absolute_error: 0.1691\n",
      "Epoch 15/400\n",
      "12500/12500 [==============================] - 6s 455us/step - loss: 0.1687 - mean_absolute_error: 0.1687 - val_loss: 0.1680 - val_mean_absolute_error: 0.1680\n",
      "Epoch 16/400\n",
      "12500/12500 [==============================] - 6s 474us/step - loss: 0.1680 - mean_absolute_error: 0.1680 - val_loss: 0.1676 - val_mean_absolute_error: 0.1676\n",
      "Epoch 17/400\n",
      "12500/12500 [==============================] - 6s 484us/step - loss: 0.1673 - mean_absolute_error: 0.1673 - val_loss: 0.1678 - val_mean_absolute_error: 0.1678\n",
      "Epoch 18/400\n",
      "12500/12500 [==============================] - 6s 450us/step - loss: 0.1667 - mean_absolute_error: 0.1667 - val_loss: 0.1628 - val_mean_absolute_error: 0.1628\n",
      "Epoch 19/400\n",
      "12500/12500 [==============================] - 6s 480us/step - loss: 0.1661 - mean_absolute_error: 0.1661 - val_loss: 0.1658 - val_mean_absolute_error: 0.1658\n",
      "Epoch 20/400\n",
      "12500/12500 [==============================] - 6s 485us/step - loss: 0.1656 - mean_absolute_error: 0.1656 - val_loss: 0.1634 - val_mean_absolute_error: 0.1634\n",
      "Epoch 21/400\n",
      "12500/12500 [==============================] - 6s 479us/step - loss: 0.1651 - mean_absolute_error: 0.1651 - val_loss: 0.1699 - val_mean_absolute_error: 0.1699\n",
      "Epoch 22/400\n",
      "12500/12500 [==============================] - 6s 467us/step - loss: 0.1646 - mean_absolute_error: 0.1646 - val_loss: 0.1669 - val_mean_absolute_error: 0.1669\n",
      "Epoch 23/400\n",
      "12500/12500 [==============================] - 6s 494us/step - loss: 0.1642 - mean_absolute_error: 0.1642 - val_loss: 0.1617 - val_mean_absolute_error: 0.1617\n",
      "Epoch 24/400\n",
      "12500/12500 [==============================] - 6s 480us/step - loss: 0.1637 - mean_absolute_error: 0.1637 - val_loss: 0.1634 - val_mean_absolute_error: 0.1634\n",
      "Epoch 25/400\n",
      "12500/12500 [==============================] - 6s 480us/step - loss: 0.1632 - mean_absolute_error: 0.1632 - val_loss: 0.1673 - val_mean_absolute_error: 0.1673\n",
      "Epoch 26/400\n",
      "12500/12500 [==============================] - 6s 487us/step - loss: 0.1628 - mean_absolute_error: 0.1628 - val_loss: 0.1633 - val_mean_absolute_error: 0.1633\n",
      "Epoch 27/400\n",
      "12500/12500 [==============================] - 6s 482us/step - loss: 0.1624 - mean_absolute_error: 0.1624 - val_loss: 0.1645 - val_mean_absolute_error: 0.1645\n",
      "Epoch 28/400\n",
      "12500/12500 [==============================] - 6s 481us/step - loss: 0.1620 - mean_absolute_error: 0.1620 - val_loss: 0.1622 - val_mean_absolute_error: 0.1622\n",
      "Epoch 29/400\n",
      "12500/12500 [==============================] - 6s 493us/step - loss: 0.1617 - mean_absolute_error: 0.1617 - val_loss: 0.1650 - val_mean_absolute_error: 0.1650\n",
      "Epoch 30/400\n",
      "12500/12500 [==============================] - 6s 490us/step - loss: 0.1614 - mean_absolute_error: 0.1614 - val_loss: 0.1662 - val_mean_absolute_error: 0.1662\n",
      "Epoch 31/400\n",
      "12500/12500 [==============================] - 6s 453us/step - loss: 0.1610 - mean_absolute_error: 0.1610 - val_loss: 0.1600 - val_mean_absolute_error: 0.1600\n",
      "Epoch 32/400\n",
      "12500/12500 [==============================] - 6s 444us/step - loss: 0.1608 - mean_absolute_error: 0.1608 - val_loss: 0.1606 - val_mean_absolute_error: 0.1606\n",
      "Epoch 33/400\n",
      "12500/12500 [==============================] - 6s 456us/step - loss: 0.1605 - mean_absolute_error: 0.1605 - val_loss: 0.1623 - val_mean_absolute_error: 0.1623\n",
      "Epoch 34/400\n",
      "12500/12500 [==============================] - 6s 461us/step - loss: 0.1601 - mean_absolute_error: 0.1601 - val_loss: 0.1606 - val_mean_absolute_error: 0.1606\n",
      "Epoch 35/400\n",
      "12500/12500 [==============================] - 6s 486us/step - loss: 0.1599 - mean_absolute_error: 0.1599 - val_loss: 0.1608 - val_mean_absolute_error: 0.1608\n",
      "Epoch 36/400\n",
      "12500/12500 [==============================] - 6s 467us/step - loss: 0.1596 - mean_absolute_error: 0.1596 - val_loss: 0.1618 - val_mean_absolute_error: 0.1618\n",
      "Epoch 37/400\n",
      "12500/12500 [==============================] - 6s 447us/step - loss: 0.1594 - mean_absolute_error: 0.1594 - val_loss: 0.1588 - val_mean_absolute_error: 0.1588\n",
      "Epoch 38/400\n",
      "12500/12500 [==============================] - 6s 456us/step - loss: 0.1592 - mean_absolute_error: 0.1592 - val_loss: 0.1604 - val_mean_absolute_error: 0.1604\n",
      "Epoch 39/400\n",
      "12500/12500 [==============================] - 6s 446us/step - loss: 0.1590 - mean_absolute_error: 0.1590 - val_loss: 0.1607 - val_mean_absolute_error: 0.1607\n",
      "Epoch 40/400\n",
      "12500/12500 [==============================] - 6s 476us/step - loss: 0.1589 - mean_absolute_error: 0.1589 - val_loss: 0.1589 - val_mean_absolute_error: 0.1589\n",
      "Epoch 41/400\n",
      "12500/12500 [==============================] - 6s 470us/step - loss: 0.1587 - mean_absolute_error: 0.1587 - val_loss: 0.1639 - val_mean_absolute_error: 0.1639\n",
      "Epoch 42/400\n",
      "12500/12500 [==============================] - 6s 446us/step - loss: 0.1585 - mean_absolute_error: 0.1585 - val_loss: 0.1588 - val_mean_absolute_error: 0.1588\n",
      "Epoch 43/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1583 - mean_absolute_error: 0.1583 - val_loss: 0.1606 - val_mean_absolute_error: 0.1606\n",
      "Epoch 44/400\n",
      "12500/12500 [==============================] - 6s 447us/step - loss: 0.1581 - mean_absolute_error: 0.1581 - val_loss: 0.1586 - val_mean_absolute_error: 0.1586\n",
      "Epoch 45/400\n",
      "12500/12500 [==============================] - 6s 454us/step - loss: 0.1579 - mean_absolute_error: 0.1579 - val_loss: 0.1601 - val_mean_absolute_error: 0.1601\n",
      "Epoch 46/400\n",
      "12500/12500 [==============================] - 6s 446us/step - loss: 0.1578 - mean_absolute_error: 0.1578 - val_loss: 0.1613 - val_mean_absolute_error: 0.1613\n",
      "Epoch 47/400\n",
      "12500/12500 [==============================] - 6s 445us/step - loss: 0.1577 - mean_absolute_error: 0.1577 - val_loss: 0.1632 - val_mean_absolute_error: 0.1632\n",
      "Epoch 48/400\n",
      "12500/12500 [==============================] - 6s 452us/step - loss: 0.1576 - mean_absolute_error: 0.1576 - val_loss: 0.1592 - val_mean_absolute_error: 0.1592\n",
      "Epoch 49/400\n",
      "12500/12500 [==============================] - 6s 461us/step - loss: 0.1574 - mean_absolute_error: 0.1574 - val_loss: 0.1578 - val_mean_absolute_error: 0.1578\n",
      "Epoch 50/400\n",
      "12500/12500 [==============================] - 6s 488us/step - loss: 0.1572 - mean_absolute_error: 0.1572 - val_loss: 0.1561 - val_mean_absolute_error: 0.1561\n",
      "Epoch 51/400\n",
      "12500/12500 [==============================] - 6s 469us/step - loss: 0.1571 - mean_absolute_error: 0.1571 - val_loss: 0.1599 - val_mean_absolute_error: 0.1599\n",
      "Epoch 52/400\n",
      "12500/12500 [==============================] - 6s 470us/step - loss: 0.1570 - mean_absolute_error: 0.1570 - val_loss: 0.1569 - val_mean_absolute_error: 0.1569\n",
      "Epoch 53/400\n",
      "12500/12500 [==============================] - 6s 447us/step - loss: 0.1569 - mean_absolute_error: 0.1569 - val_loss: 0.1605 - val_mean_absolute_error: 0.1605\n",
      "Epoch 54/400\n",
      "12500/12500 [==============================] - 6s 461us/step - loss: 0.1568 - mean_absolute_error: 0.1568 - val_loss: 0.1568 - val_mean_absolute_error: 0.1568\n",
      "Epoch 55/400\n",
      "12500/12500 [==============================] - 6s 450us/step - loss: 0.1567 - mean_absolute_error: 0.1567 - val_loss: 0.1590 - val_mean_absolute_error: 0.1590\n",
      "Epoch 56/400\n",
      "12500/12500 [==============================] - 6s 449us/step - loss: 0.1566 - mean_absolute_error: 0.1566 - val_loss: 0.1564 - val_mean_absolute_error: 0.1564\n",
      "Epoch 57/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1565 - mean_absolute_error: 0.1565 - val_loss: 0.1554 - val_mean_absolute_error: 0.1554\n",
      "Epoch 58/400\n",
      "12500/12500 [==============================] - 6s 475us/step - loss: 0.1564 - mean_absolute_error: 0.1564 - val_loss: 0.1543 - val_mean_absolute_error: 0.1543\n",
      "Epoch 59/400\n",
      "12500/12500 [==============================] - 6s 446us/step - loss: 0.1562 - mean_absolute_error: 0.1562 - val_loss: 0.1573 - val_mean_absolute_error: 0.1573\n",
      "Epoch 60/400\n",
      "12500/12500 [==============================] - 6s 465us/step - loss: 0.1562 - mean_absolute_error: 0.1562 - val_loss: 0.1597 - val_mean_absolute_error: 0.1597\n",
      "Epoch 61/400\n",
      "12500/12500 [==============================] - 6s 458us/step - loss: 0.1561 - mean_absolute_error: 0.1561 - val_loss: 0.1597 - val_mean_absolute_error: 0.1597\n",
      "Epoch 62/400\n",
      "12500/12500 [==============================] - 6s 453us/step - loss: 0.1560 - mean_absolute_error: 0.1560 - val_loss: 0.1592 - val_mean_absolute_error: 0.1592\n",
      "Epoch 63/400\n",
      "12500/12500 [==============================] - 6s 456us/step - loss: 0.1558 - mean_absolute_error: 0.1558 - val_loss: 0.1569 - val_mean_absolute_error: 0.1569\n",
      "Epoch 64/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1558 - mean_absolute_error: 0.1558 - val_loss: 0.1575 - val_mean_absolute_error: 0.1575\n",
      "Epoch 65/400\n",
      "12500/12500 [==============================] - 6s 456us/step - loss: 0.1557 - mean_absolute_error: 0.1557 - val_loss: 0.1553 - val_mean_absolute_error: 0.1553\n",
      "Epoch 66/400\n",
      "12500/12500 [==============================] - 6s 472us/step - loss: 0.1556 - mean_absolute_error: 0.1556 - val_loss: 0.1563 - val_mean_absolute_error: 0.1563\n",
      "Epoch 67/400\n",
      "12500/12500 [==============================] - 6s 457us/step - loss: 0.1555 - mean_absolute_error: 0.1555 - val_loss: 0.1582 - val_mean_absolute_error: 0.1582\n",
      "Epoch 68/400\n",
      "12500/12500 [==============================] - 6s 452us/step - loss: 0.1555 - mean_absolute_error: 0.1555 - val_loss: 0.1545 - val_mean_absolute_error: 0.1545\n",
      "Epoch 69/400\n",
      "12500/12500 [==============================] - 6s 451us/step - loss: 0.1554 - mean_absolute_error: 0.1554 - val_loss: 0.1576 - val_mean_absolute_error: 0.1576\n",
      "Epoch 70/400\n",
      "12500/12500 [==============================] - 6s 446us/step - loss: 0.1554 - mean_absolute_error: 0.1554 - val_loss: 0.1564 - val_mean_absolute_error: 0.1564\n",
      "Epoch 71/400\n",
      "12500/12500 [==============================] - 6s 466us/step - loss: 0.1552 - mean_absolute_error: 0.1552 - val_loss: 0.1554 - val_mean_absolute_error: 0.1554\n",
      "Epoch 72/400\n",
      "12500/12500 [==============================] - 6s 455us/step - loss: 0.1552 - mean_absolute_error: 0.1552 - val_loss: 0.1573 - val_mean_absolute_error: 0.1573\n",
      "Epoch 73/400\n",
      "12500/12500 [==============================] - 6s 461us/step - loss: 0.1552 - mean_absolute_error: 0.1552 - val_loss: 0.1582 - val_mean_absolute_error: 0.1582\n",
      "Epoch 74/400\n",
      "12500/12500 [==============================] - 6s 463us/step - loss: 0.1551 - mean_absolute_error: 0.1551 - val_loss: 0.1549 - val_mean_absolute_error: 0.1549\n",
      "Epoch 75/400\n",
      "12500/12500 [==============================] - 6s 452us/step - loss: 0.1550 - mean_absolute_error: 0.1550 - val_loss: 0.1596 - val_mean_absolute_error: 0.1596\n",
      "Epoch 76/400\n",
      "12500/12500 [==============================] - 6s 465us/step - loss: 0.1549 - mean_absolute_error: 0.1549 - val_loss: 0.1546 - val_mean_absolute_error: 0.1546\n",
      "Epoch 77/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1549 - mean_absolute_error: 0.1549 - val_loss: 0.1603 - val_mean_absolute_error: 0.1603\n",
      "Epoch 78/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1548 - mean_absolute_error: 0.1548 - val_loss: 0.1556 - val_mean_absolute_error: 0.1556\n",
      "Epoch 79/400\n",
      "12500/12500 [==============================] - 6s 477us/step - loss: 0.1548 - mean_absolute_error: 0.1548 - val_loss: 0.1576 - val_mean_absolute_error: 0.1576\n",
      "Epoch 80/400\n",
      "12500/12500 [==============================] - 6s 462us/step - loss: 0.1547 - mean_absolute_error: 0.1547 - val_loss: 0.1558 - val_mean_absolute_error: 0.1558\n",
      "Epoch 81/400\n",
      "12500/12500 [==============================] - 6s 463us/step - loss: 0.1547 - mean_absolute_error: 0.1547 - val_loss: 0.1590 - val_mean_absolute_error: 0.1590\n",
      "Epoch 82/400\n",
      "12500/12500 [==============================] - 6s 452us/step - loss: 0.1546 - mean_absolute_error: 0.1546 - val_loss: 0.1594 - val_mean_absolute_error: 0.1594\n",
      "Epoch 83/400\n",
      "12500/12500 [==============================] - 6s 456us/step - loss: 0.1546 - mean_absolute_error: 0.1546 - val_loss: 0.1551 - val_mean_absolute_error: 0.1551\n",
      "Epoch 84/400\n",
      "12500/12500 [==============================] - 6s 475us/step - loss: 0.1545 - mean_absolute_error: 0.1545 - val_loss: 0.1569 - val_mean_absolute_error: 0.1569\n",
      "Epoch 85/400\n",
      "12500/12500 [==============================] - 6s 450us/step - loss: 0.1545 - mean_absolute_error: 0.1545 - val_loss: 0.1579 - val_mean_absolute_error: 0.1579\n",
      "Epoch 86/400\n",
      "12500/12500 [==============================] - 6s 455us/step - loss: 0.1544 - mean_absolute_error: 0.1544 - val_loss: 0.1574 - val_mean_absolute_error: 0.1574\n",
      "Epoch 87/400\n",
      "12500/12500 [==============================] - 6s 470us/step - loss: 0.1544 - mean_absolute_error: 0.1544 - val_loss: 0.1578 - val_mean_absolute_error: 0.1578\n",
      "Epoch 88/400\n",
      "12500/12500 [==============================] - 6s 478us/step - loss: 0.1543 - mean_absolute_error: 0.1543 - val_loss: 0.1554 - val_mean_absolute_error: 0.1554\n",
      "Epoch 89/400\n",
      "12500/12500 [==============================] - 6s 469us/step - loss: 0.1543 - mean_absolute_error: 0.1543 - val_loss: 0.1562 - val_mean_absolute_error: 0.1562\n",
      "Epoch 90/400\n",
      "12500/12500 [==============================] - 6s 461us/step - loss: 0.1543 - mean_absolute_error: 0.1543 - val_loss: 0.1550 - val_mean_absolute_error: 0.1550\n",
      "Epoch 91/400\n",
      "12500/12500 [==============================] - 6s 452us/step - loss: 0.1542 - mean_absolute_error: 0.1542 - val_loss: 0.1586 - val_mean_absolute_error: 0.1586\n",
      "Epoch 92/400\n",
      "12500/12500 [==============================] - 6s 453us/step - loss: 0.1541 - mean_absolute_error: 0.1541 - val_loss: 0.1563 - val_mean_absolute_error: 0.1563\n",
      "Epoch 93/400\n",
      "12500/12500 [==============================] - 6s 462us/step - loss: 0.1541 - mean_absolute_error: 0.1541 - val_loss: 0.1543 - val_mean_absolute_error: 0.1543\n",
      "Epoch 94/400\n",
      "12500/12500 [==============================] - 6s 494us/step - loss: 0.1540 - mean_absolute_error: 0.1540 - val_loss: 0.1587 - val_mean_absolute_error: 0.1587\n",
      "Epoch 95/400\n",
      "12500/12500 [==============================] - 6s 446us/step - loss: 0.1540 - mean_absolute_error: 0.1540 - val_loss: 0.1564 - val_mean_absolute_error: 0.1564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/400\n",
      "12500/12500 [==============================] - 6s 485us/step - loss: 0.1540 - mean_absolute_error: 0.1540 - val_loss: 0.1578 - val_mean_absolute_error: 0.1578\n",
      "Epoch 97/400\n",
      "12500/12500 [==============================] - 6s 451us/step - loss: 0.1539 - mean_absolute_error: 0.1539 - val_loss: 0.1541 - val_mean_absolute_error: 0.1541\n",
      "Epoch 98/400\n",
      "12500/12500 [==============================] - 6s 451us/step - loss: 0.1539 - mean_absolute_error: 0.1539 - val_loss: 0.1547 - val_mean_absolute_error: 0.1547\n",
      "Epoch 99/400\n",
      "12500/12500 [==============================] - 6s 464us/step - loss: 0.1539 - mean_absolute_error: 0.1539 - val_loss: 0.1564 - val_mean_absolute_error: 0.1564\n",
      "Epoch 100/400\n",
      "12500/12500 [==============================] - 6s 469us/step - loss: 0.1539 - mean_absolute_error: 0.1539 - val_loss: 0.1558 - val_mean_absolute_error: 0.1558\n",
      "Epoch 101/400\n",
      "12500/12500 [==============================] - 6s 453us/step - loss: 0.1538 - mean_absolute_error: 0.1538 - val_loss: 0.1539 - val_mean_absolute_error: 0.1539\n",
      "Epoch 102/400\n",
      "12500/12500 [==============================] - 6s 478us/step - loss: 0.1537 - mean_absolute_error: 0.1537 - val_loss: 0.1562 - val_mean_absolute_error: 0.1562\n",
      "Epoch 103/400\n",
      "12500/12500 [==============================] - 6s 455us/step - loss: 0.1537 - mean_absolute_error: 0.1537 - val_loss: 0.1530 - val_mean_absolute_error: 0.1530\n",
      "Epoch 104/400\n",
      "12500/12500 [==============================] - 6s 462us/step - loss: 0.1536 - mean_absolute_error: 0.1536 - val_loss: 0.1539 - val_mean_absolute_error: 0.1539\n",
      "Epoch 105/400\n",
      "12500/12500 [==============================] - 6s 458us/step - loss: 0.1536 - mean_absolute_error: 0.1536 - val_loss: 0.1561 - val_mean_absolute_error: 0.1561\n",
      "Epoch 106/400\n",
      "12500/12500 [==============================] - 6s 452us/step - loss: 0.1535 - mean_absolute_error: 0.1535 - val_loss: 0.1550 - val_mean_absolute_error: 0.1550\n",
      "Epoch 107/400\n",
      "12500/12500 [==============================] - 6s 451us/step - loss: 0.1535 - mean_absolute_error: 0.1535 - val_loss: 0.1558 - val_mean_absolute_error: 0.1558\n",
      "Epoch 108/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1535 - mean_absolute_error: 0.1535 - val_loss: 0.1536 - val_mean_absolute_error: 0.1536\n",
      "Epoch 109/400\n",
      "12500/12500 [==============================] - 6s 454us/step - loss: 0.1534 - mean_absolute_error: 0.1534 - val_loss: 0.1554 - val_mean_absolute_error: 0.1554\n",
      "Epoch 110/400\n",
      "12500/12500 [==============================] - 6s 456us/step - loss: 0.1534 - mean_absolute_error: 0.1534 - val_loss: 0.1550 - val_mean_absolute_error: 0.1550\n",
      "Epoch 111/400\n",
      "12500/12500 [==============================] - 6s 466us/step - loss: 0.1533 - mean_absolute_error: 0.1533 - val_loss: 0.1524 - val_mean_absolute_error: 0.1524\n",
      "Epoch 112/400\n",
      "12500/12500 [==============================] - 13s 1ms/step - loss: 0.1534 - mean_absolute_error: 0.1534 - val_loss: 0.1536 - val_mean_absolute_error: 0.1536\n",
      "Epoch 113/400\n",
      "12500/12500 [==============================] - 9s 691us/step - loss: 0.1534 - mean_absolute_error: 0.1534 - val_loss: 0.1545 - val_mean_absolute_error: 0.1545\n",
      "Epoch 114/400\n",
      "12500/12500 [==============================] - 9s 726us/step - loss: 0.1533 - mean_absolute_error: 0.1533 - val_loss: 0.1542 - val_mean_absolute_error: 0.1542\n",
      "Epoch 115/400\n",
      "12500/12500 [==============================] - 9s 732us/step - loss: 0.1532 - mean_absolute_error: 0.1532 - val_loss: 0.1545 - val_mean_absolute_error: 0.1545\n",
      "Epoch 116/400\n",
      "12500/12500 [==============================] - 10s 792us/step - loss: 0.1532 - mean_absolute_error: 0.1532 - val_loss: 0.1554 - val_mean_absolute_error: 0.1554\n",
      "Epoch 117/400\n",
      "12500/12500 [==============================] - 9s 752us/step - loss: 0.1531 - mean_absolute_error: 0.1531 - val_loss: 0.1558 - val_mean_absolute_error: 0.1558\n",
      "Epoch 118/400\n",
      "12500/12500 [==============================] - 10s 772us/step - loss: 0.1531 - mean_absolute_error: 0.1531 - val_loss: 0.1532 - val_mean_absolute_error: 0.1532\n",
      "Epoch 119/400\n",
      "12500/12500 [==============================] - 10s 769us/step - loss: 0.1530 - mean_absolute_error: 0.1530 - val_loss: 0.1526 - val_mean_absolute_error: 0.1526\n",
      "Epoch 120/400\n",
      "12500/12500 [==============================] - 9s 753us/step - loss: 0.1531 - mean_absolute_error: 0.1531 - val_loss: 0.1538 - val_mean_absolute_error: 0.1538\n",
      "Epoch 121/400\n",
      "12500/12500 [==============================] - 10s 765us/step - loss: 0.1530 - mean_absolute_error: 0.1530 - val_loss: 0.1536 - val_mean_absolute_error: 0.1536\n",
      "Epoch 122/400\n",
      "12500/12500 [==============================] - 9s 759us/step - loss: 0.1530 - mean_absolute_error: 0.1530 - val_loss: 0.1543 - val_mean_absolute_error: 0.1543\n",
      "Epoch 123/400\n",
      "12500/12500 [==============================] - 10s 785us/step - loss: 0.1529 - mean_absolute_error: 0.1529 - val_loss: 0.1597 - val_mean_absolute_error: 0.1597\n",
      "Epoch 124/400\n",
      "12500/12500 [==============================] - 9s 738us/step - loss: 0.1530 - mean_absolute_error: 0.1530 - val_loss: 0.1549 - val_mean_absolute_error: 0.1549\n",
      "Epoch 125/400\n",
      "12500/12500 [==============================] - 10s 792us/step - loss: 0.1530 - mean_absolute_error: 0.1530 - val_loss: 0.1528 - val_mean_absolute_error: 0.1528\n",
      "Epoch 126/400\n",
      "12500/12500 [==============================] - 10s 785us/step - loss: 0.1529 - mean_absolute_error: 0.1529 - val_loss: 0.1529 - val_mean_absolute_error: 0.1529\n",
      "Epoch 127/400\n",
      "12500/12500 [==============================] - 6s 517us/step - loss: 0.1528 - mean_absolute_error: 0.1528 - val_loss: 0.1565 - val_mean_absolute_error: 0.1565\n",
      "Epoch 128/400\n",
      "12500/12500 [==============================] - 6s 469us/step - loss: 0.1529 - mean_absolute_error: 0.1529 - val_loss: 0.1578 - val_mean_absolute_error: 0.1578\n",
      "Epoch 129/400\n",
      "12500/12500 [==============================] - 7s 580us/step - loss: 0.1528 - mean_absolute_error: 0.1528 - val_loss: 0.1533 - val_mean_absolute_error: 0.1533\n",
      "Epoch 130/400\n",
      "12500/12500 [==============================] - 7s 598us/step - loss: 0.1528 - mean_absolute_error: 0.1528 - val_loss: 0.1535 - val_mean_absolute_error: 0.1535\n",
      "Epoch 131/400\n",
      "12500/12500 [==============================] - 6s 452us/step - loss: 0.1528 - mean_absolute_error: 0.1528 - val_loss: 0.1563 - val_mean_absolute_error: 0.1563\n",
      "Epoch 132/400\n",
      "12500/12500 [==============================] - 6s 455us/step - loss: 0.1527 - mean_absolute_error: 0.1527 - val_loss: 0.1552 - val_mean_absolute_error: 0.1552\n",
      "Epoch 133/400\n",
      "12500/12500 [==============================] - 6s 457us/step - loss: 0.1528 - mean_absolute_error: 0.1528 - val_loss: 0.1545 - val_mean_absolute_error: 0.1545\n",
      "Epoch 134/400\n",
      "12500/12500 [==============================] - 6s 459us/step - loss: 0.1527 - mean_absolute_error: 0.1527 - val_loss: 0.1533 - val_mean_absolute_error: 0.1533\n",
      "Epoch 135/400\n",
      "12500/12500 [==============================] - 6s 462us/step - loss: 0.1527 - mean_absolute_error: 0.1527 - val_loss: 0.1520 - val_mean_absolute_error: 0.1520\n",
      "Epoch 136/400\n",
      "12500/12500 [==============================] - 6s 499us/step - loss: 0.1526 - mean_absolute_error: 0.1526 - val_loss: 0.1543 - val_mean_absolute_error: 0.1543\n",
      "Epoch 137/400\n",
      "12500/12500 [==============================] - 6s 459us/step - loss: 0.1526 - mean_absolute_error: 0.1526 - val_loss: 0.1536 - val_mean_absolute_error: 0.1536\n",
      "Epoch 138/400\n",
      "12500/12500 [==============================] - 6s 456us/step - loss: 0.1526 - mean_absolute_error: 0.1526 - val_loss: 0.1537 - val_mean_absolute_error: 0.1537\n",
      "Epoch 139/400\n",
      "12500/12500 [==============================] - 6s 464us/step - loss: 0.1526 - mean_absolute_error: 0.1526 - val_loss: 0.1546 - val_mean_absolute_error: 0.1546\n",
      "Epoch 140/400\n",
      "12500/12500 [==============================] - 6s 457us/step - loss: 0.1526 - mean_absolute_error: 0.1526 - val_loss: 0.1512 - val_mean_absolute_error: 0.1512\n",
      "Epoch 141/400\n",
      "12500/12500 [==============================] - 6s 471us/step - loss: 0.1525 - mean_absolute_error: 0.1525 - val_loss: 0.1531 - val_mean_absolute_error: 0.1531\n",
      "Epoch 142/400\n",
      "12500/12500 [==============================] - 6s 461us/step - loss: 0.1525 - mean_absolute_error: 0.1525 - val_loss: 0.1563 - val_mean_absolute_error: 0.1563\n",
      "Epoch 143/400\n",
      "12500/12500 [==============================] - 6s 474us/step - loss: 0.1525 - mean_absolute_error: 0.1525 - val_loss: 0.1541 - val_mean_absolute_error: 0.1541\n",
      "Epoch 144/400\n",
      "12500/12500 [==============================] - 6s 473us/step - loss: 0.1524 - mean_absolute_error: 0.1524 - val_loss: 0.1522 - val_mean_absolute_error: 0.1522\n",
      "Epoch 145/400\n",
      "12500/12500 [==============================] - 6s 481us/step - loss: 0.1524 - mean_absolute_error: 0.1524 - val_loss: 0.1532 - val_mean_absolute_error: 0.1532\n",
      "Epoch 146/400\n",
      "12500/12500 [==============================] - 7s 523us/step - loss: 0.1524 - mean_absolute_error: 0.1524 - val_loss: 0.1571 - val_mean_absolute_error: 0.1571\n",
      "Epoch 147/400\n",
      "12500/12500 [==============================] - 6s 477us/step - loss: 0.1524 - mean_absolute_error: 0.1524 - val_loss: 0.1569 - val_mean_absolute_error: 0.1569\n",
      "Epoch 148/400\n",
      "12500/12500 [==============================] - 6s 502us/step - loss: 0.1524 - mean_absolute_error: 0.1524 - val_loss: 0.1561 - val_mean_absolute_error: 0.1561\n",
      "Epoch 149/400\n",
      "12500/12500 [==============================] - 6s 503us/step - loss: 0.1523 - mean_absolute_error: 0.1523 - val_loss: 0.1540 - val_mean_absolute_error: 0.1540\n",
      "Epoch 150/400\n",
      "12500/12500 [==============================] - 6s 490us/step - loss: 0.1523 - mean_absolute_error: 0.1523 - val_loss: 0.1517 - val_mean_absolute_error: 0.1517\n",
      "Epoch 151/400\n",
      "12500/12500 [==============================] - 6s 462us/step - loss: 0.1523 - mean_absolute_error: 0.1523 - val_loss: 0.1525 - val_mean_absolute_error: 0.1525\n",
      "Epoch 152/400\n",
      "12500/12500 [==============================] - 6s 470us/step - loss: 0.1523 - mean_absolute_error: 0.1523 - val_loss: 0.1548 - val_mean_absolute_error: 0.1548\n",
      "Epoch 153/400\n",
      "12500/12500 [==============================] - 6s 458us/step - loss: 0.1522 - mean_absolute_error: 0.1522 - val_loss: 0.1510 - val_mean_absolute_error: 0.1510\n",
      "Epoch 154/400\n",
      "12500/12500 [==============================] - 6s 496us/step - loss: 0.1522 - mean_absolute_error: 0.1522 - val_loss: 0.1530 - val_mean_absolute_error: 0.1530\n",
      "Epoch 155/400\n",
      "12500/12500 [==============================] - 6s 491us/step - loss: 0.1522 - mean_absolute_error: 0.1522 - val_loss: 0.1544 - val_mean_absolute_error: 0.1544\n",
      "Epoch 156/400\n",
      "12500/12500 [==============================] - 6s 498us/step - loss: 0.1522 - mean_absolute_error: 0.1522 - val_loss: 0.1520 - val_mean_absolute_error: 0.1520\n",
      "Epoch 157/400\n",
      "12500/12500 [==============================] - 6s 476us/step - loss: 0.1521 - mean_absolute_error: 0.1521 - val_loss: 0.1519 - val_mean_absolute_error: 0.1519\n",
      "Epoch 158/400\n",
      "12500/12500 [==============================] - 6s 504us/step - loss: 0.1521 - mean_absolute_error: 0.1521 - val_loss: 0.1571 - val_mean_absolute_error: 0.1571\n",
      "Epoch 159/400\n",
      "12500/12500 [==============================] - 6s 467us/step - loss: 0.1520 - mean_absolute_error: 0.1520 - val_loss: 0.1527 - val_mean_absolute_error: 0.1527\n",
      "Epoch 160/400\n",
      "12500/12500 [==============================] - 6s 517us/step - loss: 0.1521 - mean_absolute_error: 0.1521 - val_loss: 0.1529 - val_mean_absolute_error: 0.1529\n",
      "Epoch 161/400\n",
      "12500/12500 [==============================] - 7s 524us/step - loss: 0.1520 - mean_absolute_error: 0.1520 - val_loss: 0.1550 - val_mean_absolute_error: 0.1550\n",
      "Epoch 162/400\n",
      "12500/12500 [==============================] - 6s 501us/step - loss: 0.1520 - mean_absolute_error: 0.1520 - val_loss: 0.1505 - val_mean_absolute_error: 0.1505\n",
      "Epoch 163/400\n",
      "12500/12500 [==============================] - 6s 468us/step - loss: 0.1519 - mean_absolute_error: 0.1519 - val_loss: 0.1538 - val_mean_absolute_error: 0.1538\n",
      "Epoch 164/400\n",
      "12500/12500 [==============================] - 6s 451us/step - loss: 0.1519 - mean_absolute_error: 0.1519 - val_loss: 0.1510 - val_mean_absolute_error: 0.1510\n",
      "Epoch 165/400\n",
      "12500/12500 [==============================] - 7s 526us/step - loss: 0.1520 - mean_absolute_error: 0.1520 - val_loss: 0.1594 - val_mean_absolute_error: 0.1594\n",
      "Epoch 166/400\n",
      "12500/12500 [==============================] - 6s 476us/step - loss: 0.1520 - mean_absolute_error: 0.1520 - val_loss: 0.1528 - val_mean_absolute_error: 0.1528\n",
      "Epoch 167/400\n",
      "12500/12500 [==============================] - 6s 483us/step - loss: 0.1519 - mean_absolute_error: 0.1519 - val_loss: 0.1550 - val_mean_absolute_error: 0.1550\n",
      "Epoch 168/400\n",
      "12500/12500 [==============================] - 6s 500us/step - loss: 0.1519 - mean_absolute_error: 0.1519 - val_loss: 0.1558 - val_mean_absolute_error: 0.1558\n",
      "Epoch 169/400\n",
      "12500/12500 [==============================] - 6s 490us/step - loss: 0.1518 - mean_absolute_error: 0.1518 - val_loss: 0.1519 - val_mean_absolute_error: 0.1519\n",
      "Epoch 170/400\n",
      "12500/12500 [==============================] - 6s 467us/step - loss: 0.1518 - mean_absolute_error: 0.1518 - val_loss: 0.1523 - val_mean_absolute_error: 0.1523\n",
      "Epoch 171/400\n",
      "12500/12500 [==============================] - 6s 461us/step - loss: 0.1518 - mean_absolute_error: 0.1518 - val_loss: 0.1518 - val_mean_absolute_error: 0.1518\n",
      "Epoch 172/400\n",
      "12500/12500 [==============================] - 6s 480us/step - loss: 0.1518 - mean_absolute_error: 0.1518 - val_loss: 0.1554 - val_mean_absolute_error: 0.1554\n",
      "Epoch 173/400\n",
      "12500/12500 [==============================] - 6s 486us/step - loss: 0.1518 - mean_absolute_error: 0.1518 - val_loss: 0.1521 - val_mean_absolute_error: 0.1521\n",
      "Epoch 174/400\n",
      "12500/12500 [==============================] - 6s 469us/step - loss: 0.1518 - mean_absolute_error: 0.1518 - val_loss: 0.1510 - val_mean_absolute_error: 0.1510\n",
      "Epoch 175/400\n",
      "12500/12500 [==============================] - 6s 475us/step - loss: 0.1518 - mean_absolute_error: 0.1518 - val_loss: 0.1543 - val_mean_absolute_error: 0.1543\n",
      "Epoch 176/400\n",
      "12500/12500 [==============================] - 6s 468us/step - loss: 0.1518 - mean_absolute_error: 0.1518 - val_loss: 0.1538 - val_mean_absolute_error: 0.1538\n",
      "Epoch 177/400\n",
      "12500/12500 [==============================] - 6s 456us/step - loss: 0.1517 - mean_absolute_error: 0.1517 - val_loss: 0.1515 - val_mean_absolute_error: 0.1515\n",
      "Epoch 178/400\n",
      "12500/12500 [==============================] - 6s 461us/step - loss: 0.1518 - mean_absolute_error: 0.1518 - val_loss: 0.1517 - val_mean_absolute_error: 0.1517\n",
      "Epoch 179/400\n",
      "12500/12500 [==============================] - 6s 452us/step - loss: 0.1517 - mean_absolute_error: 0.1517 - val_loss: 0.1498 - val_mean_absolute_error: 0.1498\n",
      "Epoch 180/400\n",
      "12500/12500 [==============================] - 6s 451us/step - loss: 0.1517 - mean_absolute_error: 0.1517 - val_loss: 0.1528 - val_mean_absolute_error: 0.1528\n",
      "Epoch 181/400\n",
      "12500/12500 [==============================] - 6s 453us/step - loss: 0.1517 - mean_absolute_error: 0.1517 - val_loss: 0.1544 - val_mean_absolute_error: 0.1544\n",
      "Epoch 182/400\n",
      "12500/12500 [==============================] - 6s 451us/step - loss: 0.1517 - mean_absolute_error: 0.1517 - val_loss: 0.1534 - val_mean_absolute_error: 0.1534\n",
      "Epoch 183/400\n",
      "12500/12500 [==============================] - 6s 452us/step - loss: 0.1517 - mean_absolute_error: 0.1517 - val_loss: 0.1537 - val_mean_absolute_error: 0.1537\n",
      "Epoch 184/400\n",
      "12500/12500 [==============================] - 6s 473us/step - loss: 0.1516 - mean_absolute_error: 0.1516 - val_loss: 0.1556 - val_mean_absolute_error: 0.1556\n",
      "Epoch 185/400\n",
      "12500/12500 [==============================] - 6s 451us/step - loss: 0.1516 - mean_absolute_error: 0.1516 - val_loss: 0.1533 - val_mean_absolute_error: 0.1533\n",
      "Epoch 186/400\n",
      "12500/12500 [==============================] - 6s 452us/step - loss: 0.1516 - mean_absolute_error: 0.1516 - val_loss: 0.1563 - val_mean_absolute_error: 0.1563\n",
      "Epoch 187/400\n",
      "12500/12500 [==============================] - 6s 451us/step - loss: 0.1516 - mean_absolute_error: 0.1516 - val_loss: 0.1546 - val_mean_absolute_error: 0.1546\n",
      "Epoch 188/400\n",
      "12500/12500 [==============================] - 6s 453us/step - loss: 0.1516 - mean_absolute_error: 0.1516 - val_loss: 0.1500 - val_mean_absolute_error: 0.1500\n",
      "Epoch 189/400\n",
      "12500/12500 [==============================] - 6s 453us/step - loss: 0.1516 - mean_absolute_error: 0.1516 - val_loss: 0.1545 - val_mean_absolute_error: 0.1545\n",
      "Epoch 190/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 6s 453us/step - loss: 0.1515 - mean_absolute_error: 0.1515 - val_loss: 0.1581 - val_mean_absolute_error: 0.1581\n",
      "Epoch 191/400\n",
      "12500/12500 [==============================] - 6s 454us/step - loss: 0.1515 - mean_absolute_error: 0.1515 - val_loss: 0.1517 - val_mean_absolute_error: 0.1517\n",
      "Epoch 192/400\n",
      "12500/12500 [==============================] - 6s 449us/step - loss: 0.1515 - mean_absolute_error: 0.1515 - val_loss: 0.1533 - val_mean_absolute_error: 0.1533\n",
      "Epoch 193/400\n",
      "12500/12500 [==============================] - 6s 473us/step - loss: 0.1515 - mean_absolute_error: 0.1515 - val_loss: 0.1523 - val_mean_absolute_error: 0.1523\n",
      "Epoch 194/400\n",
      "12500/12500 [==============================] - 7s 596us/step - loss: 0.1516 - mean_absolute_error: 0.1516 - val_loss: 0.1562 - val_mean_absolute_error: 0.1562\n",
      "Epoch 195/400\n",
      "12500/12500 [==============================] - 8s 648us/step - loss: 0.1516 - mean_absolute_error: 0.1516 - val_loss: 0.1534 - val_mean_absolute_error: 0.1534\n",
      "Epoch 196/400\n",
      "12500/12500 [==============================] - 6s 502us/step - loss: 0.1515 - mean_absolute_error: 0.1515 - val_loss: 0.1518 - val_mean_absolute_error: 0.1518\n",
      "Epoch 197/400\n",
      "12500/12500 [==============================] - 6s 474us/step - loss: 0.1515 - mean_absolute_error: 0.1515 - val_loss: 0.1546 - val_mean_absolute_error: 0.1546\n",
      "Epoch 198/400\n",
      "12500/12500 [==============================] - 6s 491us/step - loss: 0.1515 - mean_absolute_error: 0.1515 - val_loss: 0.1523 - val_mean_absolute_error: 0.1523\n",
      "Epoch 199/400\n",
      "12500/12500 [==============================] - 6s 493us/step - loss: 0.1515 - mean_absolute_error: 0.1515 - val_loss: 0.1531 - val_mean_absolute_error: 0.1531\n",
      "Epoch 200/400\n",
      "12500/12500 [==============================] - 6s 467us/step - loss: 0.1515 - mean_absolute_error: 0.1515 - val_loss: 0.1561 - val_mean_absolute_error: 0.1561\n",
      "Epoch 201/400\n",
      "12500/12500 [==============================] - 6s 479us/step - loss: 0.1515 - mean_absolute_error: 0.1515 - val_loss: 0.1517 - val_mean_absolute_error: 0.1517\n",
      "Epoch 202/400\n",
      "12500/12500 [==============================] - 6s 494us/step - loss: 0.1514 - mean_absolute_error: 0.1514 - val_loss: 0.1515 - val_mean_absolute_error: 0.1515\n",
      "Epoch 203/400\n",
      "12500/12500 [==============================] - 6s 463us/step - loss: 0.1515 - mean_absolute_error: 0.1515 - val_loss: 0.1541 - val_mean_absolute_error: 0.1541\n",
      "Epoch 204/400\n",
      "12500/12500 [==============================] - 6s 469us/step - loss: 0.1514 - mean_absolute_error: 0.1514 - val_loss: 0.1513 - val_mean_absolute_error: 0.1513\n",
      "Epoch 205/400\n",
      "12500/12500 [==============================] - 6s 519us/step - loss: 0.1514 - mean_absolute_error: 0.1514 - val_loss: 0.1502 - val_mean_absolute_error: 0.1502\n",
      "Epoch 206/400\n",
      "12500/12500 [==============================] - 6s 470us/step - loss: 0.1514 - mean_absolute_error: 0.1514 - val_loss: 0.1537 - val_mean_absolute_error: 0.1537\n",
      "Epoch 207/400\n",
      "12500/12500 [==============================] - 6s 503us/step - loss: 0.1514 - mean_absolute_error: 0.1514 - val_loss: 0.1533 - val_mean_absolute_error: 0.1533\n",
      "Epoch 208/400\n",
      "12500/12500 [==============================] - 6s 511us/step - loss: 0.1515 - mean_absolute_error: 0.1515 - val_loss: 0.1515 - val_mean_absolute_error: 0.1515\n",
      "Epoch 209/400\n",
      "12500/12500 [==============================] - 6s 487us/step - loss: 0.1514 - mean_absolute_error: 0.1514 - val_loss: 0.1555 - val_mean_absolute_error: 0.1555\n",
      "Epoch 210/400\n",
      "12500/12500 [==============================] - 6s 478us/step - loss: 0.1514 - mean_absolute_error: 0.1514 - val_loss: 0.1534 - val_mean_absolute_error: 0.1534\n",
      "Epoch 211/400\n",
      "12500/12500 [==============================] - 6s 494us/step - loss: 0.1515 - mean_absolute_error: 0.1515 - val_loss: 0.1502 - val_mean_absolute_error: 0.1502\n",
      "Epoch 212/400\n",
      "12500/12500 [==============================] - 6s 469us/step - loss: 0.1514 - mean_absolute_error: 0.1514 - val_loss: 0.1559 - val_mean_absolute_error: 0.1559\n",
      "Epoch 213/400\n",
      "12500/12500 [==============================] - 6s 489us/step - loss: 0.1514 - mean_absolute_error: 0.1514 - val_loss: 0.1541 - val_mean_absolute_error: 0.1541\n",
      "Epoch 214/400\n",
      "12500/12500 [==============================] - 6s 476us/step - loss: 0.1514 - mean_absolute_error: 0.1514 - val_loss: 0.1514 - val_mean_absolute_error: 0.1514\n",
      "Epoch 215/400\n",
      "12500/12500 [==============================] - 6s 454us/step - loss: 0.1514 - mean_absolute_error: 0.1514 - val_loss: 0.1532 - val_mean_absolute_error: 0.1532\n",
      "Epoch 216/400\n",
      "12500/12500 [==============================] - 6s 495us/step - loss: 0.1514 - mean_absolute_error: 0.1514 - val_loss: 0.1546 - val_mean_absolute_error: 0.1546\n",
      "Epoch 217/400\n",
      "12500/12500 [==============================] - 6s 487us/step - loss: 0.1514 - mean_absolute_error: 0.1514 - val_loss: 0.1573 - val_mean_absolute_error: 0.1573\n",
      "Epoch 218/400\n",
      "12500/12500 [==============================] - 6s 462us/step - loss: 0.1513 - mean_absolute_error: 0.1513 - val_loss: 0.1555 - val_mean_absolute_error: 0.1555\n",
      "Epoch 219/400\n",
      "12500/12500 [==============================] - 6s 459us/step - loss: 0.1513 - mean_absolute_error: 0.1513 - val_loss: 0.1510 - val_mean_absolute_error: 0.1510\n",
      "Epoch 220/400\n",
      "12500/12500 [==============================] - 6s 467us/step - loss: 0.1514 - mean_absolute_error: 0.1514 - val_loss: 0.1543 - val_mean_absolute_error: 0.1543\n",
      "Epoch 221/400\n",
      "12500/12500 [==============================] - 6s 480us/step - loss: 0.1514 - mean_absolute_error: 0.1514 - val_loss: 0.1539 - val_mean_absolute_error: 0.1539\n",
      "Epoch 222/400\n",
      "12500/12500 [==============================] - 6s 467us/step - loss: 0.1513 - mean_absolute_error: 0.1513 - val_loss: 0.1512 - val_mean_absolute_error: 0.1512\n",
      "Epoch 223/400\n",
      "12500/12500 [==============================] - 6s 472us/step - loss: 0.1513 - mean_absolute_error: 0.1513 - val_loss: 0.1519 - val_mean_absolute_error: 0.1519\n",
      "Epoch 224/400\n",
      "12500/12500 [==============================] - 6s 461us/step - loss: 0.1514 - mean_absolute_error: 0.1514 - val_loss: 0.1525 - val_mean_absolute_error: 0.1525\n",
      "Epoch 225/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1513 - mean_absolute_error: 0.1513 - val_loss: 0.1510 - val_mean_absolute_error: 0.1510\n",
      "Epoch 226/400\n",
      "12500/12500 [==============================] - 6s 462us/step - loss: 0.1513 - mean_absolute_error: 0.1513 - val_loss: 0.1515 - val_mean_absolute_error: 0.1515\n",
      "Epoch 227/400\n",
      "12500/12500 [==============================] - 6s 503us/step - loss: 0.1513 - mean_absolute_error: 0.1513 - val_loss: 0.1522 - val_mean_absolute_error: 0.1522\n",
      "Epoch 228/400\n",
      "12500/12500 [==============================] - 6s 478us/step - loss: 0.1513 - mean_absolute_error: 0.1513 - val_loss: 0.1508 - val_mean_absolute_error: 0.1508\n",
      "Epoch 229/400\n",
      "12500/12500 [==============================] - 6s 462us/step - loss: 0.1513 - mean_absolute_error: 0.1513 - val_loss: 0.1533 - val_mean_absolute_error: 0.1533\n",
      "Epoch 230/400\n",
      "12500/12500 [==============================] - 6s 458us/step - loss: 0.1513 - mean_absolute_error: 0.1513 - val_loss: 0.1529 - val_mean_absolute_error: 0.1529\n",
      "Epoch 231/400\n",
      "12500/12500 [==============================] - 6s 465us/step - loss: 0.1513 - mean_absolute_error: 0.1513 - val_loss: 0.1525 - val_mean_absolute_error: 0.1525\n",
      "Epoch 232/400\n",
      "12500/12500 [==============================] - 6s 462us/step - loss: 0.1513 - mean_absolute_error: 0.1513 - val_loss: 0.1521 - val_mean_absolute_error: 0.1521\n",
      "Epoch 233/400\n",
      "12500/12500 [==============================] - 6s 453us/step - loss: 0.1513 - mean_absolute_error: 0.1513 - val_loss: 0.1521 - val_mean_absolute_error: 0.1521\n",
      "Epoch 234/400\n",
      "12500/12500 [==============================] - 6s 472us/step - loss: 0.1513 - mean_absolute_error: 0.1513 - val_loss: 0.1575 - val_mean_absolute_error: 0.1575\n",
      "Epoch 235/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1513 - mean_absolute_error: 0.1513 - val_loss: 0.1516 - val_mean_absolute_error: 0.1516\n",
      "Epoch 236/400\n",
      "12500/12500 [==============================] - 6s 469us/step - loss: 0.1512 - mean_absolute_error: 0.1512 - val_loss: 0.1538 - val_mean_absolute_error: 0.1538\n",
      "Epoch 237/400\n",
      "12500/12500 [==============================] - 6s 471us/step - loss: 0.1512 - mean_absolute_error: 0.1512 - val_loss: 0.1522 - val_mean_absolute_error: 0.1522\n",
      "Epoch 238/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1512 - mean_absolute_error: 0.1512 - val_loss: 0.1534 - val_mean_absolute_error: 0.1534\n",
      "Epoch 239/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1513 - mean_absolute_error: 0.1513 - val_loss: 0.1535 - val_mean_absolute_error: 0.1535\n",
      "Epoch 240/400\n",
      "12500/12500 [==============================] - 6s 485us/step - loss: 0.1512 - mean_absolute_error: 0.1512 - val_loss: 0.1546 - val_mean_absolute_error: 0.1546\n",
      "Epoch 241/400\n",
      "12500/12500 [==============================] - 6s 454us/step - loss: 0.1513 - mean_absolute_error: 0.1513 - val_loss: 0.1530 - val_mean_absolute_error: 0.1530\n",
      "Epoch 242/400\n",
      "12500/12500 [==============================] - 6s 453us/step - loss: 0.1512 - mean_absolute_error: 0.1512 - val_loss: 0.1525 - val_mean_absolute_error: 0.1525\n",
      "Epoch 243/400\n",
      "12500/12500 [==============================] - 6s 453us/step - loss: 0.1512 - mean_absolute_error: 0.1512 - val_loss: 0.1528 - val_mean_absolute_error: 0.1528\n",
      "Epoch 244/400\n",
      "12500/12500 [==============================] - 6s 455us/step - loss: 0.1512 - mean_absolute_error: 0.1512 - val_loss: 0.1543 - val_mean_absolute_error: 0.1543\n",
      "Epoch 245/400\n",
      "12500/12500 [==============================] - 6s 452us/step - loss: 0.1512 - mean_absolute_error: 0.1512 - val_loss: 0.1526 - val_mean_absolute_error: 0.1526\n",
      "Epoch 246/400\n",
      "12500/12500 [==============================] - 6s 454us/step - loss: 0.1512 - mean_absolute_error: 0.1512 - val_loss: 0.1521 - val_mean_absolute_error: 0.1521\n",
      "Epoch 247/400\n",
      "12500/12500 [==============================] - 6s 454us/step - loss: 0.1512 - mean_absolute_error: 0.1512 - val_loss: 0.1519 - val_mean_absolute_error: 0.1519\n",
      "Epoch 248/400\n",
      "12500/12500 [==============================] - 6s 453us/step - loss: 0.1512 - mean_absolute_error: 0.1512 - val_loss: 0.1514 - val_mean_absolute_error: 0.1514\n",
      "Epoch 249/400\n",
      "12500/12500 [==============================] - 6s 452us/step - loss: 0.1512 - mean_absolute_error: 0.1512 - val_loss: 0.1540 - val_mean_absolute_error: 0.1540\n",
      "Epoch 250/400\n",
      "12500/12500 [==============================] - 6s 453us/step - loss: 0.1512 - mean_absolute_error: 0.1512 - val_loss: 0.1518 - val_mean_absolute_error: 0.1518\n",
      "Epoch 251/400\n",
      "12500/12500 [==============================] - 6s 455us/step - loss: 0.1511 - mean_absolute_error: 0.1511 - val_loss: 0.1521 - val_mean_absolute_error: 0.1521\n",
      "Epoch 252/400\n",
      "12500/12500 [==============================] - 6s 455us/step - loss: 0.1512 - mean_absolute_error: 0.1512 - val_loss: 0.1514 - val_mean_absolute_error: 0.1514\n",
      "Epoch 253/400\n",
      "12500/12500 [==============================] - 6s 455us/step - loss: 0.1512 - mean_absolute_error: 0.1512 - val_loss: 0.1521 - val_mean_absolute_error: 0.1521\n",
      "Epoch 254/400\n",
      "12500/12500 [==============================] - 6s 454us/step - loss: 0.1511 - mean_absolute_error: 0.1511 - val_loss: 0.1562 - val_mean_absolute_error: 0.1562\n",
      "Epoch 255/400\n",
      "12500/12500 [==============================] - 6s 452us/step - loss: 0.1512 - mean_absolute_error: 0.1512 - val_loss: 0.1517 - val_mean_absolute_error: 0.1517\n",
      "Epoch 256/400\n",
      "12500/12500 [==============================] - 6s 453us/step - loss: 0.1511 - mean_absolute_error: 0.1511 - val_loss: 0.1514 - val_mean_absolute_error: 0.1514\n",
      "Epoch 257/400\n",
      "12500/12500 [==============================] - 6s 453us/step - loss: 0.1511 - mean_absolute_error: 0.1511 - val_loss: 0.1527 - val_mean_absolute_error: 0.1527\n",
      "Epoch 258/400\n",
      "12500/12500 [==============================] - 6s 452us/step - loss: 0.1511 - mean_absolute_error: 0.1511 - val_loss: 0.1517 - val_mean_absolute_error: 0.1517\n",
      "Epoch 259/400\n",
      "12500/12500 [==============================] - 6s 453us/step - loss: 0.1512 - mean_absolute_error: 0.1512 - val_loss: 0.1541 - val_mean_absolute_error: 0.1541\n",
      "Epoch 260/400\n",
      "12500/12500 [==============================] - 6s 452us/step - loss: 0.1511 - mean_absolute_error: 0.1511 - val_loss: 0.1521 - val_mean_absolute_error: 0.1521\n",
      "Epoch 261/400\n",
      "12500/12500 [==============================] - 6s 451us/step - loss: 0.1510 - mean_absolute_error: 0.1510 - val_loss: 0.1537 - val_mean_absolute_error: 0.1537\n",
      "Epoch 262/400\n",
      "12500/12500 [==============================] - 6s 463us/step - loss: 0.1511 - mean_absolute_error: 0.1511 - val_loss: 0.1528 - val_mean_absolute_error: 0.1528\n",
      "Epoch 263/400\n",
      "12500/12500 [==============================] - 6s 454us/step - loss: 0.1511 - mean_absolute_error: 0.1511 - val_loss: 0.1524 - val_mean_absolute_error: 0.1524\n",
      "Epoch 264/400\n",
      "12500/12500 [==============================] - 6s 455us/step - loss: 0.1511 - mean_absolute_error: 0.1511 - val_loss: 0.1540 - val_mean_absolute_error: 0.1540\n",
      "Epoch 265/400\n",
      "12500/12500 [==============================] - 6s 458us/step - loss: 0.1511 - mean_absolute_error: 0.1511 - val_loss: 0.1518 - val_mean_absolute_error: 0.1518\n",
      "Epoch 266/400\n",
      "12500/12500 [==============================] - 6s 455us/step - loss: 0.1511 - mean_absolute_error: 0.1511 - val_loss: 0.1516 - val_mean_absolute_error: 0.1516\n",
      "Epoch 267/400\n",
      "12500/12500 [==============================] - 6s 467us/step - loss: 0.1512 - mean_absolute_error: 0.1512 - val_loss: 0.1526 - val_mean_absolute_error: 0.1526\n",
      "Epoch 268/400\n",
      "12500/12500 [==============================] - 6s 498us/step - loss: 0.1511 - mean_absolute_error: 0.1511 - val_loss: 0.1511 - val_mean_absolute_error: 0.1511\n",
      "Epoch 269/400\n",
      "12500/12500 [==============================] - 6s 506us/step - loss: 0.1511 - mean_absolute_error: 0.1511 - val_loss: 0.1543 - val_mean_absolute_error: 0.1543\n",
      "Epoch 270/400\n",
      "12500/12500 [==============================] - 6s 466us/step - loss: 0.1510 - mean_absolute_error: 0.1510 - val_loss: 0.1543 - val_mean_absolute_error: 0.1543\n",
      "Epoch 271/400\n",
      "12500/12500 [==============================] - 6s 476us/step - loss: 0.1511 - mean_absolute_error: 0.1511 - val_loss: 0.1553 - val_mean_absolute_error: 0.1553\n",
      "Epoch 272/400\n",
      "12500/12500 [==============================] - 6s 453us/step - loss: 0.1511 - mean_absolute_error: 0.1511 - val_loss: 0.1534 - val_mean_absolute_error: 0.1534\n",
      "Epoch 273/400\n",
      "12500/12500 [==============================] - 5s 437us/step - loss: 0.1510 - mean_absolute_error: 0.1510 - val_loss: 0.1555 - val_mean_absolute_error: 0.1555\n",
      "Epoch 274/400\n",
      "12500/12500 [==============================] - 5s 437us/step - loss: 0.1510 - mean_absolute_error: 0.1510 - val_loss: 0.1542 - val_mean_absolute_error: 0.1542\n",
      "Epoch 275/400\n",
      "12500/12500 [==============================] - 6s 457us/step - loss: 0.1510 - mean_absolute_error: 0.1510 - val_loss: 0.1516 - val_mean_absolute_error: 0.1516\n",
      "Epoch 276/400\n",
      "12500/12500 [==============================] - 6s 456us/step - loss: 0.1510 - mean_absolute_error: 0.1510 - val_loss: 0.1521 - val_mean_absolute_error: 0.1521\n",
      "Epoch 277/400\n",
      "12500/12500 [==============================] - 5s 435us/step - loss: 0.1510 - mean_absolute_error: 0.1510 - val_loss: 0.1515 - val_mean_absolute_error: 0.1515\n",
      "Epoch 278/400\n",
      "12500/12500 [==============================] - 6s 445us/step - loss: 0.1510 - mean_absolute_error: 0.1510 - val_loss: 0.1520 - val_mean_absolute_error: 0.1520\n",
      "Epoch 279/400\n",
      "12500/12500 [==============================] - 6s 448us/step - loss: 0.1510 - mean_absolute_error: 0.1510 - val_loss: 0.1494 - val_mean_absolute_error: 0.1494\n",
      "Epoch 280/400\n",
      "12500/12500 [==============================] - 6s 450us/step - loss: 0.1510 - mean_absolute_error: 0.1510 - val_loss: 0.1531 - val_mean_absolute_error: 0.1531\n",
      "Epoch 281/400\n",
      "12500/12500 [==============================] - 6s 447us/step - loss: 0.1509 - mean_absolute_error: 0.1509 - val_loss: 0.1521 - val_mean_absolute_error: 0.1521\n",
      "Epoch 282/400\n",
      "12500/12500 [==============================] - 6s 447us/step - loss: 0.1509 - mean_absolute_error: 0.1509 - val_loss: 0.1523 - val_mean_absolute_error: 0.1523\n",
      "Epoch 283/400\n",
      "12500/12500 [==============================] - 6s 444us/step - loss: 0.1509 - mean_absolute_error: 0.1509 - val_loss: 0.1531 - val_mean_absolute_error: 0.1531\n",
      "Epoch 284/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 6s 450us/step - loss: 0.1509 - mean_absolute_error: 0.1509 - val_loss: 0.1538 - val_mean_absolute_error: 0.1538\n",
      "Epoch 285/400\n",
      "12500/12500 [==============================] - 6s 464us/step - loss: 0.1509 - mean_absolute_error: 0.1509 - val_loss: 0.1514 - val_mean_absolute_error: 0.1514\n",
      "Epoch 286/400\n",
      "12500/12500 [==============================] - 5s 433us/step - loss: 0.1509 - mean_absolute_error: 0.1509 - val_loss: 0.1547 - val_mean_absolute_error: 0.1547\n",
      "Epoch 287/400\n",
      "12500/12500 [==============================] - 5s 431us/step - loss: 0.1510 - mean_absolute_error: 0.1510 - val_loss: 0.1538 - val_mean_absolute_error: 0.1538\n",
      "Epoch 288/400\n",
      "12500/12500 [==============================] - 6s 442us/step - loss: 0.1509 - mean_absolute_error: 0.1509 - val_loss: 0.1497 - val_mean_absolute_error: 0.1497\n",
      "Epoch 289/400\n",
      "12500/12500 [==============================] - 6s 456us/step - loss: 0.1509 - mean_absolute_error: 0.1509 - val_loss: 0.1517 - val_mean_absolute_error: 0.1517\n",
      "Epoch 290/400\n",
      "12500/12500 [==============================] - 5s 438us/step - loss: 0.1508 - mean_absolute_error: 0.1508 - val_loss: 0.1514 - val_mean_absolute_error: 0.1514\n",
      "Epoch 291/400\n",
      "12500/12500 [==============================] - 6s 450us/step - loss: 0.1509 - mean_absolute_error: 0.1509 - val_loss: 0.1525 - val_mean_absolute_error: 0.1525\n",
      "Epoch 292/400\n",
      "12500/12500 [==============================] - 6s 440us/step - loss: 0.1509 - mean_absolute_error: 0.1509 - val_loss: 0.1558 - val_mean_absolute_error: 0.1558\n",
      "Epoch 293/400\n",
      "12500/12500 [==============================] - 6s 441us/step - loss: 0.1508 - mean_absolute_error: 0.1508 - val_loss: 0.1533 - val_mean_absolute_error: 0.1533\n",
      "Epoch 294/400\n",
      "12500/12500 [==============================] - 6s 457us/step - loss: 0.1508 - mean_absolute_error: 0.1508 - val_loss: 0.1536 - val_mean_absolute_error: 0.1536\n",
      "Epoch 295/400\n",
      "12500/12500 [==============================] - 6s 446us/step - loss: 0.1508 - mean_absolute_error: 0.1508 - val_loss: 0.1545 - val_mean_absolute_error: 0.1545\n",
      "Epoch 296/400\n",
      "12500/12500 [==============================] - 6s 456us/step - loss: 0.1508 - mean_absolute_error: 0.1508 - val_loss: 0.1492 - val_mean_absolute_error: 0.1492\n",
      "Epoch 297/400\n",
      "12500/12500 [==============================] - 6s 447us/step - loss: 0.1508 - mean_absolute_error: 0.1508 - val_loss: 0.1513 - val_mean_absolute_error: 0.1513\n",
      "Epoch 298/400\n",
      "12500/12500 [==============================] - 6s 453us/step - loss: 0.1508 - mean_absolute_error: 0.1508 - val_loss: 0.1525 - val_mean_absolute_error: 0.1525\n",
      "Epoch 299/400\n",
      "12500/12500 [==============================] - 6s 441us/step - loss: 0.1508 - mean_absolute_error: 0.1508 - val_loss: 0.1552 - val_mean_absolute_error: 0.1552\n",
      "Epoch 300/400\n",
      "12500/12500 [==============================] - 6s 454us/step - loss: 0.1508 - mean_absolute_error: 0.1508 - val_loss: 0.1493 - val_mean_absolute_error: 0.1493\n",
      "Epoch 301/400\n",
      "12500/12500 [==============================] - 7s 522us/step - loss: 0.1507 - mean_absolute_error: 0.1507 - val_loss: 0.1511 - val_mean_absolute_error: 0.1511\n",
      "Epoch 302/400\n",
      "12500/12500 [==============================] - 6s 450us/step - loss: 0.1507 - mean_absolute_error: 0.1507 - val_loss: 0.1543 - val_mean_absolute_error: 0.1543\n",
      "Epoch 303/400\n",
      "12500/12500 [==============================] - 6s 464us/step - loss: 0.1507 - mean_absolute_error: 0.1507 - val_loss: 0.1527 - val_mean_absolute_error: 0.1527\n",
      "Epoch 304/400\n",
      "12500/12500 [==============================] - 6s 453us/step - loss: 0.1507 - mean_absolute_error: 0.1507 - val_loss: 0.1537 - val_mean_absolute_error: 0.1537\n",
      "Epoch 305/400\n",
      "12500/12500 [==============================] - 6s 447us/step - loss: 0.1506 - mean_absolute_error: 0.1506 - val_loss: 0.1511 - val_mean_absolute_error: 0.1511\n",
      "Epoch 306/400\n",
      "12500/12500 [==============================] - 6s 472us/step - loss: 0.1506 - mean_absolute_error: 0.1506 - val_loss: 0.1493 - val_mean_absolute_error: 0.1493\n",
      "Epoch 307/400\n",
      "12500/12500 [==============================] - 6s 466us/step - loss: 0.1506 - mean_absolute_error: 0.1506 - val_loss: 0.1524 - val_mean_absolute_error: 0.1524\n",
      "Epoch 308/400\n",
      "12500/12500 [==============================] - 6s 461us/step - loss: 0.1506 - mean_absolute_error: 0.1506 - val_loss: 0.1526 - val_mean_absolute_error: 0.1526\n",
      "Epoch 309/400\n",
      "12500/12500 [==============================] - 6s 466us/step - loss: 0.1506 - mean_absolute_error: 0.1506 - val_loss: 0.1528 - val_mean_absolute_error: 0.1528\n",
      "Epoch 310/400\n",
      "12500/12500 [==============================] - 6s 461us/step - loss: 0.1506 - mean_absolute_error: 0.1506 - val_loss: 0.1522 - val_mean_absolute_error: 0.1522\n",
      "Epoch 311/400\n",
      "12500/12500 [==============================] - 6s 459us/step - loss: 0.1506 - mean_absolute_error: 0.1506 - val_loss: 0.1507 - val_mean_absolute_error: 0.1507\n",
      "Epoch 312/400\n",
      "12500/12500 [==============================] - 6s 480us/step - loss: 0.1506 - mean_absolute_error: 0.1506 - val_loss: 0.1504 - val_mean_absolute_error: 0.1504\n",
      "Epoch 313/400\n",
      "12500/12500 [==============================] - 6s 463us/step - loss: 0.1506 - mean_absolute_error: 0.1506 - val_loss: 0.1532 - val_mean_absolute_error: 0.1532\n",
      "Epoch 314/400\n",
      "12500/12500 [==============================] - 6s 485us/step - loss: 0.1506 - mean_absolute_error: 0.1506 - val_loss: 0.1511 - val_mean_absolute_error: 0.1511\n",
      "Epoch 315/400\n",
      "12500/12500 [==============================] - 6s 472us/step - loss: 0.1506 - mean_absolute_error: 0.1506 - val_loss: 0.1557 - val_mean_absolute_error: 0.1557\n",
      "Epoch 316/400\n",
      "12500/12500 [==============================] - 6s 482us/step - loss: 0.1506 - mean_absolute_error: 0.1506 - val_loss: 0.1534 - val_mean_absolute_error: 0.1534\n",
      "Epoch 317/400\n",
      "12500/12500 [==============================] - 6s 478us/step - loss: 0.1506 - mean_absolute_error: 0.1506 - val_loss: 0.1510 - val_mean_absolute_error: 0.1510\n",
      "Epoch 318/400\n",
      "12500/12500 [==============================] - 6s 482us/step - loss: 0.1506 - mean_absolute_error: 0.1506 - val_loss: 0.1546 - val_mean_absolute_error: 0.1546\n",
      "Epoch 319/400\n",
      "12500/12500 [==============================] - 6s 455us/step - loss: 0.1505 - mean_absolute_error: 0.1505 - val_loss: 0.1509 - val_mean_absolute_error: 0.1509\n",
      "Epoch 320/400\n",
      "12500/12500 [==============================] - 6s 453us/step - loss: 0.1505 - mean_absolute_error: 0.1505 - val_loss: 0.1536 - val_mean_absolute_error: 0.1536\n",
      "Epoch 321/400\n",
      "12500/12500 [==============================] - 6s 457us/step - loss: 0.1505 - mean_absolute_error: 0.1505 - val_loss: 0.1523 - val_mean_absolute_error: 0.1523\n",
      "Epoch 322/400\n",
      "12500/12500 [==============================] - 6s 500us/step - loss: 0.1505 - mean_absolute_error: 0.1505 - val_loss: 0.1500 - val_mean_absolute_error: 0.1500\n",
      "Epoch 323/400\n",
      "12500/12500 [==============================] - 14s 1ms/step - loss: 0.1505 - mean_absolute_error: 0.1505 - val_loss: 0.1531 - val_mean_absolute_error: 0.1531\n",
      "Epoch 324/400\n",
      "12500/12500 [==============================] - 9s 725us/step - loss: 0.1506 - mean_absolute_error: 0.1506 - val_loss: 0.1513 - val_mean_absolute_error: 0.1513\n",
      "Epoch 325/400\n",
      "12500/12500 [==============================] - 10s 824us/step - loss: 0.1505 - mean_absolute_error: 0.1505 - val_loss: 0.1523 - val_mean_absolute_error: 0.1523\n",
      "Epoch 326/400\n",
      "12500/12500 [==============================] - 11s 865us/step - loss: 0.1505 - mean_absolute_error: 0.1505 - val_loss: 0.1523 - val_mean_absolute_error: 0.1523\n",
      "Epoch 327/400\n",
      "12500/12500 [==============================] - 11s 852us/step - loss: 0.1504 - mean_absolute_error: 0.1504 - val_loss: 0.1541 - val_mean_absolute_error: 0.1541\n",
      "Epoch 328/400\n",
      "12500/12500 [==============================] - 11s 897us/step - loss: 0.1505 - mean_absolute_error: 0.1505 - val_loss: 0.1520 - val_mean_absolute_error: 0.1520\n",
      "Epoch 329/400\n",
      "12500/12500 [==============================] - 11s 874us/step - loss: 0.1504 - mean_absolute_error: 0.1504 - val_loss: 0.1545 - val_mean_absolute_error: 0.1545\n",
      "Epoch 330/400\n",
      "12500/12500 [==============================] - 10s 824us/step - loss: 0.1505 - mean_absolute_error: 0.1505 - val_loss: 0.1519 - val_mean_absolute_error: 0.1519\n",
      "Epoch 331/400\n",
      "12500/12500 [==============================] - 10s 776us/step - loss: 0.1505 - mean_absolute_error: 0.1505 - val_loss: 0.1528 - val_mean_absolute_error: 0.1528\n",
      "Epoch 332/400\n",
      "12500/12500 [==============================] - 11s 848us/step - loss: 0.1505 - mean_absolute_error: 0.1505 - val_loss: 0.1526 - val_mean_absolute_error: 0.1526\n",
      "Epoch 333/400\n",
      "12500/12500 [==============================] - 11s 868us/step - loss: 0.1505 - mean_absolute_error: 0.1505 - val_loss: 0.1541 - val_mean_absolute_error: 0.1541\n",
      "Epoch 334/400\n",
      "12500/12500 [==============================] - 11s 850us/step - loss: 0.1505 - mean_absolute_error: 0.1505 - val_loss: 0.1523 - val_mean_absolute_error: 0.1523\n",
      "Epoch 335/400\n",
      "12500/12500 [==============================] - 10s 827us/step - loss: 0.1505 - mean_absolute_error: 0.1505 - val_loss: 0.1523 - val_mean_absolute_error: 0.1523\n",
      "Epoch 336/400\n",
      "12500/12500 [==============================] - 10s 781us/step - loss: 0.1504 - mean_absolute_error: 0.1504 - val_loss: 0.1519 - val_mean_absolute_error: 0.1519\n",
      "Epoch 337/400\n",
      "12500/12500 [==============================] - 10s 775us/step - loss: 0.1504 - mean_absolute_error: 0.1504 - val_loss: 0.1537 - val_mean_absolute_error: 0.1537\n",
      "Epoch 338/400\n",
      "12500/12500 [==============================] - 9s 688us/step - loss: 0.1504 - mean_absolute_error: 0.1504 - val_loss: 0.1497 - val_mean_absolute_error: 0.1497\n",
      "Epoch 339/400\n",
      "12500/12500 [==============================] - 6s 448us/step - loss: 0.1504 - mean_absolute_error: 0.1504 - val_loss: 0.1507 - val_mean_absolute_error: 0.1507\n",
      "Epoch 340/400\n",
      "12500/12500 [==============================] - 6s 446us/step - loss: 0.1504 - mean_absolute_error: 0.1504 - val_loss: 0.1519 - val_mean_absolute_error: 0.1519\n",
      "Epoch 341/400\n",
      "12500/12500 [==============================] - 9s 699us/step - loss: 0.1504 - mean_absolute_error: 0.1504 - val_loss: 0.1510 - val_mean_absolute_error: 0.1510\n",
      "Epoch 342/400\n",
      "12500/12500 [==============================] - 6s 461us/step - loss: 0.1504 - mean_absolute_error: 0.1504 - val_loss: 0.1537 - val_mean_absolute_error: 0.1537\n",
      "Epoch 343/400\n",
      "12500/12500 [==============================] - 6s 462us/step - loss: 0.1504 - mean_absolute_error: 0.1504 - val_loss: 0.1556 - val_mean_absolute_error: 0.1556\n",
      "Epoch 344/400\n",
      "12500/12500 [==============================] - 6s 461us/step - loss: 0.1504 - mean_absolute_error: 0.1504 - val_loss: 0.1507 - val_mean_absolute_error: 0.1507\n",
      "Epoch 345/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1504 - mean_absolute_error: 0.1504 - val_loss: 0.1512 - val_mean_absolute_error: 0.1512\n",
      "Epoch 346/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1504 - mean_absolute_error: 0.1504 - val_loss: 0.1510 - val_mean_absolute_error: 0.1510\n",
      "Epoch 347/400\n",
      "12500/12500 [==============================] - 6s 459us/step - loss: 0.1504 - mean_absolute_error: 0.1504 - val_loss: 0.1510 - val_mean_absolute_error: 0.1510\n",
      "Epoch 348/400\n",
      "12500/12500 [==============================] - 6s 459us/step - loss: 0.1504 - mean_absolute_error: 0.1504 - val_loss: 0.1496 - val_mean_absolute_error: 0.1496\n",
      "Epoch 349/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1504 - mean_absolute_error: 0.1504 - val_loss: 0.1524 - val_mean_absolute_error: 0.1524\n",
      "Epoch 350/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1504 - mean_absolute_error: 0.1504 - val_loss: 0.1499 - val_mean_absolute_error: 0.1499\n",
      "Epoch 351/400\n",
      "12500/12500 [==============================] - 6s 459us/step - loss: 0.1504 - mean_absolute_error: 0.1504 - val_loss: 0.1508 - val_mean_absolute_error: 0.1508\n",
      "Epoch 352/400\n",
      "12500/12500 [==============================] - 6s 457us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1497 - val_mean_absolute_error: 0.1497\n",
      "Epoch 353/400\n",
      "12500/12500 [==============================] - 6s 459us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1508 - val_mean_absolute_error: 0.1508\n",
      "Epoch 354/400\n",
      "12500/12500 [==============================] - 6s 469us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1532 - val_mean_absolute_error: 0.1532\n",
      "Epoch 355/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1513 - val_mean_absolute_error: 0.1513\n",
      "Epoch 356/400\n",
      "12500/12500 [==============================] - 6s 464us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1528 - val_mean_absolute_error: 0.1528\n",
      "Epoch 357/400\n",
      "12500/12500 [==============================] - 6s 461us/step - loss: 0.1504 - mean_absolute_error: 0.1504 - val_loss: 0.1517 - val_mean_absolute_error: 0.1517\n",
      "Epoch 358/400\n",
      "12500/12500 [==============================] - 6s 459us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1509 - val_mean_absolute_error: 0.1509\n",
      "Epoch 359/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1533 - val_mean_absolute_error: 0.1533\n",
      "Epoch 360/400\n",
      "12500/12500 [==============================] - 6s 461us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1500 - val_mean_absolute_error: 0.1500\n",
      "Epoch 361/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1505 - val_mean_absolute_error: 0.1505\n",
      "Epoch 362/400\n",
      "12500/12500 [==============================] - 6s 459us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1548 - val_mean_absolute_error: 0.1548\n",
      "Epoch 363/400\n",
      "12500/12500 [==============================] - 6s 466us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1503 - val_mean_absolute_error: 0.1503\n",
      "Epoch 364/400\n",
      "12500/12500 [==============================] - 6s 465us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1504 - val_mean_absolute_error: 0.1504\n",
      "Epoch 365/400\n",
      "12500/12500 [==============================] - 6s 461us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1534 - val_mean_absolute_error: 0.1534\n",
      "Epoch 366/400\n",
      "12500/12500 [==============================] - 6s 459us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1508 - val_mean_absolute_error: 0.1508\n",
      "Epoch 367/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1502 - mean_absolute_error: 0.1502 - val_loss: 0.1495 - val_mean_absolute_error: 0.1495\n",
      "Epoch 368/400\n",
      "12500/12500 [==============================] - 6s 461us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1509 - val_mean_absolute_error: 0.1509\n",
      "Epoch 369/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1538 - val_mean_absolute_error: 0.1538\n",
      "Epoch 370/400\n",
      "12500/12500 [==============================] - 6s 461us/step - loss: 0.1502 - mean_absolute_error: 0.1502 - val_loss: 0.1535 - val_mean_absolute_error: 0.1535\n",
      "Epoch 371/400\n",
      "12500/12500 [==============================] - 6s 464us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1509 - val_mean_absolute_error: 0.1509\n",
      "Epoch 372/400\n",
      "12500/12500 [==============================] - 6s 467us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1537 - val_mean_absolute_error: 0.1537\n",
      "Epoch 373/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1521 - val_mean_absolute_error: 0.1521\n",
      "Epoch 374/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1544 - val_mean_absolute_error: 0.1544\n",
      "Epoch 375/400\n",
      "12500/12500 [==============================] - 6s 461us/step - loss: 0.1502 - mean_absolute_error: 0.1502 - val_loss: 0.1528 - val_mean_absolute_error: 0.1528\n",
      "Epoch 376/400\n",
      "12500/12500 [==============================] - 6s 459us/step - loss: 0.1502 - mean_absolute_error: 0.1502 - val_loss: 0.1508 - val_mean_absolute_error: 0.1508\n",
      "Epoch 377/400\n",
      "12500/12500 [==============================] - 6s 459us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1489 - val_mean_absolute_error: 0.1489\n",
      "Epoch 378/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1523 - val_mean_absolute_error: 0.1523\n",
      "Epoch 379/400\n",
      "12500/12500 [==============================] - 6s 459us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1529 - val_mean_absolute_error: 0.1529\n",
      "Epoch 380/400\n",
      "12500/12500 [==============================] - 6s 464us/step - loss: 0.1502 - mean_absolute_error: 0.1502 - val_loss: 0.1525 - val_mean_absolute_error: 0.1525\n",
      "Epoch 381/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1503 - mean_absolute_error: 0.1503 - val_loss: 0.1528 - val_mean_absolute_error: 0.1528\n",
      "Epoch 382/400\n",
      "12500/12500 [==============================] - 6s 463us/step - loss: 0.1502 - mean_absolute_error: 0.1502 - val_loss: 0.1530 - val_mean_absolute_error: 0.1530\n",
      "Epoch 383/400\n",
      "12500/12500 [==============================] - 6s 459us/step - loss: 0.1502 - mean_absolute_error: 0.1502 - val_loss: 0.1521 - val_mean_absolute_error: 0.1521\n",
      "Epoch 384/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1502 - mean_absolute_error: 0.1502 - val_loss: 0.1512 - val_mean_absolute_error: 0.1512\n",
      "Epoch 385/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1502 - mean_absolute_error: 0.1502 - val_loss: 0.1560 - val_mean_absolute_error: 0.1560\n",
      "Epoch 386/400\n",
      "12500/12500 [==============================] - 6s 459us/step - loss: 0.1502 - mean_absolute_error: 0.1502 - val_loss: 0.1491 - val_mean_absolute_error: 0.1491\n",
      "Epoch 387/400\n",
      "12500/12500 [==============================] - 6s 461us/step - loss: 0.1501 - mean_absolute_error: 0.1501 - val_loss: 0.1507 - val_mean_absolute_error: 0.1507\n",
      "Epoch 388/400\n",
      "12500/12500 [==============================] - 6s 458us/step - loss: 0.1502 - mean_absolute_error: 0.1502 - val_loss: 0.1531 - val_mean_absolute_error: 0.1531\n",
      "Epoch 389/400\n",
      "12500/12500 [==============================] - 6s 458us/step - loss: 0.1502 - mean_absolute_error: 0.1502 - val_loss: 0.1530 - val_mean_absolute_error: 0.1530\n",
      "Epoch 390/400\n",
      "12500/12500 [==============================] - 6s 459us/step - loss: 0.1502 - mean_absolute_error: 0.1502 - val_loss: 0.1511 - val_mean_absolute_error: 0.1511\n",
      "Epoch 391/400\n",
      "12500/12500 [==============================] - 6s 458us/step - loss: 0.1502 - mean_absolute_error: 0.1502 - val_loss: 0.1487 - val_mean_absolute_error: 0.1487\n",
      "Epoch 392/400\n",
      "12500/12500 [==============================] - 6s 461us/step - loss: 0.1501 - mean_absolute_error: 0.1501 - val_loss: 0.1521 - val_mean_absolute_error: 0.1521\n",
      "Epoch 393/400\n",
      "12500/12500 [==============================] - 6s 458us/step - loss: 0.1501 - mean_absolute_error: 0.1501 - val_loss: 0.1517 - val_mean_absolute_error: 0.1517\n",
      "Epoch 394/400\n",
      "12500/12500 [==============================] - 6s 463us/step - loss: 0.1502 - mean_absolute_error: 0.1502 - val_loss: 0.1541 - val_mean_absolute_error: 0.1541\n",
      "Epoch 395/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1501 - mean_absolute_error: 0.1501 - val_loss: 0.1523 - val_mean_absolute_error: 0.1523\n",
      "Epoch 396/400\n",
      "12500/12500 [==============================] - 6s 459us/step - loss: 0.1502 - mean_absolute_error: 0.1502 - val_loss: 0.1532 - val_mean_absolute_error: 0.1532\n",
      "Epoch 397/400\n",
      "12500/12500 [==============================] - 6s 458us/step - loss: 0.1502 - mean_absolute_error: 0.1502 - val_loss: 0.1494 - val_mean_absolute_error: 0.1494\n",
      "Epoch 398/400\n",
      "12500/12500 [==============================] - 6s 460us/step - loss: 0.1501 - mean_absolute_error: 0.1501 - val_loss: 0.1496 - val_mean_absolute_error: 0.1496\n",
      "Epoch 399/400\n",
      "12500/12500 [==============================] - 6s 458us/step - loss: 0.1501 - mean_absolute_error: 0.1501 - val_loss: 0.1547 - val_mean_absolute_error: 0.1547\n",
      "Epoch 400/400\n",
      "12500/12500 [==============================] - 6s 457us/step - loss: 0.1501 - mean_absolute_error: 0.1501 - val_loss: 0.1523 - val_mean_absolute_error: 0.1523\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    batch_size=64,\n",
    "    epochs=400,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(X_test, Y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93629dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 0s 315us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10905128717603396"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_train, model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04ad8c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 0s 311us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11408455206590504"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(Y_test, model.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
